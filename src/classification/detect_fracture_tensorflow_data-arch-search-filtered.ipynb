{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models, Model\n",
    "from tensorflow.keras.mixed_precision import experimental as mixed_precision\n",
    "\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "\n",
    "import IPython.display as display\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pathlib\n",
    "\n",
    "import tensorflow.keras.applications\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import cv2\n",
    "\n",
    "import math\n",
    "import warnings\n",
    "\n",
    "\n",
    "from tensorflow.keras.applications import DenseNet121,DenseNet169,  \\\n",
    "                                          DenseNet201,InceptionResNetV2,  \\\n",
    "                                          InceptionV3,MobileNet,MobileNetV2,  \\\n",
    "                                          NASNetLarge,NASNetMobile,ResNet101,  \\\n",
    "                                          ResNet101V2,ResNet152,ResNet152V2,  \\\n",
    "                                          ResNet50,ResNet50V2,VGG16,VGG19,Xception  \n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "IMG_HEIGHT = 512\n",
    "IMG_WIDTH = 512\n",
    "EPOCHS = 20\n",
    "lr = 3e-3\n",
    "CHANNELS =3\n",
    "IMG_SHAPE = (IMG_HEIGHT, IMG_WIDTH, CHANNELS)\n",
    "\n",
    "FILTER_SIZE = 3\n",
    "\n",
    "lrs = [1e-4, 3e-3, 1e-2]\n",
    "batch_sizes = [16,32,64]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy = mixed_precision.Policy('mixed_float16')\n",
    "mixed_precision.set_policy(policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Module for Image Save\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def save_grayscale(image, output_dir, output_name):\n",
    "    \"\"\"\n",
    "    Save a 3D Numpy array (H, W, 1) as an image.\n",
    "    Args:\n",
    "        image (numpy.ndarray): Image to save\n",
    "        output_dir (str): Output directory\n",
    "        output_name (str): Output name\n",
    "    \"\"\"\n",
    "    Path.mkdir(Path(output_dir), parents=True, exist_ok=True)\n",
    "\n",
    "    cv2.imwrite(str(Path(output_dir) / output_name), image)\n",
    "\n",
    "\n",
    "def save_rgb(image, output_dir, output_name):\n",
    "    \"\"\"\n",
    "    Save a 3D Numpy array (H, W, 3) as an image.\n",
    "    Args:\n",
    "        image (numpy.ndarray): Image to save\n",
    "        output_dir (str): Output directory\n",
    "        output_name (str): Output name\n",
    "    \"\"\"\n",
    "    Path.mkdir(Path(output_dir), parents=True, exist_ok=True)\n",
    "\n",
    "    cv2.imwrite(\n",
    "        str(Path(output_dir) / output_name), cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def grid_display(array, num_rows=None, num_columns=None):\n",
    "    \"\"\"\n",
    "    Display a list of images as a grid.\n",
    "    Args:\n",
    "        array (numpy.ndarray): 4D Tensor (batch_size, height, width, channels)\n",
    "    Returns:\n",
    "        numpy.ndarray: 3D Tensor as concatenation of input images on a grid\n",
    "    \"\"\"\n",
    "    if num_rows is not None and num_columns is not None:\n",
    "        total_grid_size = num_rows * num_columns\n",
    "        if total_grid_size < len(array):\n",
    "            warnings.warn(\n",
    "                Warning(\n",
    "                    \"Given values for num_rows and num_columns doesn't allow to display \"\n",
    "                    \"all images. Values have been overrided to respect at least num_columns\"\n",
    "                )\n",
    "            )\n",
    "            num_rows = math.ceil(len(array) / num_columns)\n",
    "    elif num_rows is not None:\n",
    "        num_columns = math.ceil(len(array) / num_rows)\n",
    "    elif num_columns is not None:\n",
    "        num_rows = math.ceil(len(array) / num_columns)\n",
    "    else:\n",
    "        num_rows = math.ceil(math.sqrt(len(array)))\n",
    "        num_columns = math.ceil(math.sqrt(len(array)))\n",
    "\n",
    "    number_of_missing_elements = num_columns * num_rows - len(array)\n",
    "    # We fill the array with np.zeros elements to obtain a perfect square\n",
    "    array = np.append(\n",
    "        array,\n",
    "        np.zeros((number_of_missing_elements, *array[0].shape)).astype(array.dtype),\n",
    "        axis=0,\n",
    "    )\n",
    "\n",
    "    grid = np.concatenate(\n",
    "        [\n",
    "            np.concatenate(\n",
    "                array[index * num_columns : (index + 1) * num_columns], axis=1\n",
    "            )\n",
    "            for index in range(num_rows)\n",
    "        ],\n",
    "        axis=0,\n",
    "    )\n",
    "\n",
    "    return grid\n",
    "\n",
    "\n",
    "def filter_display(array, num_rows=None, num_columns=None):\n",
    "    \"\"\"\n",
    "    Display a list of filter outputs as a greyscale images grid.\n",
    "    Args:\n",
    "        array (numpy.ndarray): 4D Tensor (batch_size, height, width, channels)\n",
    "    Returns:\n",
    "        numpy.ndarray: 3D Tensor as concatenation of input images on a grid\n",
    "    \"\"\"\n",
    "    return grid_display(\n",
    "        np.concatenate(np.rollaxis(array, 3, 1), axis=0), num_rows, num_columns\n",
    "    )\n",
    "\n",
    "\n",
    "def image_to_uint_255(image):\n",
    "    \"\"\"\n",
    "    Convert float images to int 0-255 images.\n",
    "    Args:\n",
    "        image (numpy.ndarray): Input image. Can be either [0, 255], [0, 1], [-1, 1]\n",
    "    Returns:\n",
    "        numpy.ndarray:\n",
    "    \"\"\"\n",
    "    if image.dtype == np.uint8:\n",
    "        return image\n",
    "\n",
    "    if image.min() < 0:\n",
    "        image = (image + 1.0) / 2.0\n",
    "\n",
    "    return (image * 255).astype(\"uint8\")\n",
    "\n",
    "\n",
    "def heatmap_display(\n",
    "    heatmap, original_image, colormap=cv2.COLORMAP_VIRIDIS, image_weight=0.7\n",
    "):\n",
    "    \"\"\"\n",
    "    Apply a heatmap (as an np.ndarray) on top of an original image.\n",
    "    Args:\n",
    "        heatmap (numpy.ndarray): Array corresponding to the heatmap\n",
    "        original_image (numpy.ndarray): Image on which we apply the heatmap\n",
    "        colormap (int): OpenCV Colormap to use for heatmap visualization\n",
    "        image_weight (float): An optional `float` value in range [0,1] indicating the weight of\n",
    "            the input image to be overlaying the calculated attribution maps. Defaults to `0.7`\n",
    "    Returns:\n",
    "        np.ndarray: Original image with heatmap applied\n",
    "    \"\"\"\n",
    "    heatmap = cv2.resize(heatmap, (original_image.shape[1], original_image.shape[0]))\n",
    "\n",
    "    image = image_to_uint_255(original_image)\n",
    "\n",
    "    heatmap = (heatmap - np.min(heatmap)) / (heatmap.max() - heatmap.min())\n",
    "\n",
    "    heatmap = cv2.applyColorMap(\n",
    "        cv2.cvtColor((heatmap * 255).astype(\"uint8\"), cv2.COLOR_GRAY2BGR), colormap\n",
    "    )\n",
    "\n",
    "    output = cv2.addWeighted(\n",
    "        cv2.cvtColor(image, cv2.COLOR_RGB2BGR), image_weight, heatmap, 1, 0\n",
    "    )\n",
    "\n",
    "    return cv2.cvtColor(output, cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Core Module for Grad CAM Algorithm\n",
    "\"\"\"\n",
    "\n",
    "class GradCAM:\n",
    "\n",
    "    \"\"\"\n",
    "    Perform Grad CAM algorithm for a given input\n",
    "    Paper: [Grad-CAM: Visual Explanations from Deep Networks\n",
    "            via Gradient-based Localization](https://arxiv.org/abs/1610.02391)\n",
    "    \"\"\"\n",
    "\n",
    "    def explain(\n",
    "        self,\n",
    "        validation_data,\n",
    "        model,\n",
    "        class_index,\n",
    "        layer_name=None,\n",
    "        colormap=cv2.COLORMAP_VIRIDIS,\n",
    "        image_weight=0.7,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Compute GradCAM for a specific class index.\n",
    "        Args:\n",
    "            validation_data (Tuple[np.ndarray, Optional[np.ndarray]]): Validation data\n",
    "                to perform the method on. Tuple containing (x, y).\n",
    "            model (tf.keras.Model): tf.keras model to inspect\n",
    "            class_index (int): Index of targeted class\n",
    "            layer_name (str): Targeted layer for GradCAM. If no layer is provided, it is\n",
    "                automatically infered from the model architecture.\n",
    "            colormap (int): OpenCV Colormap to use for heatmap visualization\n",
    "            image_weight (float): An optional `float` value in range [0,1] indicating the weight of\n",
    "                the input image to be overlaying the calculated attribution maps. Defaults to `0.7`.\n",
    "        Returns:\n",
    "            numpy.ndarray: Grid of all the GradCAM\n",
    "        \"\"\"\n",
    "        images, _ = validation_data\n",
    "\n",
    "        if layer_name is None:\n",
    "            layer_name = self.infer_grad_cam_target_layer(model)\n",
    "\n",
    "        outputs, guided_grads = GradCAM.get_gradients_and_filters(\n",
    "            model, images, layer_name, class_index\n",
    "        )\n",
    "\n",
    "        cams = GradCAM.generate_ponderated_output(outputs, guided_grads)\n",
    "\n",
    "        heatmaps = np.array(\n",
    "            [\n",
    "                # not showing the actual image if image_weight=0\n",
    "                heatmap_display(cam.numpy(), image, colormap, image_weight)\n",
    "                for cam, image in zip(cams, images)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        grid = grid_display(heatmaps)\n",
    "\n",
    "        return grid\n",
    "\n",
    "    @staticmethod\n",
    "    def infer_grad_cam_target_layer(model):\n",
    "        \"\"\"\n",
    "        Search for the last convolutional layer to perform Grad CAM, as stated\n",
    "        in the original paper.\n",
    "        Args:\n",
    "            model (tf.keras.Model): tf.keras model to inspect\n",
    "        Returns:\n",
    "            str: Name of the target layer\n",
    "        \"\"\"\n",
    "        for layer in reversed(model.layers):\n",
    "            # Select closest 4D layer to the end of the network.\n",
    "            if len(layer.output_shape) == 4:\n",
    "                print(layer.name)\n",
    "                return layer.name\n",
    "\n",
    "        raise ValueError(\n",
    "            \"Model does not seem to contain 4D layer. Grad CAM cannot be applied.\"\n",
    "        )\n",
    "\n",
    "    @staticmethod\n",
    "    @tf.function\n",
    "    def get_gradients_and_filters(model, images, layer_name, class_index):\n",
    "        \"\"\"\n",
    "        Generate guided gradients and convolutional outputs with an inference.\n",
    "        Args:\n",
    "            model (tf.keras.Model): tf.keras model to inspect\n",
    "            images (numpy.ndarray): 4D-Tensor with shape (batch_size, H, W, 3)\n",
    "            layer_name (str): Targeted layer for GradCAM\n",
    "            class_index (int): Index of targeted class\n",
    "        Returns:\n",
    "            Tuple[tf.Tensor, tf.Tensor]: (Target layer outputs, Guided gradients)\n",
    "        \"\"\"\n",
    "        grad_model = tf.keras.models.Model(\n",
    "            [model.inputs], [model.get_layer(layer_name).output, model.output]\n",
    "        )\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            inputs = tf.cast(images, tf.float32)\n",
    "            conv_outputs, predictions = grad_model(inputs)\n",
    "            loss = predictions[:, class_index]\n",
    "\n",
    "        grads = tape.gradient(loss, conv_outputs)\n",
    "\n",
    "        guided_grads = (\n",
    "            tf.cast(conv_outputs > 0, \"float32\") * tf.cast(grads > 0, \"float32\") * grads\n",
    "        )\n",
    "\n",
    "        return conv_outputs, guided_grads\n",
    "\n",
    "    @staticmethod\n",
    "    def generate_ponderated_output(outputs, grads):\n",
    "        \"\"\"\n",
    "        Apply Grad CAM algorithm scheme.\n",
    "        Inputs are the convolutional outputs (shape WxHxN) and gradients (shape WxHxN).\n",
    "        From there:\n",
    "            - we compute the spatial average of the gradients\n",
    "            - we build a ponderated sum of the convolutional outputs based on those averaged weights\n",
    "        Args:\n",
    "            output (tf.Tensor): Target layer outputs, with shape (batch_size, Hl, Wl, Nf),\n",
    "                where Hl and Wl are the target layer output height and width, and Nf the\n",
    "                number of filters.\n",
    "            grads (tf.Tensor): Guided gradients with shape (batch_size, Hl, Wl, Nf)\n",
    "        Returns:\n",
    "            List[tf.Tensor]: List of ponderated output of shape (batch_size, Hl, Wl, 1)\n",
    "        \"\"\"\n",
    "\n",
    "        maps = [\n",
    "            GradCAM.ponderate_output(output, grad)\n",
    "            for output, grad in zip(outputs, grads)\n",
    "        ]\n",
    "\n",
    "        return maps\n",
    "\n",
    "    @staticmethod\n",
    "    def ponderate_output(output, grad):\n",
    "        \"\"\"\n",
    "        Perform the ponderation of filters output with respect to average of gradients values.\n",
    "        Args:\n",
    "            output (tf.Tensor): Target layer outputs, with shape (Hl, Wl, Nf),\n",
    "                where Hl and Wl are the target layer output height and width, and Nf the\n",
    "                number of filters.\n",
    "            grads (tf.Tensor): Guided gradients with shape (Hl, Wl, Nf)\n",
    "        Returns:\n",
    "            tf.Tensor: Ponderated output of shape (Hl, Wl, 1)\n",
    "        \"\"\"\n",
    "        weights = tf.reduce_mean(grad, axis=(0, 1))\n",
    "\n",
    "        # Perform ponderated sum : w_i * output[:, :, i]\n",
    "        cam = tf.reduce_sum(tf.multiply(weights, output), axis=-1)\n",
    "\n",
    "        return cam\n",
    "\n",
    "    def save(self, grid, output_dir, output_name):\n",
    "        \"\"\"\n",
    "        Save the output to a specific dir.\n",
    "        Args:\n",
    "            grid (numpy.ndarray): Grid of all the heatmaps\n",
    "            output_dir (str): Output directory path\n",
    "            output_name (str): Output name\n",
    "        \"\"\"\n",
    "        save_rgb(grid, output_dir, output_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "negative  positive\r\n"
     ]
    }
   ],
   "source": [
    "!ls /opt/AIStorage/PLAYGROUND/images/512/filtered/data_filtered/train/data_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['positive', 'negative'], dtype='<U8')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_dir = '/opt/AIStorage/PLAYGROUND/images/512/filtered/data_filtered/train/data_filtered/'\n",
    "\n",
    "data_dir_path = pathlib.Path(train_data_dir)\n",
    "\n",
    "CLASS_NAMES = np.array([item.name for item in data_dir_path.glob('*')])\n",
    "\n",
    "CLASS_NAMES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8827"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "image_list = glob.glob(train_data_dir + '**/*.png', recursive=True)\n",
    "DATASET_SIZE = len(image_list)\n",
    "DATASET_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_count = int(0.8 * DATASET_SIZE)\n",
    "val_image_count = int(0.2 * DATASET_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7061"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1765"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_image_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "full_list_ds = tf.data.Dataset.from_tensor_slices(image_list)\n",
    "\n",
    "full_list_ds = full_list_ds.shuffle(buffer_size=10000)\n",
    "\n",
    "train_list_ds = full_list_ds.take(image_count)\n",
    "\n",
    "val_list_ds = full_list_ds.skip(image_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(file_path):\n",
    "    # convert the path to a list of path components\n",
    "    parts = tf.strings.split(file_path, os.path.sep)\n",
    "    # The second to last is the class-directory\n",
    "    label = -1\n",
    "    if parts[-2] == 'negative':\n",
    "        label = tf.constant([1.0, 0.0])\n",
    "    else:\n",
    "        label = tf.constant([0.0, 1.0])\n",
    "    return label\n",
    "\n",
    "def decode_img(img):\n",
    "    # convert the compressed string to a 3D uint8 tensor\n",
    "    img = tf.image.decode_png(img, channels=CHANNELS)\n",
    "    # Use `convert_image_dtype` to convert to floats in the [0,1] range.\n",
    "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "    # resize the image to the desired size.\n",
    "    return tf.image.resize(img, [IMG_WIDTH, IMG_HEIGHT])\n",
    "\n",
    "def process_path(file_path):\n",
    "    label = get_label(file_path)\n",
    "    # load the raw data from the file as a string\n",
    "    img = tf.io.read_file(file_path)\n",
    "    img = decode_img(img)\n",
    "    return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set `num_parallel_calls` so multiple images are loaded/processed in parallel.\n",
    "labeled_ds = train_list_ds.map(process_path, num_parallel_calls=AUTOTUNE)\n",
    "\n",
    "val_labeled_ds = val_list_ds.map(process_path, num_parallel_calls=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape:  (512, 512, 3)\n",
      "Label:  [0. 1.]\n",
      "Image shape:  (512, 512, 3)\n",
      "Label:  [1. 0.]\n",
      "Image shape:  (512, 512, 3)\n",
      "Label:  [0. 1.]\n",
      "Image shape:  (512, 512, 3)\n",
      "Label:  [0. 1.]\n",
      "Image shape:  (512, 512, 3)\n",
      "Label:  [0. 1.]\n"
     ]
    }
   ],
   "source": [
    "for image, label in labeled_ds.take(5):\n",
    "    print(\"Image shape: \", image.numpy().shape)\n",
    "    print(\"Label: \", label.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "STEPS_PER_EPOCH = np.ceil(image_count/BATCH_SIZE)\n",
    "VAL_STEPS_PER_EPOCH = np.ceil(val_image_count/BATCH_SIZE)\n",
    "\n",
    "def prepare_for_training(ds, shuffle=True, cache=True, shuffle_buffer_size=11000):\n",
    "    # This is a small dataset, only load it once, and keep it in memory.\n",
    "    # use `.cache(filename)` to cache preprocessing work for datasets that don't\n",
    "    # fit in memory.\n",
    "    if cache:\n",
    "        if isinstance(cache, str):\n",
    "            ds = ds.cache(cache)\n",
    "        else:\n",
    "            ds = ds.cache()\n",
    "\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(buffer_size=shuffle_buffer_size, reshuffle_each_iteration=True)\n",
    "\n",
    "    # Repeat forever\n",
    "    ds = ds.repeat()\n",
    "\n",
    "    ds = ds.batch(BATCH_SIZE)\n",
    "\n",
    "    # `prefetch` lets the dataset fetch batches in the background while the model\n",
    "    # is training.\n",
    "    ds = ds.prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "    return ds\n",
    "\n",
    "train_ds = prepare_for_training(labeled_ds)\n",
    "\n",
    "valid_ds = prepare_for_training(val_labeled_ds, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    base_model = ResNet152V2(input_shape=IMG_SHAPE,include_top=False,weights='imagenet')\n",
    "    \n",
    "    #base_model.trainable = False\n",
    "        \n",
    "    for layer in base_model.layers:\n",
    "        if layer.name.endswith('bn'):\n",
    "            layer.trainable = True\n",
    "        else:\n",
    "            layer.trainable = False\n",
    "                \n",
    "    x = base_model.output\n",
    "        \n",
    "    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "        \n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Dropout(0.30)(x)\n",
    "    x = tf.keras.layers.Dense(1024,activation='relu')(x)\n",
    "        \n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Dropout(0.4)(x)\n",
    "    predictions = tf.keras.layers.Dense(2, activation=\"sigmoid\", dtype=tf.float32)(x)\n",
    "        \n",
    "    model = Model(inputs=base_model.input,outputs=predictions)\n",
    "    \n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Arch:  DenseNet201\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 512, 512, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 518, 518, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_conv (Conv2D)             (None, 256, 256, 64) 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 258, 258, 64) 0           conv1_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pool (MaxPooling2D)       (None, 128, 128, 64) 0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_preact_bn (BatchNo (None, 128, 128, 64) 256         pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_preact_relu (Activ (None, 128, 128, 64) 0           conv2_block1_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, 128, 128, 64) 4096        conv2_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, 128, 128, 64) 256         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, 128, 128, 64) 0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_pad (ZeroPadding (None, 130, 130, 64) 0           conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, 128, 128, 64) 36864       conv2_block1_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_bn (BatchNormali (None, 128, 128, 64) 256         conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_relu (Activation (None, 128, 128, 64) 0           conv2_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_conv (Conv2D)    (None, 128, 128, 256 16640       conv2_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_conv (Conv2D)    (None, 128, 128, 256 16640       conv2_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_out (Add)          (None, 128, 128, 256 0           conv2_block1_0_conv[0][0]        \n",
      "                                                                 conv2_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_preact_bn (BatchNo (None, 128, 128, 256 1024        conv2_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_preact_relu (Activ (None, 128, 128, 256 0           conv2_block2_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, 128, 128, 64) 16384       conv2_block2_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, 128, 128, 64) 256         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, 128, 128, 64) 0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_pad (ZeroPadding (None, 130, 130, 64) 0           conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, 128, 128, 64) 36864       conv2_block2_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_bn (BatchNormali (None, 128, 128, 64) 256         conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_relu (Activation (None, 128, 128, 64) 0           conv2_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_conv (Conv2D)    (None, 128, 128, 256 16640       conv2_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_out (Add)          (None, 128, 128, 256 0           conv2_block1_out[0][0]           \n",
      "                                                                 conv2_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_preact_bn (BatchNo (None, 128, 128, 256 1024        conv2_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_preact_relu (Activ (None, 128, 128, 256 0           conv2_block3_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, 128, 128, 64) 16384       conv2_block3_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, 128, 128, 64) 256         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, 128, 128, 64) 0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_pad (ZeroPadding (None, 130, 130, 64) 0           conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, 64, 64, 64)   36864       conv2_block3_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_relu (Activation (None, 64, 64, 64)   0           conv2_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 64, 64, 256)  0           conv2_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_conv (Conv2D)    (None, 64, 64, 256)  16640       conv2_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_out (Add)          (None, 64, 64, 256)  0           max_pooling2d[0][0]              \n",
      "                                                                 conv2_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_preact_bn (BatchNo (None, 64, 64, 256)  1024        conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_preact_relu (Activ (None, 64, 64, 256)  0           conv3_block1_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, 64, 64, 128)  32768       conv3_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, 64, 64, 128)  512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, 64, 64, 128)  0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_pad (ZeroPadding (None, 66, 66, 128)  0           conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, 64, 64, 128)  147456      conv3_block1_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_bn (BatchNormali (None, 64, 64, 128)  512         conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_relu (Activation (None, 64, 64, 128)  0           conv3_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_conv (Conv2D)    (None, 64, 64, 512)  131584      conv3_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_conv (Conv2D)    (None, 64, 64, 512)  66048       conv3_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_out (Add)          (None, 64, 64, 512)  0           conv3_block1_0_conv[0][0]        \n",
      "                                                                 conv3_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_preact_bn (BatchNo (None, 64, 64, 512)  2048        conv3_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_preact_relu (Activ (None, 64, 64, 512)  0           conv3_block2_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, 64, 64, 128)  65536       conv3_block2_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, 64, 64, 128)  512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, 64, 64, 128)  0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_pad (ZeroPadding (None, 66, 66, 128)  0           conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, 64, 64, 128)  147456      conv3_block2_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_bn (BatchNormali (None, 64, 64, 128)  512         conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_relu (Activation (None, 64, 64, 128)  0           conv3_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_conv (Conv2D)    (None, 64, 64, 512)  66048       conv3_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_out (Add)          (None, 64, 64, 512)  0           conv3_block1_out[0][0]           \n",
      "                                                                 conv3_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_preact_bn (BatchNo (None, 64, 64, 512)  2048        conv3_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_preact_relu (Activ (None, 64, 64, 512)  0           conv3_block3_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, 64, 64, 128)  65536       conv3_block3_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, 64, 64, 128)  512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, 64, 64, 128)  0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_pad (ZeroPadding (None, 66, 66, 128)  0           conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, 64, 64, 128)  147456      conv3_block3_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_bn (BatchNormali (None, 64, 64, 128)  512         conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_relu (Activation (None, 64, 64, 128)  0           conv3_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_conv (Conv2D)    (None, 64, 64, 512)  66048       conv3_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_out (Add)          (None, 64, 64, 512)  0           conv3_block2_out[0][0]           \n",
      "                                                                 conv3_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_preact_bn (BatchNo (None, 64, 64, 512)  2048        conv3_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_preact_relu (Activ (None, 64, 64, 512)  0           conv3_block4_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, 64, 64, 128)  65536       conv3_block4_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, 64, 64, 128)  512         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, 64, 64, 128)  0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_pad (ZeroPadding (None, 66, 66, 128)  0           conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, 64, 64, 128)  147456      conv3_block4_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_bn (BatchNormali (None, 64, 64, 128)  512         conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_relu (Activation (None, 64, 64, 128)  0           conv3_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_conv (Conv2D)    (None, 64, 64, 512)  66048       conv3_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_out (Add)          (None, 64, 64, 512)  0           conv3_block3_out[0][0]           \n",
      "                                                                 conv3_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_preact_bn (BatchNo (None, 64, 64, 512)  2048        conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_preact_relu (Activ (None, 64, 64, 512)  0           conv3_block5_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_1_conv (Conv2D)    (None, 64, 64, 128)  65536       conv3_block5_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_1_bn (BatchNormali (None, 64, 64, 128)  512         conv3_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_1_relu (Activation (None, 64, 64, 128)  0           conv3_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_2_pad (ZeroPadding (None, 66, 66, 128)  0           conv3_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_2_conv (Conv2D)    (None, 64, 64, 128)  147456      conv3_block5_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_2_bn (BatchNormali (None, 64, 64, 128)  512         conv3_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_2_relu (Activation (None, 64, 64, 128)  0           conv3_block5_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_3_conv (Conv2D)    (None, 64, 64, 512)  66048       conv3_block5_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_out (Add)          (None, 64, 64, 512)  0           conv3_block4_out[0][0]           \n",
      "                                                                 conv3_block5_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_preact_bn (BatchNo (None, 64, 64, 512)  2048        conv3_block5_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_preact_relu (Activ (None, 64, 64, 512)  0           conv3_block6_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_1_conv (Conv2D)    (None, 64, 64, 128)  65536       conv3_block6_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_1_bn (BatchNormali (None, 64, 64, 128)  512         conv3_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_1_relu (Activation (None, 64, 64, 128)  0           conv3_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_2_pad (ZeroPadding (None, 66, 66, 128)  0           conv3_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_2_conv (Conv2D)    (None, 64, 64, 128)  147456      conv3_block6_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_2_bn (BatchNormali (None, 64, 64, 128)  512         conv3_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_2_relu (Activation (None, 64, 64, 128)  0           conv3_block6_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_3_conv (Conv2D)    (None, 64, 64, 512)  66048       conv3_block6_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_out (Add)          (None, 64, 64, 512)  0           conv3_block5_out[0][0]           \n",
      "                                                                 conv3_block6_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_preact_bn (BatchNo (None, 64, 64, 512)  2048        conv3_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_preact_relu (Activ (None, 64, 64, 512)  0           conv3_block7_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_1_conv (Conv2D)    (None, 64, 64, 128)  65536       conv3_block7_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_1_bn (BatchNormali (None, 64, 64, 128)  512         conv3_block7_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_1_relu (Activation (None, 64, 64, 128)  0           conv3_block7_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_2_pad (ZeroPadding (None, 66, 66, 128)  0           conv3_block7_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_2_conv (Conv2D)    (None, 64, 64, 128)  147456      conv3_block7_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_2_bn (BatchNormali (None, 64, 64, 128)  512         conv3_block7_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_2_relu (Activation (None, 64, 64, 128)  0           conv3_block7_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_3_conv (Conv2D)    (None, 64, 64, 512)  66048       conv3_block7_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_out (Add)          (None, 64, 64, 512)  0           conv3_block6_out[0][0]           \n",
      "                                                                 conv3_block7_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_preact_bn (BatchNo (None, 64, 64, 512)  2048        conv3_block7_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_preact_relu (Activ (None, 64, 64, 512)  0           conv3_block8_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_1_conv (Conv2D)    (None, 64, 64, 128)  65536       conv3_block8_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_1_bn (BatchNormali (None, 64, 64, 128)  512         conv3_block8_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_1_relu (Activation (None, 64, 64, 128)  0           conv3_block8_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_2_pad (ZeroPadding (None, 66, 66, 128)  0           conv3_block8_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_2_conv (Conv2D)    (None, 32, 32, 128)  147456      conv3_block8_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_2_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block8_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_2_relu (Activation (None, 32, 32, 128)  0           conv3_block8_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 32, 32, 512)  0           conv3_block7_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_3_conv (Conv2D)    (None, 32, 32, 512)  66048       conv3_block8_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_out (Add)          (None, 32, 32, 512)  0           max_pooling2d_1[0][0]            \n",
      "                                                                 conv3_block8_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_preact_bn (BatchNo (None, 32, 32, 512)  2048        conv3_block8_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_preact_relu (Activ (None, 32, 32, 512)  0           conv4_block1_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, 32, 32, 256)  131072      conv4_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, 32, 32, 256)  1024        conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, 32, 32, 256)  0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_pad (ZeroPadding (None, 34, 34, 256)  0           conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, 32, 32, 256)  589824      conv4_block1_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_bn (BatchNormali (None, 32, 32, 256)  1024        conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_relu (Activation (None, 32, 32, 256)  0           conv4_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_conv (Conv2D)    (None, 32, 32, 1024) 525312      conv4_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_conv (Conv2D)    (None, 32, 32, 1024) 263168      conv4_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_out (Add)          (None, 32, 32, 1024) 0           conv4_block1_0_conv[0][0]        \n",
      "                                                                 conv4_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_preact_bn (BatchNo (None, 32, 32, 1024) 4096        conv4_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_preact_relu (Activ (None, 32, 32, 1024) 0           conv4_block2_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, 32, 32, 256)  262144      conv4_block2_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, 32, 32, 256)  1024        conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, 32, 32, 256)  0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_pad (ZeroPadding (None, 34, 34, 256)  0           conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, 32, 32, 256)  589824      conv4_block2_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_bn (BatchNormali (None, 32, 32, 256)  1024        conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_relu (Activation (None, 32, 32, 256)  0           conv4_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_conv (Conv2D)    (None, 32, 32, 1024) 263168      conv4_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_out (Add)          (None, 32, 32, 1024) 0           conv4_block1_out[0][0]           \n",
      "                                                                 conv4_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_preact_bn (BatchNo (None, 32, 32, 1024) 4096        conv4_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_preact_relu (Activ (None, 32, 32, 1024) 0           conv4_block3_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, 32, 32, 256)  262144      conv4_block3_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, 32, 32, 256)  1024        conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, 32, 32, 256)  0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_pad (ZeroPadding (None, 34, 34, 256)  0           conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, 32, 32, 256)  589824      conv4_block3_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_bn (BatchNormali (None, 32, 32, 256)  1024        conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_relu (Activation (None, 32, 32, 256)  0           conv4_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_conv (Conv2D)    (None, 32, 32, 1024) 263168      conv4_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_out (Add)          (None, 32, 32, 1024) 0           conv4_block2_out[0][0]           \n",
      "                                                                 conv4_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_preact_bn (BatchNo (None, 32, 32, 1024) 4096        conv4_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_preact_relu (Activ (None, 32, 32, 1024) 0           conv4_block4_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, 32, 32, 256)  262144      conv4_block4_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, 32, 32, 256)  1024        conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, 32, 32, 256)  0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_pad (ZeroPadding (None, 34, 34, 256)  0           conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, 32, 32, 256)  589824      conv4_block4_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_bn (BatchNormali (None, 32, 32, 256)  1024        conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_relu (Activation (None, 32, 32, 256)  0           conv4_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_conv (Conv2D)    (None, 32, 32, 1024) 263168      conv4_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_out (Add)          (None, 32, 32, 1024) 0           conv4_block3_out[0][0]           \n",
      "                                                                 conv4_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_preact_bn (BatchNo (None, 32, 32, 1024) 4096        conv4_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_preact_relu (Activ (None, 32, 32, 1024) 0           conv4_block5_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, 32, 32, 256)  262144      conv4_block5_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, 32, 32, 256)  1024        conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, 32, 32, 256)  0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_pad (ZeroPadding (None, 34, 34, 256)  0           conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, 32, 32, 256)  589824      conv4_block5_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_bn (BatchNormali (None, 32, 32, 256)  1024        conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_relu (Activation (None, 32, 32, 256)  0           conv4_block5_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_conv (Conv2D)    (None, 32, 32, 1024) 263168      conv4_block5_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_out (Add)          (None, 32, 32, 1024) 0           conv4_block4_out[0][0]           \n",
      "                                                                 conv4_block5_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_preact_bn (BatchNo (None, 32, 32, 1024) 4096        conv4_block5_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_preact_relu (Activ (None, 32, 32, 1024) 0           conv4_block6_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, 32, 32, 256)  262144      conv4_block6_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, 32, 32, 256)  1024        conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, 32, 32, 256)  0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_pad (ZeroPadding (None, 34, 34, 256)  0           conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, 32, 32, 256)  589824      conv4_block6_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_bn (BatchNormali (None, 32, 32, 256)  1024        conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_relu (Activation (None, 32, 32, 256)  0           conv4_block6_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_conv (Conv2D)    (None, 32, 32, 1024) 263168      conv4_block6_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_out (Add)          (None, 32, 32, 1024) 0           conv4_block5_out[0][0]           \n",
      "                                                                 conv4_block6_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_preact_bn (BatchNo (None, 32, 32, 1024) 4096        conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_preact_relu (Activ (None, 32, 32, 1024) 0           conv4_block7_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_1_conv (Conv2D)    (None, 32, 32, 256)  262144      conv4_block7_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_1_bn (BatchNormali (None, 32, 32, 256)  1024        conv4_block7_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_1_relu (Activation (None, 32, 32, 256)  0           conv4_block7_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_2_pad (ZeroPadding (None, 34, 34, 256)  0           conv4_block7_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_2_conv (Conv2D)    (None, 32, 32, 256)  589824      conv4_block7_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_2_bn (BatchNormali (None, 32, 32, 256)  1024        conv4_block7_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_2_relu (Activation (None, 32, 32, 256)  0           conv4_block7_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_3_conv (Conv2D)    (None, 32, 32, 1024) 263168      conv4_block7_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_out (Add)          (None, 32, 32, 1024) 0           conv4_block6_out[0][0]           \n",
      "                                                                 conv4_block7_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_preact_bn (BatchNo (None, 32, 32, 1024) 4096        conv4_block7_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_preact_relu (Activ (None, 32, 32, 1024) 0           conv4_block8_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_conv (Conv2D)    (None, 32, 32, 256)  262144      conv4_block8_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_bn (BatchNormali (None, 32, 32, 256)  1024        conv4_block8_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_relu (Activation (None, 32, 32, 256)  0           conv4_block8_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_2_pad (ZeroPadding (None, 34, 34, 256)  0           conv4_block8_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_2_conv (Conv2D)    (None, 32, 32, 256)  589824      conv4_block8_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_2_bn (BatchNormali (None, 32, 32, 256)  1024        conv4_block8_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_2_relu (Activation (None, 32, 32, 256)  0           conv4_block8_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_3_conv (Conv2D)    (None, 32, 32, 1024) 263168      conv4_block8_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_out (Add)          (None, 32, 32, 1024) 0           conv4_block7_out[0][0]           \n",
      "                                                                 conv4_block8_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_preact_bn (BatchNo (None, 32, 32, 1024) 4096        conv4_block8_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_preact_relu (Activ (None, 32, 32, 1024) 0           conv4_block9_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_conv (Conv2D)    (None, 32, 32, 256)  262144      conv4_block9_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_bn (BatchNormali (None, 32, 32, 256)  1024        conv4_block9_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_relu (Activation (None, 32, 32, 256)  0           conv4_block9_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_2_pad (ZeroPadding (None, 34, 34, 256)  0           conv4_block9_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_2_conv (Conv2D)    (None, 32, 32, 256)  589824      conv4_block9_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_2_bn (BatchNormali (None, 32, 32, 256)  1024        conv4_block9_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_2_relu (Activation (None, 32, 32, 256)  0           conv4_block9_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_3_conv (Conv2D)    (None, 32, 32, 1024) 263168      conv4_block9_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_out (Add)          (None, 32, 32, 1024) 0           conv4_block8_out[0][0]           \n",
      "                                                                 conv4_block9_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_preact_bn (BatchN (None, 32, 32, 1024) 4096        conv4_block9_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_preact_relu (Acti (None, 32, 32, 1024) 0           conv4_block10_preact_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_conv (Conv2D)   (None, 32, 32, 256)  262144      conv4_block10_preact_relu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_bn (BatchNormal (None, 32, 32, 256)  1024        conv4_block10_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_relu (Activatio (None, 32, 32, 256)  0           conv4_block10_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_2_pad (ZeroPaddin (None, 34, 34, 256)  0           conv4_block10_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_2_conv (Conv2D)   (None, 32, 32, 256)  589824      conv4_block10_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_2_bn (BatchNormal (None, 32, 32, 256)  1024        conv4_block10_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_2_relu (Activatio (None, 32, 32, 256)  0           conv4_block10_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_3_conv (Conv2D)   (None, 32, 32, 1024) 263168      conv4_block10_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_out (Add)         (None, 32, 32, 1024) 0           conv4_block9_out[0][0]           \n",
      "                                                                 conv4_block10_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_preact_bn (BatchN (None, 32, 32, 1024) 4096        conv4_block10_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_preact_relu (Acti (None, 32, 32, 1024) 0           conv4_block11_preact_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_1_conv (Conv2D)   (None, 32, 32, 256)  262144      conv4_block11_preact_relu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_1_bn (BatchNormal (None, 32, 32, 256)  1024        conv4_block11_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_1_relu (Activatio (None, 32, 32, 256)  0           conv4_block11_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_2_pad (ZeroPaddin (None, 34, 34, 256)  0           conv4_block11_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_2_conv (Conv2D)   (None, 32, 32, 256)  589824      conv4_block11_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_2_bn (BatchNormal (None, 32, 32, 256)  1024        conv4_block11_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_2_relu (Activatio (None, 32, 32, 256)  0           conv4_block11_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_3_conv (Conv2D)   (None, 32, 32, 1024) 263168      conv4_block11_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_out (Add)         (None, 32, 32, 1024) 0           conv4_block10_out[0][0]          \n",
      "                                                                 conv4_block11_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_preact_bn (BatchN (None, 32, 32, 1024) 4096        conv4_block11_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_preact_relu (Acti (None, 32, 32, 1024) 0           conv4_block12_preact_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_1_conv (Conv2D)   (None, 32, 32, 256)  262144      conv4_block12_preact_relu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_1_bn (BatchNormal (None, 32, 32, 256)  1024        conv4_block12_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_1_relu (Activatio (None, 32, 32, 256)  0           conv4_block12_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_2_pad (ZeroPaddin (None, 34, 34, 256)  0           conv4_block12_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_2_conv (Conv2D)   (None, 32, 32, 256)  589824      conv4_block12_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_2_bn (BatchNormal (None, 32, 32, 256)  1024        conv4_block12_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_2_relu (Activatio (None, 32, 32, 256)  0           conv4_block12_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_3_conv (Conv2D)   (None, 32, 32, 1024) 263168      conv4_block12_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_out (Add)         (None, 32, 32, 1024) 0           conv4_block11_out[0][0]          \n",
      "                                                                 conv4_block12_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_preact_bn (BatchN (None, 32, 32, 1024) 4096        conv4_block12_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_preact_relu (Acti (None, 32, 32, 1024) 0           conv4_block13_preact_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_1_conv (Conv2D)   (None, 32, 32, 256)  262144      conv4_block13_preact_relu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_1_bn (BatchNormal (None, 32, 32, 256)  1024        conv4_block13_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_1_relu (Activatio (None, 32, 32, 256)  0           conv4_block13_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_2_pad (ZeroPaddin (None, 34, 34, 256)  0           conv4_block13_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_2_conv (Conv2D)   (None, 32, 32, 256)  589824      conv4_block13_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_2_bn (BatchNormal (None, 32, 32, 256)  1024        conv4_block13_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_2_relu (Activatio (None, 32, 32, 256)  0           conv4_block13_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_3_conv (Conv2D)   (None, 32, 32, 1024) 263168      conv4_block13_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_out (Add)         (None, 32, 32, 1024) 0           conv4_block12_out[0][0]          \n",
      "                                                                 conv4_block13_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_preact_bn (BatchN (None, 32, 32, 1024) 4096        conv4_block13_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_preact_relu (Acti (None, 32, 32, 1024) 0           conv4_block14_preact_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_1_conv (Conv2D)   (None, 32, 32, 256)  262144      conv4_block14_preact_relu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_1_bn (BatchNormal (None, 32, 32, 256)  1024        conv4_block14_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_1_relu (Activatio (None, 32, 32, 256)  0           conv4_block14_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_2_pad (ZeroPaddin (None, 34, 34, 256)  0           conv4_block14_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_2_conv (Conv2D)   (None, 32, 32, 256)  589824      conv4_block14_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_2_bn (BatchNormal (None, 32, 32, 256)  1024        conv4_block14_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_2_relu (Activatio (None, 32, 32, 256)  0           conv4_block14_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_3_conv (Conv2D)   (None, 32, 32, 1024) 263168      conv4_block14_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_out (Add)         (None, 32, 32, 1024) 0           conv4_block13_out[0][0]          \n",
      "                                                                 conv4_block14_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_preact_bn (BatchN (None, 32, 32, 1024) 4096        conv4_block14_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_preact_relu (Acti (None, 32, 32, 1024) 0           conv4_block15_preact_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_1_conv (Conv2D)   (None, 32, 32, 256)  262144      conv4_block15_preact_relu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_1_bn (BatchNormal (None, 32, 32, 256)  1024        conv4_block15_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_1_relu (Activatio (None, 32, 32, 256)  0           conv4_block15_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_2_pad (ZeroPaddin (None, 34, 34, 256)  0           conv4_block15_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_2_conv (Conv2D)   (None, 32, 32, 256)  589824      conv4_block15_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_2_bn (BatchNormal (None, 32, 32, 256)  1024        conv4_block15_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_2_relu (Activatio (None, 32, 32, 256)  0           conv4_block15_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_3_conv (Conv2D)   (None, 32, 32, 1024) 263168      conv4_block15_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_out (Add)         (None, 32, 32, 1024) 0           conv4_block14_out[0][0]          \n",
      "                                                                 conv4_block15_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_preact_bn (BatchN (None, 32, 32, 1024) 4096        conv4_block15_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_preact_relu (Acti (None, 32, 32, 1024) 0           conv4_block16_preact_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_1_conv (Conv2D)   (None, 32, 32, 256)  262144      conv4_block16_preact_relu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_1_bn (BatchNormal (None, 32, 32, 256)  1024        conv4_block16_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_1_relu (Activatio (None, 32, 32, 256)  0           conv4_block16_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_2_pad (ZeroPaddin (None, 34, 34, 256)  0           conv4_block16_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_2_conv (Conv2D)   (None, 32, 32, 256)  589824      conv4_block16_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_2_bn (BatchNormal (None, 32, 32, 256)  1024        conv4_block16_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_2_relu (Activatio (None, 32, 32, 256)  0           conv4_block16_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_3_conv (Conv2D)   (None, 32, 32, 1024) 263168      conv4_block16_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_out (Add)         (None, 32, 32, 1024) 0           conv4_block15_out[0][0]          \n",
      "                                                                 conv4_block16_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_preact_bn (BatchN (None, 32, 32, 1024) 4096        conv4_block16_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_preact_relu (Acti (None, 32, 32, 1024) 0           conv4_block17_preact_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_1_conv (Conv2D)   (None, 32, 32, 256)  262144      conv4_block17_preact_relu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_1_bn (BatchNormal (None, 32, 32, 256)  1024        conv4_block17_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_1_relu (Activatio (None, 32, 32, 256)  0           conv4_block17_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_2_pad (ZeroPaddin (None, 34, 34, 256)  0           conv4_block17_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_2_conv (Conv2D)   (None, 32, 32, 256)  589824      conv4_block17_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_2_bn (BatchNormal (None, 32, 32, 256)  1024        conv4_block17_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_2_relu (Activatio (None, 32, 32, 256)  0           conv4_block17_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_3_conv (Conv2D)   (None, 32, 32, 1024) 263168      conv4_block17_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_out (Add)         (None, 32, 32, 1024) 0           conv4_block16_out[0][0]          \n",
      "                                                                 conv4_block17_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_preact_bn (BatchN (None, 32, 32, 1024) 4096        conv4_block17_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_preact_relu (Acti (None, 32, 32, 1024) 0           conv4_block18_preact_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_1_conv (Conv2D)   (None, 32, 32, 256)  262144      conv4_block18_preact_relu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_1_bn (BatchNormal (None, 32, 32, 256)  1024        conv4_block18_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_1_relu (Activatio (None, 32, 32, 256)  0           conv4_block18_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_2_pad (ZeroPaddin (None, 34, 34, 256)  0           conv4_block18_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_2_conv (Conv2D)   (None, 32, 32, 256)  589824      conv4_block18_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_2_bn (BatchNormal (None, 32, 32, 256)  1024        conv4_block18_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_2_relu (Activatio (None, 32, 32, 256)  0           conv4_block18_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_3_conv (Conv2D)   (None, 32, 32, 1024) 263168      conv4_block18_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_out (Add)         (None, 32, 32, 1024) 0           conv4_block17_out[0][0]          \n",
      "                                                                 conv4_block18_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_preact_bn (BatchN (None, 32, 32, 1024) 4096        conv4_block18_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_preact_relu (Acti (None, 32, 32, 1024) 0           conv4_block19_preact_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_1_conv (Conv2D)   (None, 32, 32, 256)  262144      conv4_block19_preact_relu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_1_bn (BatchNormal (None, 32, 32, 256)  1024        conv4_block19_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_1_relu (Activatio (None, 32, 32, 256)  0           conv4_block19_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_2_pad (ZeroPaddin (None, 34, 34, 256)  0           conv4_block19_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_2_conv (Conv2D)   (None, 32, 32, 256)  589824      conv4_block19_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_2_bn (BatchNormal (None, 32, 32, 256)  1024        conv4_block19_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_2_relu (Activatio (None, 32, 32, 256)  0           conv4_block19_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_3_conv (Conv2D)   (None, 32, 32, 1024) 263168      conv4_block19_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_out (Add)         (None, 32, 32, 1024) 0           conv4_block18_out[0][0]          \n",
      "                                                                 conv4_block19_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_preact_bn (BatchN (None, 32, 32, 1024) 4096        conv4_block19_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_preact_relu (Acti (None, 32, 32, 1024) 0           conv4_block20_preact_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_1_conv (Conv2D)   (None, 32, 32, 256)  262144      conv4_block20_preact_relu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_1_bn (BatchNormal (None, 32, 32, 256)  1024        conv4_block20_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_1_relu (Activatio (None, 32, 32, 256)  0           conv4_block20_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_2_pad (ZeroPaddin (None, 34, 34, 256)  0           conv4_block20_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_2_conv (Conv2D)   (None, 32, 32, 256)  589824      conv4_block20_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_2_bn (BatchNormal (None, 32, 32, 256)  1024        conv4_block20_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_2_relu (Activatio (None, 32, 32, 256)  0           conv4_block20_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_3_conv (Conv2D)   (None, 32, 32, 1024) 263168      conv4_block20_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_out (Add)         (None, 32, 32, 1024) 0           conv4_block19_out[0][0]          \n",
      "                                                                 conv4_block20_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_preact_bn (BatchN (None, 32, 32, 1024) 4096        conv4_block20_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_preact_relu (Acti (None, 32, 32, 1024) 0           conv4_block21_preact_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_1_conv (Conv2D)   (None, 32, 32, 256)  262144      conv4_block21_preact_relu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_1_bn (BatchNormal (None, 32, 32, 256)  1024        conv4_block21_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_1_relu (Activatio (None, 32, 32, 256)  0           conv4_block21_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_2_pad (ZeroPaddin (None, 34, 34, 256)  0           conv4_block21_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_2_conv (Conv2D)   (None, 32, 32, 256)  589824      conv4_block21_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_2_bn (BatchNormal (None, 32, 32, 256)  1024        conv4_block21_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_2_relu (Activatio (None, 32, 32, 256)  0           conv4_block21_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_3_conv (Conv2D)   (None, 32, 32, 1024) 263168      conv4_block21_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_out (Add)         (None, 32, 32, 1024) 0           conv4_block20_out[0][0]          \n",
      "                                                                 conv4_block21_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_preact_bn (BatchN (None, 32, 32, 1024) 4096        conv4_block21_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_preact_relu (Acti (None, 32, 32, 1024) 0           conv4_block22_preact_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_1_conv (Conv2D)   (None, 32, 32, 256)  262144      conv4_block22_preact_relu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_1_bn (BatchNormal (None, 32, 32, 256)  1024        conv4_block22_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_1_relu (Activatio (None, 32, 32, 256)  0           conv4_block22_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_2_pad (ZeroPaddin (None, 34, 34, 256)  0           conv4_block22_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_2_conv (Conv2D)   (None, 32, 32, 256)  589824      conv4_block22_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_2_bn (BatchNormal (None, 32, 32, 256)  1024        conv4_block22_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_2_relu (Activatio (None, 32, 32, 256)  0           conv4_block22_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_3_conv (Conv2D)   (None, 32, 32, 1024) 263168      conv4_block22_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_out (Add)         (None, 32, 32, 1024) 0           conv4_block21_out[0][0]          \n",
      "                                                                 conv4_block22_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_preact_bn (BatchN (None, 32, 32, 1024) 4096        conv4_block22_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_preact_relu (Acti (None, 32, 32, 1024) 0           conv4_block23_preact_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_1_conv (Conv2D)   (None, 32, 32, 256)  262144      conv4_block23_preact_relu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_1_bn (BatchNormal (None, 32, 32, 256)  1024        conv4_block23_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_1_relu (Activatio (None, 32, 32, 256)  0           conv4_block23_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_2_pad (ZeroPaddin (None, 34, 34, 256)  0           conv4_block23_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_2_conv (Conv2D)   (None, 32, 32, 256)  589824      conv4_block23_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_2_bn (BatchNormal (None, 32, 32, 256)  1024        conv4_block23_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_2_relu (Activatio (None, 32, 32, 256)  0           conv4_block23_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_3_conv (Conv2D)   (None, 32, 32, 1024) 263168      conv4_block23_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_out (Add)         (None, 32, 32, 1024) 0           conv4_block22_out[0][0]          \n",
      "                                                                 conv4_block23_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_preact_bn (BatchN (None, 32, 32, 1024) 4096        conv4_block23_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_preact_relu (Acti (None, 32, 32, 1024) 0           conv4_block24_preact_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_1_conv (Conv2D)   (None, 32, 32, 256)  262144      conv4_block24_preact_relu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_1_bn (BatchNormal (None, 32, 32, 256)  1024        conv4_block24_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_1_relu (Activatio (None, 32, 32, 256)  0           conv4_block24_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_2_pad (ZeroPaddin (None, 34, 34, 256)  0           conv4_block24_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_2_conv (Conv2D)   (None, 32, 32, 256)  589824      conv4_block24_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_2_bn (BatchNormal (None, 32, 32, 256)  1024        conv4_block24_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_2_relu (Activatio (None, 32, 32, 256)  0           conv4_block24_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_3_conv (Conv2D)   (None, 32, 32, 1024) 263168      conv4_block24_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_out (Add)         (None, 32, 32, 1024) 0           conv4_block23_out[0][0]          \n",
      "                                                                 conv4_block24_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block25_preact_bn (BatchN (None, 32, 32, 1024) 4096        conv4_block24_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block25_preact_relu (Acti (None, 32, 32, 1024) 0           conv4_block25_preact_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block25_1_conv (Conv2D)   (None, 32, 32, 256)  262144      conv4_block25_preact_relu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block25_1_bn (BatchNormal (None, 32, 32, 256)  1024        conv4_block25_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block25_1_relu (Activatio (None, 32, 32, 256)  0           conv4_block25_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block25_2_pad (ZeroPaddin (None, 34, 34, 256)  0           conv4_block25_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block25_2_conv (Conv2D)   (None, 32, 32, 256)  589824      conv4_block25_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block25_2_bn (BatchNormal (None, 32, 32, 256)  1024        conv4_block25_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block25_2_relu (Activatio (None, 32, 32, 256)  0           conv4_block25_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block25_3_conv (Conv2D)   (None, 32, 32, 1024) 263168      conv4_block25_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block25_out (Add)         (None, 32, 32, 1024) 0           conv4_block24_out[0][0]          \n",
      "                                                                 conv4_block25_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block26_preact_bn (BatchN (None, 32, 32, 1024) 4096        conv4_block25_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block26_preact_relu (Acti (None, 32, 32, 1024) 0           conv4_block26_preact_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block26_1_conv (Conv2D)   (None, 32, 32, 256)  262144      conv4_block26_preact_relu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block26_1_bn (BatchNormal (None, 32, 32, 256)  1024        conv4_block26_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block26_1_relu (Activatio (None, 32, 32, 256)  0           conv4_block26_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block26_2_pad (ZeroPaddin (None, 34, 34, 256)  0           conv4_block26_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block26_2_conv (Conv2D)   (None, 32, 32, 256)  589824      conv4_block26_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block26_2_bn (BatchNormal (None, 32, 32, 256)  1024        conv4_block26_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block26_2_relu (Activatio (None, 32, 32, 256)  0           conv4_block26_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block26_3_conv (Conv2D)   (None, 32, 32, 1024) 263168      conv4_block26_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block26_out (Add)         (None, 32, 32, 1024) 0           conv4_block25_out[0][0]          \n",
      "                                                                 conv4_block26_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block27_preact_bn (BatchN (None, 32, 32, 1024) 4096        conv4_block26_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block27_preact_relu (Acti (None, 32, 32, 1024) 0           conv4_block27_preact_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block27_1_conv (Conv2D)   (None, 32, 32, 256)  262144      conv4_block27_preact_relu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block27_1_bn (BatchNormal (None, 32, 32, 256)  1024        conv4_block27_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block27_1_relu (Activatio (None, 32, 32, 256)  0           conv4_block27_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block27_2_pad (ZeroPaddin (None, 34, 34, 256)  0           conv4_block27_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block27_2_conv (Conv2D)   (None, 32, 32, 256)  589824      conv4_block27_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block27_2_bn (BatchNormal (None, 32, 32, 256)  1024        conv4_block27_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block27_2_relu (Activatio (None, 32, 32, 256)  0           conv4_block27_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block27_3_conv (Conv2D)   (None, 32, 32, 1024) 263168      conv4_block27_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block27_out (Add)         (None, 32, 32, 1024) 0           conv4_block26_out[0][0]          \n",
      "                                                                 conv4_block27_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block28_preact_bn (BatchN (None, 32, 32, 1024) 4096        conv4_block27_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block28_preact_relu (Acti (None, 32, 32, 1024) 0           conv4_block28_preact_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block28_1_conv (Conv2D)   (None, 32, 32, 256)  262144      conv4_block28_preact_relu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block28_1_bn (BatchNormal (None, 32, 32, 256)  1024        conv4_block28_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block28_1_relu (Activatio (None, 32, 32, 256)  0           conv4_block28_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block28_2_pad (ZeroPaddin (None, 34, 34, 256)  0           conv4_block28_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block28_2_conv (Conv2D)   (None, 32, 32, 256)  589824      conv4_block28_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block28_2_bn (BatchNormal (None, 32, 32, 256)  1024        conv4_block28_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block28_2_relu (Activatio (None, 32, 32, 256)  0           conv4_block28_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block28_3_conv (Conv2D)   (None, 32, 32, 1024) 263168      conv4_block28_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block28_out (Add)         (None, 32, 32, 1024) 0           conv4_block27_out[0][0]          \n",
      "                                                                 conv4_block28_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block29_preact_bn (BatchN (None, 32, 32, 1024) 4096        conv4_block28_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block29_preact_relu (Acti (None, 32, 32, 1024) 0           conv4_block29_preact_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block29_1_conv (Conv2D)   (None, 32, 32, 256)  262144      conv4_block29_preact_relu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block29_1_bn (BatchNormal (None, 32, 32, 256)  1024        conv4_block29_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block29_1_relu (Activatio (None, 32, 32, 256)  0           conv4_block29_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block29_2_pad (ZeroPaddin (None, 34, 34, 256)  0           conv4_block29_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block29_2_conv (Conv2D)   (None, 32, 32, 256)  589824      conv4_block29_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block29_2_bn (BatchNormal (None, 32, 32, 256)  1024        conv4_block29_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block29_2_relu (Activatio (None, 32, 32, 256)  0           conv4_block29_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block29_3_conv (Conv2D)   (None, 32, 32, 1024) 263168      conv4_block29_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block29_out (Add)         (None, 32, 32, 1024) 0           conv4_block28_out[0][0]          \n",
      "                                                                 conv4_block29_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block30_preact_bn (BatchN (None, 32, 32, 1024) 4096        conv4_block29_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block30_preact_relu (Acti (None, 32, 32, 1024) 0           conv4_block30_preact_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block30_1_conv (Conv2D)   (None, 32, 32, 256)  262144      conv4_block30_preact_relu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block30_1_bn (BatchNormal (None, 32, 32, 256)  1024        conv4_block30_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block30_1_relu (Activatio (None, 32, 32, 256)  0           conv4_block30_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block30_2_pad (ZeroPaddin (None, 34, 34, 256)  0           conv4_block30_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block30_2_conv (Conv2D)   (None, 32, 32, 256)  589824      conv4_block30_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block30_2_bn (BatchNormal (None, 32, 32, 256)  1024        conv4_block30_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block30_2_relu (Activatio (None, 32, 32, 256)  0           conv4_block30_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block30_3_conv (Conv2D)   (None, 32, 32, 1024) 263168      conv4_block30_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block30_out (Add)         (None, 32, 32, 1024) 0           conv4_block29_out[0][0]          \n",
      "                                                                 conv4_block30_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block31_preact_bn (BatchN (None, 32, 32, 1024) 4096        conv4_block30_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block31_preact_relu (Acti (None, 32, 32, 1024) 0           conv4_block31_preact_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block31_1_conv (Conv2D)   (None, 32, 32, 256)  262144      conv4_block31_preact_relu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block31_1_bn (BatchNormal (None, 32, 32, 256)  1024        conv4_block31_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block31_1_relu (Activatio (None, 32, 32, 256)  0           conv4_block31_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block31_2_pad (ZeroPaddin (None, 34, 34, 256)  0           conv4_block31_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block31_2_conv (Conv2D)   (None, 32, 32, 256)  589824      conv4_block31_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block31_2_bn (BatchNormal (None, 32, 32, 256)  1024        conv4_block31_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block31_2_relu (Activatio (None, 32, 32, 256)  0           conv4_block31_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block31_3_conv (Conv2D)   (None, 32, 32, 1024) 263168      conv4_block31_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block31_out (Add)         (None, 32, 32, 1024) 0           conv4_block30_out[0][0]          \n",
      "                                                                 conv4_block31_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block32_preact_bn (BatchN (None, 32, 32, 1024) 4096        conv4_block31_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block32_preact_relu (Acti (None, 32, 32, 1024) 0           conv4_block32_preact_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block32_1_conv (Conv2D)   (None, 32, 32, 256)  262144      conv4_block32_preact_relu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block32_1_bn (BatchNormal (None, 32, 32, 256)  1024        conv4_block32_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block32_1_relu (Activatio (None, 32, 32, 256)  0           conv4_block32_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block32_2_pad (ZeroPaddin (None, 34, 34, 256)  0           conv4_block32_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block32_2_conv (Conv2D)   (None, 32, 32, 256)  589824      conv4_block32_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block32_2_bn (BatchNormal (None, 32, 32, 256)  1024        conv4_block32_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block32_2_relu (Activatio (None, 32, 32, 256)  0           conv4_block32_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block32_3_conv (Conv2D)   (None, 32, 32, 1024) 263168      conv4_block32_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block32_out (Add)         (None, 32, 32, 1024) 0           conv4_block31_out[0][0]          \n",
      "                                                                 conv4_block32_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block33_preact_bn (BatchN (None, 32, 32, 1024) 4096        conv4_block32_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block33_preact_relu (Acti (None, 32, 32, 1024) 0           conv4_block33_preact_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block33_1_conv (Conv2D)   (None, 32, 32, 256)  262144      conv4_block33_preact_relu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block33_1_bn (BatchNormal (None, 32, 32, 256)  1024        conv4_block33_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block33_1_relu (Activatio (None, 32, 32, 256)  0           conv4_block33_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block33_2_pad (ZeroPaddin (None, 34, 34, 256)  0           conv4_block33_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block33_2_conv (Conv2D)   (None, 32, 32, 256)  589824      conv4_block33_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block33_2_bn (BatchNormal (None, 32, 32, 256)  1024        conv4_block33_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block33_2_relu (Activatio (None, 32, 32, 256)  0           conv4_block33_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block33_3_conv (Conv2D)   (None, 32, 32, 1024) 263168      conv4_block33_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block33_out (Add)         (None, 32, 32, 1024) 0           conv4_block32_out[0][0]          \n",
      "                                                                 conv4_block33_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block34_preact_bn (BatchN (None, 32, 32, 1024) 4096        conv4_block33_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block34_preact_relu (Acti (None, 32, 32, 1024) 0           conv4_block34_preact_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block34_1_conv (Conv2D)   (None, 32, 32, 256)  262144      conv4_block34_preact_relu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block34_1_bn (BatchNormal (None, 32, 32, 256)  1024        conv4_block34_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block34_1_relu (Activatio (None, 32, 32, 256)  0           conv4_block34_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block34_2_pad (ZeroPaddin (None, 34, 34, 256)  0           conv4_block34_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block34_2_conv (Conv2D)   (None, 32, 32, 256)  589824      conv4_block34_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block34_2_bn (BatchNormal (None, 32, 32, 256)  1024        conv4_block34_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block34_2_relu (Activatio (None, 32, 32, 256)  0           conv4_block34_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block34_3_conv (Conv2D)   (None, 32, 32, 1024) 263168      conv4_block34_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block34_out (Add)         (None, 32, 32, 1024) 0           conv4_block33_out[0][0]          \n",
      "                                                                 conv4_block34_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block35_preact_bn (BatchN (None, 32, 32, 1024) 4096        conv4_block34_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block35_preact_relu (Acti (None, 32, 32, 1024) 0           conv4_block35_preact_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block35_1_conv (Conv2D)   (None, 32, 32, 256)  262144      conv4_block35_preact_relu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block35_1_bn (BatchNormal (None, 32, 32, 256)  1024        conv4_block35_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block35_1_relu (Activatio (None, 32, 32, 256)  0           conv4_block35_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block35_2_pad (ZeroPaddin (None, 34, 34, 256)  0           conv4_block35_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block35_2_conv (Conv2D)   (None, 32, 32, 256)  589824      conv4_block35_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block35_2_bn (BatchNormal (None, 32, 32, 256)  1024        conv4_block35_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block35_2_relu (Activatio (None, 32, 32, 256)  0           conv4_block35_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block35_3_conv (Conv2D)   (None, 32, 32, 1024) 263168      conv4_block35_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block35_out (Add)         (None, 32, 32, 1024) 0           conv4_block34_out[0][0]          \n",
      "                                                                 conv4_block35_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block36_preact_bn (BatchN (None, 32, 32, 1024) 4096        conv4_block35_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block36_preact_relu (Acti (None, 32, 32, 1024) 0           conv4_block36_preact_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block36_1_conv (Conv2D)   (None, 32, 32, 256)  262144      conv4_block36_preact_relu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block36_1_bn (BatchNormal (None, 32, 32, 256)  1024        conv4_block36_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block36_1_relu (Activatio (None, 32, 32, 256)  0           conv4_block36_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block36_2_pad (ZeroPaddin (None, 34, 34, 256)  0           conv4_block36_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block36_2_conv (Conv2D)   (None, 16, 16, 256)  589824      conv4_block36_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block36_2_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block36_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block36_2_relu (Activatio (None, 16, 16, 256)  0           conv4_block36_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 16, 16, 1024) 0           conv4_block35_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block36_3_conv (Conv2D)   (None, 16, 16, 1024) 263168      conv4_block36_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block36_out (Add)         (None, 16, 16, 1024) 0           max_pooling2d_2[0][0]            \n",
      "                                                                 conv4_block36_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_preact_bn (BatchNo (None, 16, 16, 1024) 4096        conv4_block36_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_preact_relu (Activ (None, 16, 16, 1024) 0           conv5_block1_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, 16, 16, 512)  524288      conv5_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, 16, 16, 512)  2048        conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, 16, 16, 512)  0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_pad (ZeroPadding (None, 18, 18, 512)  0           conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, 16, 16, 512)  2359296     conv5_block1_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_bn (BatchNormali (None, 16, 16, 512)  2048        conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_relu (Activation (None, 16, 16, 512)  0           conv5_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_conv (Conv2D)    (None, 16, 16, 2048) 2099200     conv5_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_conv (Conv2D)    (None, 16, 16, 2048) 1050624     conv5_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_out (Add)          (None, 16, 16, 2048) 0           conv5_block1_0_conv[0][0]        \n",
      "                                                                 conv5_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_preact_bn (BatchNo (None, 16, 16, 2048) 8192        conv5_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_preact_relu (Activ (None, 16, 16, 2048) 0           conv5_block2_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, 16, 16, 512)  1048576     conv5_block2_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, 16, 16, 512)  2048        conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, 16, 16, 512)  0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_pad (ZeroPadding (None, 18, 18, 512)  0           conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, 16, 16, 512)  2359296     conv5_block2_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_bn (BatchNormali (None, 16, 16, 512)  2048        conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_relu (Activation (None, 16, 16, 512)  0           conv5_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_conv (Conv2D)    (None, 16, 16, 2048) 1050624     conv5_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_out (Add)          (None, 16, 16, 2048) 0           conv5_block1_out[0][0]           \n",
      "                                                                 conv5_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_preact_bn (BatchNo (None, 16, 16, 2048) 8192        conv5_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_preact_relu (Activ (None, 16, 16, 2048) 0           conv5_block3_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, 16, 16, 512)  1048576     conv5_block3_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, 16, 16, 512)  2048        conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation (None, 16, 16, 512)  0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_pad (ZeroPadding (None, 18, 18, 512)  0           conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)    (None, 16, 16, 512)  2359296     conv5_block3_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_bn (BatchNormali (None, 16, 16, 512)  2048        conv5_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_relu (Activation (None, 16, 16, 512)  0           conv5_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_conv (Conv2D)    (None, 16, 16, 2048) 1050624     conv5_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_out (Add)          (None, 16, 16, 2048) 0           conv5_block2_out[0][0]           \n",
      "                                                                 conv5_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "post_bn (BatchNormalization)    (None, 16, 16, 2048) 8192        conv5_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "post_relu (Activation)          (None, 16, 16, 2048) 0           post_bn[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d (Globa (None, 2048)         0           post_relu[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 2048)         8192        global_average_pooling2d[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 2048)         0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1024)         2098176     dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 1024)         4096        dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 1024)         0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 2)            2050        dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 60,444,162\n",
      "Trainable params: 2,250,114\n",
      "Non-trainable params: 58,194,048\n",
      "__________________________________________________________________________________________________\n",
      "Train for 442.0 steps, validate for 111.0 steps\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "442/442 [==============================] - 299s 675ms/step - loss: 0.6006 - acc: 0.7596 - val_loss: 0.3390 - val_acc: 0.8606\n",
      "Epoch 2/20\n",
      "442/442 [==============================] - 278s 629ms/step - loss: 0.3419 - acc: 0.8598 - val_loss: 0.2724 - val_acc: 0.8913\n",
      "Epoch 3/20\n",
      "442/442 [==============================] - 278s 630ms/step - loss: 0.2664 - acc: 0.8948 - val_loss: 0.1535 - val_acc: 0.9355\n",
      "Epoch 4/20\n",
      "442/442 [==============================] - 279s 631ms/step - loss: 0.2089 - acc: 0.9177 - val_loss: 0.1263 - val_acc: 0.9519\n",
      "Epoch 5/20\n",
      "442/442 [==============================] - 279s 632ms/step - loss: 0.1693 - acc: 0.9389 - val_loss: 0.1885 - val_acc: 0.9206\n",
      "Epoch 6/20\n",
      "442/442 [==============================] - 279s 632ms/step - loss: 0.1450 - acc: 0.9446 - val_loss: 0.1761 - val_acc: 0.9448\n",
      "Epoch 7/20\n",
      "442/442 [==============================] - 279s 631ms/step - loss: 0.1251 - acc: 0.9561 - val_loss: 0.0921 - val_acc: 0.9702\n",
      "Epoch 8/20\n",
      "442/442 [==============================] - 277s 628ms/step - loss: 0.1159 - acc: 0.9562 - val_loss: 0.1061 - val_acc: 0.9733\n",
      "Epoch 9/20\n",
      "442/442 [==============================] - 279s 630ms/step - loss: 0.0901 - acc: 0.9680 - val_loss: 0.0953 - val_acc: 0.9685\n",
      "Epoch 10/20\n",
      "442/442 [==============================] - 279s 632ms/step - loss: 0.0763 - acc: 0.9736 - val_loss: 0.0959 - val_acc: 0.9702\n",
      "Epoch 11/20\n",
      "442/442 [==============================] - 279s 631ms/step - loss: 0.0822 - acc: 0.9700 - val_loss: 0.0879 - val_acc: 0.9718\n",
      "Epoch 12/20\n",
      "442/442 [==============================] - 279s 632ms/step - loss: 0.0658 - acc: 0.9754 - val_loss: 0.1007 - val_acc: 0.9724\n",
      "Epoch 13/20\n",
      "442/442 [==============================] - 279s 632ms/step - loss: 0.0601 - acc: 0.9782 - val_loss: 0.1633 - val_acc: 0.9499\n",
      "Epoch 14/20\n",
      "442/442 [==============================] - 279s 631ms/step - loss: 0.0652 - acc: 0.9782 - val_loss: 0.0829 - val_acc: 0.9775\n",
      "Epoch 15/20\n",
      "442/442 [==============================] - 279s 632ms/step - loss: 0.0533 - acc: 0.9820 - val_loss: 0.0958 - val_acc: 0.9735\n",
      "Epoch 16/20\n",
      "442/442 [==============================] - 279s 632ms/step - loss: 0.0754 - acc: 0.9727 - val_loss: 0.0879 - val_acc: 0.9792\n",
      "Epoch 17/20\n",
      "442/442 [==============================] - 279s 630ms/step - loss: 0.0509 - acc: 0.9806 - val_loss: 0.1013 - val_acc: 0.9707\n",
      "Epoch 18/20\n",
      "442/442 [==============================] - 278s 629ms/step - loss: 0.0486 - acc: 0.9820 - val_loss: 0.1613 - val_acc: 0.9673\n",
      "Epoch 19/20\n",
      "442/442 [==============================] - 279s 630ms/step - loss: 0.0544 - acc: 0.9813 - val_loss: 0.0975 - val_acc: 0.9747\n",
      "Epoch 20/20\n",
      "442/442 [==============================] - 279s 630ms/step - loss: 0.0479 - acc: 0.9838 - val_loss: 0.0928 - val_acc: 0.9764\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "    \n",
    "#policy = mixed_precision.Policy('mixed_float16')\n",
    "#mixed_precision.set_policy(policy)\n",
    "print(\"\")\n",
    "print(\"Arch: \", \"DenseNet201\")\n",
    "    \n",
    "steps = np.ceil(image_count / BATCH_SIZE) * EPOCHS\n",
    "\n",
    "#optimizer = tf.keras.optimizers.SGD(lr=lr)\n",
    "    \n",
    "#optimizer = tf.keras.optimizers.RMSprop(lr=lr)\n",
    "optimizer = tf.keras.optimizers.Adam(lr=lr)\n",
    "    \n",
    "'''\n",
    "base_model = DenseNet201(input_shape=IMG_SHAPE,include_top=False,weights='imagenet')\n",
    "    \n",
    "#base_model.trainable = False\n",
    "        \n",
    "for layer in base_model.layers:\n",
    "    if layer.name.endswith('bn'):\n",
    "        layer.trainable = True\n",
    "    else:\n",
    "        layer.trainable = False\n",
    "                \n",
    "x = base_model.output\n",
    "        \n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "        \n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Dropout(0.30)(x)\n",
    "x = tf.keras.layers.Dense(1024,activation='relu')(x)\n",
    "        \n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.Dropout(0.4)(x)\n",
    "predictions = tf.keras.layers.Dense(2, activation=\"sigmoid\", dtype=tf.float32)(x)\n",
    "        \n",
    "model = Model(inputs=base_model.input,outputs=predictions)\n",
    "'''\n",
    "\n",
    "model = create_model()\n",
    "\n",
    "model.summary()\n",
    "        \n",
    "        \n",
    "model.compile(optimizer=optimizer,loss=tf.keras.losses.BinaryCrossentropy(from_logits=False),metrics=['acc'])\n",
    "    \n",
    "history = model.fit(train_ds,\n",
    "                    epochs=EPOCHS,\n",
    "                    validation_data=valid_ds, \n",
    "                    steps_per_epoch=STEPS_PER_EPOCH, \n",
    "                    validation_steps=VAL_STEPS_PER_EPOCH,\n",
    "                    callbacks=[])\n",
    "        \n",
    "        \n",
    "        \n",
    "print(\"\")\n",
    "print(\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!mkdir -p saved_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('saved_model/my_model_weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy = mixed_precision.Policy('float32')\n",
    "mixed_precision.set_policy(policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_model = create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7fc18474ac10>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saved_model.load_weights('saved_model/my_model_weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "post_relu\n"
     ]
    }
   ],
   "source": [
    "#IMAGE_PATH = '/opt/AIStorage/PLAYGROUND/images/512/filtered/data_filtered/train/data_filtered/positive/2.25.29063837649503765322829207716135903912.png'\n",
    "#IMAGE_PATH = '/opt/AIStorage/PLAYGROUND/images/512/positive/2.25.293051404113555009465480448588513430295.png'\n",
    "IMAGE_PATH = '/opt/AIStorage/PLAYGROUND/images/512/positive/2.25.181219916381488720424316063428743387152.png'\n",
    "img = tf.keras.preprocessing.image.load_img(IMAGE_PATH, target_size=(512, 512))\n",
    "img = tf.keras.preprocessing.image.img_to_array(img)\n",
    "img = img/255.0\n",
    "        \n",
    "data = ([img], None)\n",
    "\n",
    "index = 1\n",
    "explainer = GradCAM()\n",
    "        \n",
    "saved_model.trainable = True\n",
    "        \n",
    "#layer ='conv2_block1_1_conv'\n",
    "#layer ='conv5_block32_2_conv'\n",
    "    \n",
    "grid = explainer.explain(data, saved_model, class_index=index, image_weight=0.95)\n",
    "    \n",
    "explainer.save(grid, \".\", \"grad_cam10_17.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2.1-conda",
   "language": "python",
   "name": "tf2.1-conda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
