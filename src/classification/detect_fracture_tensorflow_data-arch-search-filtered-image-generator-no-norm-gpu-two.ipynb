{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models, Model\n",
    "from tensorflow.keras.mixed_precision import experimental as mixed_precision\n",
    "import pandas as pd\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "\n",
    "import IPython.display as display\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pathlib\n",
    "\n",
    "import tensorflow.keras.applications\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import cv2\n",
    "\n",
    "import math\n",
    "import warnings\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from tensorflow.keras.applications import DenseNet121,DenseNet169,  \\\n",
    "                                          DenseNet201,InceptionResNetV2,  \\\n",
    "                                          InceptionV3,MobileNet,MobileNetV2,  \\\n",
    "                                          NASNetLarge,NASNetMobile,ResNet101,  \\\n",
    "                                          ResNet101V2,ResNet152,ResNet152V2,  \\\n",
    "                                          ResNet50,ResNet50V2,VGG16,VGG19,Xception \n",
    "\n",
    "from tensorflow.keras.metrics import Accuracy, Precision, Recall, \\\n",
    "                                     FalsePositives, FalsePositives, \\\n",
    "                                     TruePositives, TrueNegatives\n",
    "\n",
    "\n",
    "BATCH_SIZE = 8\n",
    "IMG_HEIGHT = 512\n",
    "IMG_WIDTH = 512\n",
    "EPOCHS = 25\n",
    "lr = 1e-3\n",
    "CHANNELS =3\n",
    "IMG_SHAPE = (IMG_HEIGHT, IMG_WIDTH, CHANNELS)\n",
    "\n",
    "FILTER_SIZE = 3\n",
    "\n",
    "lrs = [('6e-4',6e-4), ('1e-3',1e-3), ('6e-3',6e-3)]\n",
    "batch_sizes = [('8',8),('16',16)]\n",
    "optimizers = [('Adam', tf.keras.optimizers.Adam()), \n",
    "              ('Nadam', tf.keras.optimizers.Nadam()), \n",
    "              ('SGD', tf.keras.optimizers.SGD()),\n",
    "              ('RMSprop',tf.keras.optimizers.RMSprop())]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "\n",
    "tf.config.experimental.set_visible_devices(gpus[1], 'GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#policy = mixed_precision.Policy('mixed_float16')\n",
    "#mixed_precision.set_policy(policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Module for Image Save\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def save_grayscale(image, output_dir, output_name):\n",
    "    \"\"\"\n",
    "    Save a 3D Numpy array (H, W, 1) as an image.\n",
    "    Args:\n",
    "        image (numpy.ndarray): Image to save\n",
    "        output_dir (str): Output directory\n",
    "        output_name (str): Output name\n",
    "    \"\"\"\n",
    "    Path.mkdir(Path(output_dir), parents=True, exist_ok=True)\n",
    "\n",
    "    cv2.imwrite(str(Path(output_dir) / output_name), image)\n",
    "\n",
    "\n",
    "def save_rgb(image, output_dir, output_name):\n",
    "    \"\"\"\n",
    "    Save a 3D Numpy array (H, W, 3) as an image.\n",
    "    Args:\n",
    "        image (numpy.ndarray): Image to save\n",
    "        output_dir (str): Output directory\n",
    "        output_name (str): Output name\n",
    "    \"\"\"\n",
    "    Path.mkdir(Path(output_dir), parents=True, exist_ok=True)\n",
    "\n",
    "    cv2.imwrite(\n",
    "        str(Path(output_dir) / output_name), cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def grid_display(array, num_rows=None, num_columns=None):\n",
    "    \"\"\"\n",
    "    Display a list of images as a grid.\n",
    "    Args:\n",
    "        array (numpy.ndarray): 4D Tensor (batch_size, height, width, channels)\n",
    "    Returns:\n",
    "        numpy.ndarray: 3D Tensor as concatenation of input images on a grid\n",
    "    \"\"\"\n",
    "    if num_rows is not None and num_columns is not None:\n",
    "        total_grid_size = num_rows * num_columns\n",
    "        if total_grid_size < len(array):\n",
    "            warnings.warn(\n",
    "                Warning(\n",
    "                    \"Given values for num_rows and num_columns doesn't allow to display \"\n",
    "                    \"all images. Values have been overrided to respect at least num_columns\"\n",
    "                )\n",
    "            )\n",
    "            num_rows = math.ceil(len(array) / num_columns)\n",
    "    elif num_rows is not None:\n",
    "        num_columns = math.ceil(len(array) / num_rows)\n",
    "    elif num_columns is not None:\n",
    "        num_rows = math.ceil(len(array) / num_columns)\n",
    "    else:\n",
    "        num_rows = math.ceil(math.sqrt(len(array)))\n",
    "        num_columns = math.ceil(math.sqrt(len(array)))\n",
    "\n",
    "    number_of_missing_elements = num_columns * num_rows - len(array)\n",
    "    # We fill the array with np.zeros elements to obtain a perfect square\n",
    "    array = np.append(\n",
    "        array,\n",
    "        np.zeros((number_of_missing_elements, *array[0].shape)).astype(array.dtype),\n",
    "        axis=0,\n",
    "    )\n",
    "\n",
    "    grid = np.concatenate(\n",
    "        [\n",
    "            np.concatenate(\n",
    "                array[index * num_columns : (index + 1) * num_columns], axis=1\n",
    "            )\n",
    "            for index in range(num_rows)\n",
    "        ],\n",
    "        axis=0,\n",
    "    )\n",
    "\n",
    "    return grid\n",
    "\n",
    "\n",
    "def filter_display(array, num_rows=None, num_columns=None):\n",
    "    \"\"\"\n",
    "    Display a list of filter outputs as a greyscale images grid.\n",
    "    Args:\n",
    "        array (numpy.ndarray): 4D Tensor (batch_size, height, width, channels)\n",
    "    Returns:\n",
    "        numpy.ndarray: 3D Tensor as concatenation of input images on a grid\n",
    "    \"\"\"\n",
    "    return grid_display(\n",
    "        np.concatenate(np.rollaxis(array, 3, 1), axis=0), num_rows, num_columns\n",
    "    )\n",
    "\n",
    "\n",
    "def image_to_uint_255(image):\n",
    "    \"\"\"\n",
    "    Convert float images to int 0-255 images.\n",
    "    Args:\n",
    "        image (numpy.ndarray): Input image. Can be either [0, 255], [0, 1], [-1, 1]\n",
    "    Returns:\n",
    "        numpy.ndarray:\n",
    "    \"\"\"\n",
    "    if image.dtype == np.uint8:\n",
    "        return image\n",
    "\n",
    "    if image.min() < 0:\n",
    "        image = (image + 1.0) / 2.0\n",
    "\n",
    "    return (image * 255).astype(\"uint8\")\n",
    "\n",
    "\n",
    "def heatmap_display(\n",
    "    heatmap, original_image, colormap=cv2.COLORMAP_VIRIDIS, image_weight=0.7\n",
    "):\n",
    "    \"\"\"\n",
    "    Apply a heatmap (as an np.ndarray) on top of an original image.\n",
    "    Args:\n",
    "        heatmap (numpy.ndarray): Array corresponding to the heatmap\n",
    "        original_image (numpy.ndarray): Image on which we apply the heatmap\n",
    "        colormap (int): OpenCV Colormap to use for heatmap visualization\n",
    "        image_weight (float): An optional `float` value in range [0,1] indicating the weight of\n",
    "            the input image to be overlaying the calculated attribution maps. Defaults to `0.7`\n",
    "    Returns:\n",
    "        np.ndarray: Original image with heatmap applied\n",
    "    \"\"\"\n",
    "    heatmap = cv2.resize(heatmap, (original_image.shape[1], original_image.shape[0]))\n",
    "\n",
    "    image = image_to_uint_255(original_image)\n",
    "\n",
    "    heatmap = (heatmap - np.min(heatmap)) / (heatmap.max() - heatmap.min())\n",
    "\n",
    "    heatmap = cv2.applyColorMap(\n",
    "        cv2.cvtColor((heatmap * 255).astype(\"uint8\"), cv2.COLOR_GRAY2BGR), colormap\n",
    "    )\n",
    "\n",
    "    output = cv2.addWeighted(\n",
    "        cv2.cvtColor(image, cv2.COLOR_RGB2BGR), image_weight, heatmap, 1, 0\n",
    "    )\n",
    "\n",
    "    return cv2.cvtColor(output, cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Core Module for Grad CAM Algorithm\n",
    "\"\"\"\n",
    "\n",
    "class GradCAM:\n",
    "\n",
    "    \"\"\"\n",
    "    Perform Grad CAM algorithm for a given input\n",
    "    Paper: [Grad-CAM: Visual Explanations from Deep Networks\n",
    "            via Gradient-based Localization](https://arxiv.org/abs/1610.02391)\n",
    "    \"\"\"\n",
    "\n",
    "    def explain(\n",
    "        self,\n",
    "        validation_data,\n",
    "        model,\n",
    "        class_index,\n",
    "        layer_name=None,\n",
    "        colormap=cv2.COLORMAP_VIRIDIS,\n",
    "        image_weight=0.7,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Compute GradCAM for a specific class index.\n",
    "        Args:\n",
    "            validation_data (Tuple[np.ndarray, Optional[np.ndarray]]): Validation data\n",
    "                to perform the method on. Tuple containing (x, y).\n",
    "            model (tf.keras.Model): tf.keras model to inspect\n",
    "            class_index (int): Index of targeted class\n",
    "            layer_name (str): Targeted layer for GradCAM. If no layer is provided, it is\n",
    "                automatically infered from the model architecture.\n",
    "            colormap (int): OpenCV Colormap to use for heatmap visualization\n",
    "            image_weight (float): An optional `float` value in range [0,1] indicating the weight of\n",
    "                the input image to be overlaying the calculated attribution maps. Defaults to `0.7`.\n",
    "        Returns:\n",
    "            numpy.ndarray: Grid of all the GradCAM\n",
    "        \"\"\"\n",
    "        images, _ = validation_data\n",
    "\n",
    "        if layer_name is None:\n",
    "            layer_name = self.infer_grad_cam_target_layer(model)\n",
    "\n",
    "        outputs, guided_grads = GradCAM.get_gradients_and_filters(\n",
    "            model, images, layer_name, class_index\n",
    "        )\n",
    "\n",
    "        cams = GradCAM.generate_ponderated_output(outputs, guided_grads)\n",
    "\n",
    "        heatmaps = np.array(\n",
    "            [\n",
    "                # not showing the actual image if image_weight=0\n",
    "                heatmap_display(cam.numpy(), image, colormap, image_weight)\n",
    "                for cam, image in zip(cams, images)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        grid = grid_display(heatmaps)\n",
    "\n",
    "        return grid\n",
    "\n",
    "    @staticmethod\n",
    "    def infer_grad_cam_target_layer(model):\n",
    "        \"\"\"\n",
    "        Search for the last convolutional layer to perform Grad CAM, as stated\n",
    "        in the original paper.\n",
    "        Args:\n",
    "            model (tf.keras.Model): tf.keras model to inspect\n",
    "        Returns:\n",
    "            str: Name of the target layer\n",
    "        \"\"\"\n",
    "        for layer in reversed(model.layers):\n",
    "            # Select closest 4D layer to the end of the network.\n",
    "            if len(layer.output_shape) == 4:\n",
    "                print(layer.name)\n",
    "                return layer.name\n",
    "\n",
    "        raise ValueError(\n",
    "            \"Model does not seem to contain 4D layer. Grad CAM cannot be applied.\"\n",
    "        )\n",
    "\n",
    "    @staticmethod\n",
    "    @tf.function\n",
    "    def get_gradients_and_filters(model, images, layer_name, class_index):\n",
    "        \"\"\"\n",
    "        Generate guided gradients and convolutional outputs with an inference.\n",
    "        Args:\n",
    "            model (tf.keras.Model): tf.keras model to inspect\n",
    "            images (numpy.ndarray): 4D-Tensor with shape (batch_size, H, W, 3)\n",
    "            layer_name (str): Targeted layer for GradCAM\n",
    "            class_index (int): Index of targeted class\n",
    "        Returns:\n",
    "            Tuple[tf.Tensor, tf.Tensor]: (Target layer outputs, Guided gradients)\n",
    "        \"\"\"\n",
    "        grad_model = tf.keras.models.Model(\n",
    "            [model.inputs], [model.get_layer(layer_name).output, model.output]\n",
    "        )\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            inputs = tf.cast(images, tf.float32)\n",
    "            conv_outputs, predictions = grad_model(inputs)\n",
    "            loss = predictions[:, class_index]\n",
    "\n",
    "        grads = tape.gradient(loss, conv_outputs)\n",
    "\n",
    "        guided_grads = (\n",
    "            tf.cast(conv_outputs > 0, \"float32\") * tf.cast(grads > 0, \"float32\") * grads\n",
    "        )\n",
    "\n",
    "        return conv_outputs, guided_grads\n",
    "\n",
    "    @staticmethod\n",
    "    def generate_ponderated_output(outputs, grads):\n",
    "        \"\"\"\n",
    "        Apply Grad CAM algorithm scheme.\n",
    "        Inputs are the convolutional outputs (shape WxHxN) and gradients (shape WxHxN).\n",
    "        From there:\n",
    "            - we compute the spatial average of the gradients\n",
    "            - we build a ponderated sum of the convolutional outputs based on those averaged weights\n",
    "        Args:\n",
    "            output (tf.Tensor): Target layer outputs, with shape (batch_size, Hl, Wl, Nf),\n",
    "                where Hl and Wl are the target layer output height and width, and Nf the\n",
    "                number of filters.\n",
    "            grads (tf.Tensor): Guided gradients with shape (batch_size, Hl, Wl, Nf)\n",
    "        Returns:\n",
    "            List[tf.Tensor]: List of ponderated output of shape (batch_size, Hl, Wl, 1)\n",
    "        \"\"\"\n",
    "\n",
    "        maps = [\n",
    "            GradCAM.ponderate_output(output, grad)\n",
    "            for output, grad in zip(outputs, grads)\n",
    "        ]\n",
    "\n",
    "        return maps\n",
    "\n",
    "    @staticmethod\n",
    "    def ponderate_output(output, grad):\n",
    "        \"\"\"\n",
    "        Perform the ponderation of filters output with respect to average of gradients values.\n",
    "        Args:\n",
    "            output (tf.Tensor): Target layer outputs, with shape (Hl, Wl, Nf),\n",
    "                where Hl and Wl are the target layer output height and width, and Nf the\n",
    "                number of filters.\n",
    "            grads (tf.Tensor): Guided gradients with shape (Hl, Wl, Nf)\n",
    "        Returns:\n",
    "            tf.Tensor: Ponderated output of shape (Hl, Wl, 1)\n",
    "        \"\"\"\n",
    "        weights = tf.reduce_mean(grad, axis=(0, 1))\n",
    "\n",
    "        # Perform ponderated sum : w_i * output[:, :, i]\n",
    "        cam = tf.reduce_sum(tf.multiply(weights, output), axis=-1)\n",
    "\n",
    "        return cam\n",
    "\n",
    "    def save(self, grid, output_dir, output_name):\n",
    "        \"\"\"\n",
    "        Save the output to a specific dir.\n",
    "        Args:\n",
    "            grid (numpy.ndarray): Grid of all the heatmaps\n",
    "            output_dir (str): Output directory path\n",
    "            output_name (str): Output name\n",
    "        \"\"\"\n",
    "        save_rgb(grid, output_dir, output_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>fracture</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.25.106676839056126299978531324463554518020.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.25.319643122546098503457219076291109872435.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.25.274315312442912178046853147602337975791.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.25.220685474744735840984002265562904007370.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.25.155577563460858254065799391763762302742.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              image  fracture\n",
       "0  2.25.106676839056126299978531324463554518020.png         0\n",
       "1  2.25.319643122546098503457219076291109872435.png         0\n",
       "2  2.25.274315312442912178046853147602337975791.png         1\n",
       "3  2.25.220685474744735840984002265562904007370.png         1\n",
       "4  2.25.155577563460858254065799391763762302742.png         1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(\"./train.csv\")\n",
    "valid_df = pd.read_csv(\"./val.csv\")\n",
    "\n",
    "test_df = pd.read_csv(\"./test.csv\")\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['fracture']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_generator(df, image_dir, x_col, y_cols, shuffle=True, batch_size=8, seed=1, target_w = 512, target_h = 512):\n",
    "    \"\"\"\n",
    "    Return generator for training set, normalizing using batch\n",
    "    statistics.\n",
    "\n",
    "    Args:\n",
    "      train_df (dataframe): dataframe specifying training data.\n",
    "      image_dir (str): directory where image files are held.\n",
    "      x_col (str): name of column in df that holds filenames.\n",
    "      y_cols (list): list of strings that hold y labels for images.\n",
    "      sample_size (int): size of sample to use for normalization statistics.\n",
    "      batch_size (int): images per batch to be fed into model during training.\n",
    "      seed (int): random seed.\n",
    "      target_w (int): final width of input images.\n",
    "      target_h (int): final height of input images.\n",
    "    \n",
    "    Returns:\n",
    "        train_generator (DataFrameIterator): iterator over training set\n",
    "    \"\"\"        \n",
    "    print(\"getting train generator...\") \n",
    "    # normalize images\n",
    "    image_generator = ImageDataGenerator(\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=True,\n",
    "        rotation_range=180,\n",
    "        height_shift_range=[-10,10],\n",
    "        width_shift_range=[-10,10],\n",
    "        rescale=1./255)\n",
    "    \n",
    "    # flow from directory with specified batch size\n",
    "    # and target image size\n",
    "    generator = image_generator.flow_from_dataframe(\n",
    "            dataframe=df,\n",
    "            directory=image_dir,\n",
    "            x_col=x_col,\n",
    "            y_col=y_cols,\n",
    "            class_mode=\"raw\",\n",
    "            batch_size=batch_size,\n",
    "            shuffle=shuffle,\n",
    "            seed=seed,\n",
    "            target_size=(target_w,target_h))\n",
    "    \n",
    "    return generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_and_valid_generator(valid_df, test_df, train_df, image_dir, x_col, y_cols, sample_size=2000, batch_size=8, seed=1, target_w = 512, target_h = 512):\n",
    "    \"\"\"\n",
    "    Return generator for validation set and test test set using \n",
    "    normalization statistics from training set.\n",
    "\n",
    "    Args:\n",
    "      valid_df (dataframe): dataframe specifying validation data.\n",
    "      test_df (dataframe): dataframe specifying test data.\n",
    "      train_df (dataframe): dataframe specifying training data.\n",
    "      image_dir (str): directory where image files are held.\n",
    "      x_col (str): name of column in df that holds filenames.\n",
    "      y_cols (list): list of strings that hold y labels for images.\n",
    "      sample_size (int): size of sample to use for normalization statistics.\n",
    "      batch_size (int): images per batch to be fed into model during training.\n",
    "      seed (int): random seed.\n",
    "      target_w (int): final width of input images.\n",
    "      target_h (int): final height of input images.\n",
    "    \n",
    "    Returns:\n",
    "        test_generator (DataFrameIterator) and valid_generator: iterators over test set and validation set respectively\n",
    "    \"\"\"\n",
    "    print(\"getting test and valid generators...\")\n",
    "    \n",
    "\n",
    "    # use sample to fit mean and std for test set generator\n",
    "    image_generator = ImageDataGenerator(\n",
    "       rescale=1./255)\n",
    "    \n",
    "    \n",
    "\n",
    "    # get test generator\n",
    "    valid_generator = image_generator.flow_from_dataframe(\n",
    "            dataframe=valid_df,\n",
    "            directory=image_dir,\n",
    "            x_col=x_col,\n",
    "            y_col=y_cols,\n",
    "            class_mode=\"raw\",\n",
    "            batch_size=batch_size,\n",
    "            shuffle=False,\n",
    "            seed=seed,\n",
    "            target_size=(target_w,target_h))\n",
    "\n",
    "    test_generator = image_generator.flow_from_dataframe(\n",
    "            dataframe=test_df,\n",
    "            directory=image_dir,\n",
    "            x_col=x_col,\n",
    "            y_col=y_cols,\n",
    "            class_mode=\"raw\",\n",
    "            batch_size=batch_size,\n",
    "            shuffle=False,\n",
    "            seed=seed,\n",
    "            target_size=(target_w,target_h))\n",
    "    return valid_generator, test_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting train generator...\n",
      "Found 7063 validated image filenames.\n",
      "getting test and valid generators...\n",
      "Found 882 validated image filenames.\n",
      "Found 882 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "IMAGE_DIR = \"/opt/AIStorage/PLAYGROUND/images/512/filtered/all_images\"\n",
    "train_generator = get_train_generator(train_df, IMAGE_DIR, \"image\", labels)\n",
    "valid_generator, test_generator= get_test_and_valid_generator(valid_df, test_df, train_df, IMAGE_DIR, \"image\", labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x, y = train_generator.__getitem__(0)\n",
    "plt.imshow(x[0]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    base_model = ResNet152V2(input_shape=IMG_SHAPE,include_top=False,weights='imagenet')\n",
    "    \n",
    "    #base_model.trainable = False\n",
    "        \n",
    "    for layer in base_model.layers:\n",
    "        if layer.name.endswith('bn'):\n",
    "            layer.trainable = True\n",
    "        else:\n",
    "            layer.trainable = False\n",
    "                \n",
    "    x = base_model.output\n",
    "        \n",
    "    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "        \n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Dropout(0.4)(x)\n",
    "    x = tf.keras.layers.Dense(512,activation='relu')(x)\n",
    "        \n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Dropout(0.5)(x)\n",
    "    predictions = tf.keras.layers.Dense(2, activation=\"sigmoid\", dtype=tf.float32)(x)\n",
    "        \n",
    "    model = Model(inputs=base_model.input,outputs=predictions)\n",
    "    \n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Arch:  ResNet152V2\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 512, 512, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 518, 518, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_conv (Conv2D)             (None, 256, 256, 64) 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 258, 258, 64) 0           conv1_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pool (MaxPooling2D)       (None, 128, 128, 64) 0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_preact_bn (BatchNo (None, 128, 128, 64) 256         pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_preact_relu (Activ (None, 128, 128, 64) 0           conv2_block1_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, 128, 128, 64) 4096        conv2_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, 128, 128, 64) 256         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, 128, 128, 64) 0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_pad (ZeroPadding (None, 130, 130, 64) 0           conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, 128, 128, 64) 36864       conv2_block1_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_bn (BatchNormali (None, 128, 128, 64) 256         conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_relu (Activation (None, 128, 128, 64) 0           conv2_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_conv (Conv2D)    (None, 128, 128, 256 16640       conv2_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_conv (Conv2D)    (None, 128, 128, 256 16640       conv2_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_out (Add)          (None, 128, 128, 256 0           conv2_block1_0_conv[0][0]        \n",
      "                                                                 conv2_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_preact_bn (BatchNo (None, 128, 128, 256 1024        conv2_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_preact_relu (Activ (None, 128, 128, 256 0           conv2_block2_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, 128, 128, 64) 16384       conv2_block2_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, 128, 128, 64) 256         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, 128, 128, 64) 0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_pad (ZeroPadding (None, 130, 130, 64) 0           conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, 128, 128, 64) 36864       conv2_block2_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_bn (BatchNormali (None, 128, 128, 64) 256         conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_relu (Activation (None, 128, 128, 64) 0           conv2_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_conv (Conv2D)    (None, 128, 128, 256 16640       conv2_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_out (Add)          (None, 128, 128, 256 0           conv2_block1_out[0][0]           \n",
      "                                                                 conv2_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_preact_bn (BatchNo (None, 128, 128, 256 1024        conv2_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_preact_relu (Activ (None, 128, 128, 256 0           conv2_block3_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, 128, 128, 64) 16384       conv2_block3_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, 128, 128, 64) 256         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, 128, 128, 64) 0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_pad (ZeroPadding (None, 130, 130, 64) 0           conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, 64, 64, 64)   36864       conv2_block3_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_relu (Activation (None, 64, 64, 64)   0           conv2_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 64, 64, 256)  0           conv2_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_conv (Conv2D)    (None, 64, 64, 256)  16640       conv2_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_out (Add)          (None, 64, 64, 256)  0           max_pooling2d[0][0]              \n",
      "                                                                 conv2_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_preact_bn (BatchNo (None, 64, 64, 256)  1024        conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_preact_relu (Activ (None, 64, 64, 256)  0           conv3_block1_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, 64, 64, 128)  32768       conv3_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, 64, 64, 128)  512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, 64, 64, 128)  0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_pad (ZeroPadding (None, 66, 66, 128)  0           conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, 64, 64, 128)  147456      conv3_block1_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_bn (BatchNormali (None, 64, 64, 128)  512         conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_relu (Activation (None, 64, 64, 128)  0           conv3_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_conv (Conv2D)    (None, 64, 64, 512)  131584      conv3_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_conv (Conv2D)    (None, 64, 64, 512)  66048       conv3_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_out (Add)          (None, 64, 64, 512)  0           conv3_block1_0_conv[0][0]        \n",
      "                                                                 conv3_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_preact_bn (BatchNo (None, 64, 64, 512)  2048        conv3_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_preact_relu (Activ (None, 64, 64, 512)  0           conv3_block2_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, 64, 64, 128)  65536       conv3_block2_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, 64, 64, 128)  512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, 64, 64, 128)  0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_pad (ZeroPadding (None, 66, 66, 128)  0           conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, 64, 64, 128)  147456      conv3_block2_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_bn (BatchNormali (None, 64, 64, 128)  512         conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_relu (Activation (None, 64, 64, 128)  0           conv3_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_conv (Conv2D)    (None, 64, 64, 512)  66048       conv3_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_out (Add)          (None, 64, 64, 512)  0           conv3_block1_out[0][0]           \n",
      "                                                                 conv3_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_preact_bn (BatchNo (None, 64, 64, 512)  2048        conv3_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_preact_relu (Activ (None, 64, 64, 512)  0           conv3_block3_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, 64, 64, 128)  65536       conv3_block3_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, 64, 64, 128)  512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, 64, 64, 128)  0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_pad (ZeroPadding (None, 66, 66, 128)  0           conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, 64, 64, 128)  147456      conv3_block3_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_bn (BatchNormali (None, 64, 64, 128)  512         conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_relu (Activation (None, 64, 64, 128)  0           conv3_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_conv (Conv2D)    (None, 64, 64, 512)  66048       conv3_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_out (Add)          (None, 64, 64, 512)  0           conv3_block2_out[0][0]           \n",
      "                                                                 conv3_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_preact_bn (BatchNo (None, 64, 64, 512)  2048        conv3_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_preact_relu (Activ (None, 64, 64, 512)  0           conv3_block4_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, 64, 64, 128)  65536       conv3_block4_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, 64, 64, 128)  512         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, 64, 64, 128)  0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_pad (ZeroPadding (None, 66, 66, 128)  0           conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, 64, 64, 128)  147456      conv3_block4_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_bn (BatchNormali (None, 64, 64, 128)  512         conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_relu (Activation (None, 64, 64, 128)  0           conv3_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_conv (Conv2D)    (None, 64, 64, 512)  66048       conv3_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_out (Add)          (None, 64, 64, 512)  0           conv3_block3_out[0][0]           \n",
      "                                                                 conv3_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_preact_bn (BatchNo (None, 64, 64, 512)  2048        conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_preact_relu (Activ (None, 64, 64, 512)  0           conv3_block5_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_1_conv (Conv2D)    (None, 64, 64, 128)  65536       conv3_block5_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_1_bn (BatchNormali (None, 64, 64, 128)  512         conv3_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_1_relu (Activation (None, 64, 64, 128)  0           conv3_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_2_pad (ZeroPadding (None, 66, 66, 128)  0           conv3_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_2_conv (Conv2D)    (None, 64, 64, 128)  147456      conv3_block5_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_2_bn (BatchNormali (None, 64, 64, 128)  512         conv3_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_2_relu (Activation (None, 64, 64, 128)  0           conv3_block5_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_3_conv (Conv2D)    (None, 64, 64, 512)  66048       conv3_block5_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_out (Add)          (None, 64, 64, 512)  0           conv3_block4_out[0][0]           \n",
      "                                                                 conv3_block5_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_preact_bn (BatchNo (None, 64, 64, 512)  2048        conv3_block5_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_preact_relu (Activ (None, 64, 64, 512)  0           conv3_block6_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_1_conv (Conv2D)    (None, 64, 64, 128)  65536       conv3_block6_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_1_bn (BatchNormali (None, 64, 64, 128)  512         conv3_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_1_relu (Activation (None, 64, 64, 128)  0           conv3_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_2_pad (ZeroPadding (None, 66, 66, 128)  0           conv3_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_2_conv (Conv2D)    (None, 64, 64, 128)  147456      conv3_block6_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_2_bn (BatchNormali (None, 64, 64, 128)  512         conv3_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_2_relu (Activation (None, 64, 64, 128)  0           conv3_block6_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_3_conv (Conv2D)    (None, 64, 64, 512)  66048       conv3_block6_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_out (Add)          (None, 64, 64, 512)  0           conv3_block5_out[0][0]           \n",
      "                                                                 conv3_block6_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_preact_bn (BatchNo (None, 64, 64, 512)  2048        conv3_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_preact_relu (Activ (None, 64, 64, 512)  0           conv3_block7_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_1_conv (Conv2D)    (None, 64, 64, 128)  65536       conv3_block7_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_1_bn (BatchNormali (None, 64, 64, 128)  512         conv3_block7_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_1_relu (Activation (None, 64, 64, 128)  0           conv3_block7_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_2_pad (ZeroPadding (None, 66, 66, 128)  0           conv3_block7_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_2_conv (Conv2D)    (None, 64, 64, 128)  147456      conv3_block7_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_2_bn (BatchNormali (None, 64, 64, 128)  512         conv3_block7_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_2_relu (Activation (None, 64, 64, 128)  0           conv3_block7_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_3_conv (Conv2D)    (None, 64, 64, 512)  66048       conv3_block7_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_out (Add)          (None, 64, 64, 512)  0           conv3_block6_out[0][0]           \n",
      "                                                                 conv3_block7_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_preact_bn (BatchNo (None, 64, 64, 512)  2048        conv3_block7_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_preact_relu (Activ (None, 64, 64, 512)  0           conv3_block8_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_1_conv (Conv2D)    (None, 64, 64, 128)  65536       conv3_block8_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_1_bn (BatchNormali (None, 64, 64, 128)  512         conv3_block8_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_1_relu (Activation (None, 64, 64, 128)  0           conv3_block8_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_2_pad (ZeroPadding (None, 66, 66, 128)  0           conv3_block8_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_2_conv (Conv2D)    (None, 32, 32, 128)  147456      conv3_block8_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_2_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block8_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_2_relu (Activation (None, 32, 32, 128)  0           conv3_block8_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 32, 32, 512)  0           conv3_block7_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_3_conv (Conv2D)    (None, 32, 32, 512)  66048       conv3_block8_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_out (Add)          (None, 32, 32, 512)  0           max_pooling2d_1[0][0]            \n",
      "                                                                 conv3_block8_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_preact_bn (BatchNo (None, 32, 32, 512)  2048        conv3_block8_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_preact_relu (Activ (None, 32, 32, 512)  0           conv4_block1_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, 32, 32, 256)  131072      conv4_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, 32, 32, 256)  1024        conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, 32, 32, 256)  0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_pad (ZeroPadding (None, 34, 34, 256)  0           conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, 32, 32, 256)  589824      conv4_block1_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_bn (BatchNormali (None, 32, 32, 256)  1024        conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_relu (Activation (None, 32, 32, 256)  0           conv4_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_conv (Conv2D)    (None, 32, 32, 1024) 525312      conv4_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_conv (Conv2D)    (None, 32, 32, 1024) 263168      conv4_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_out (Add)          (None, 32, 32, 1024) 0           conv4_block1_0_conv[0][0]        \n",
      "                                                                 conv4_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_preact_bn (BatchNo (None, 32, 32, 1024) 4096        conv4_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_preact_relu (Activ (None, 32, 32, 1024) 0           conv4_block2_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, 32, 32, 256)  262144      conv4_block2_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, 32, 32, 256)  1024        conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, 32, 32, 256)  0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_pad (ZeroPadding (None, 34, 34, 256)  0           conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, 32, 32, 256)  589824      conv4_block2_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_bn (BatchNormali (None, 32, 32, 256)  1024        conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_relu (Activation (None, 32, 32, 256)  0           conv4_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_conv (Conv2D)    (None, 32, 32, 1024) 263168      conv4_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_out (Add)          (None, 32, 32, 1024) 0           conv4_block1_out[0][0]           \n",
      "                                                                 conv4_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_preact_bn (BatchNo (None, 32, 32, 1024) 4096        conv4_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_preact_relu (Activ (None, 32, 32, 1024) 0           conv4_block3_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, 32, 32, 256)  262144      conv4_block3_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, 32, 32, 256)  1024        conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, 32, 32, 256)  0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_pad (ZeroPadding (None, 34, 34, 256)  0           conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, 32, 32, 256)  589824      conv4_block3_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_bn (BatchNormali (None, 32, 32, 256)  1024        conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_relu (Activation (None, 32, 32, 256)  0           conv4_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_conv (Conv2D)    (None, 32, 32, 1024) 263168      conv4_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_out (Add)          (None, 32, 32, 1024) 0           conv4_block2_out[0][0]           \n",
      "                                                                 conv4_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_preact_bn (BatchNo (None, 32, 32, 1024) 4096        conv4_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_preact_relu (Activ (None, 32, 32, 1024) 0           conv4_block4_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, 32, 32, 256)  262144      conv4_block4_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, 32, 32, 256)  1024        conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, 32, 32, 256)  0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_pad (ZeroPadding (None, 34, 34, 256)  0           conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, 32, 32, 256)  589824      conv4_block4_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_bn (BatchNormali (None, 32, 32, 256)  1024        conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_relu (Activation (None, 32, 32, 256)  0           conv4_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_conv (Conv2D)    (None, 32, 32, 1024) 263168      conv4_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_out (Add)          (None, 32, 32, 1024) 0           conv4_block3_out[0][0]           \n",
      "                                                                 conv4_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_preact_bn (BatchNo (None, 32, 32, 1024) 4096        conv4_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_preact_relu (Activ (None, 32, 32, 1024) 0           conv4_block5_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, 32, 32, 256)  262144      conv4_block5_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, 32, 32, 256)  1024        conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, 32, 32, 256)  0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_pad (ZeroPadding (None, 34, 34, 256)  0           conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, 32, 32, 256)  589824      conv4_block5_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_bn (BatchNormali (None, 32, 32, 256)  1024        conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_relu (Activation (None, 32, 32, 256)  0           conv4_block5_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_conv (Conv2D)    (None, 32, 32, 1024) 263168      conv4_block5_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_out (Add)          (None, 32, 32, 1024) 0           conv4_block4_out[0][0]           \n",
      "                                                                 conv4_block5_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_preact_bn (BatchNo (None, 32, 32, 1024) 4096        conv4_block5_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_preact_relu (Activ (None, 32, 32, 1024) 0           conv4_block6_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, 32, 32, 256)  262144      conv4_block6_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, 32, 32, 256)  1024        conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, 32, 32, 256)  0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_pad (ZeroPadding (None, 34, 34, 256)  0           conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, 32, 32, 256)  589824      conv4_block6_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_bn (BatchNormali (None, 32, 32, 256)  1024        conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_relu (Activation (None, 32, 32, 256)  0           conv4_block6_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_conv (Conv2D)    (None, 32, 32, 1024) 263168      conv4_block6_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_out (Add)          (None, 32, 32, 1024) 0           conv4_block5_out[0][0]           \n",
      "                                                                 conv4_block6_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_preact_bn (BatchNo (None, 32, 32, 1024) 4096        conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_preact_relu (Activ (None, 32, 32, 1024) 0           conv4_block7_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_1_conv (Conv2D)    (None, 32, 32, 256)  262144      conv4_block7_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_1_bn (BatchNormali (None, 32, 32, 256)  1024        conv4_block7_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_1_relu (Activation (None, 32, 32, 256)  0           conv4_block7_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_2_pad (ZeroPadding (None, 34, 34, 256)  0           conv4_block7_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_2_conv (Conv2D)    (None, 32, 32, 256)  589824      conv4_block7_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_2_bn (BatchNormali (None, 32, 32, 256)  1024        conv4_block7_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_2_relu (Activation (None, 32, 32, 256)  0           conv4_block7_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_3_conv (Conv2D)    (None, 32, 32, 1024) 263168      conv4_block7_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_out (Add)          (None, 32, 32, 1024) 0           conv4_block6_out[0][0]           \n",
      "                                                                 conv4_block7_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_preact_bn (BatchNo (None, 32, 32, 1024) 4096        conv4_block7_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_preact_relu (Activ (None, 32, 32, 1024) 0           conv4_block8_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_conv (Conv2D)    (None, 32, 32, 256)  262144      conv4_block8_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_bn (BatchNormali (None, 32, 32, 256)  1024        conv4_block8_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_relu (Activation (None, 32, 32, 256)  0           conv4_block8_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_2_pad (ZeroPadding (None, 34, 34, 256)  0           conv4_block8_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_2_conv (Conv2D)    (None, 32, 32, 256)  589824      conv4_block8_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_2_bn (BatchNormali (None, 32, 32, 256)  1024        conv4_block8_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_2_relu (Activation (None, 32, 32, 256)  0           conv4_block8_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_3_conv (Conv2D)    (None, 32, 32, 1024) 263168      conv4_block8_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_out (Add)          (None, 32, 32, 1024) 0           conv4_block7_out[0][0]           \n",
      "                                                                 conv4_block8_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_preact_bn (BatchNo (None, 32, 32, 1024) 4096        conv4_block8_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_preact_relu (Activ (None, 32, 32, 1024) 0           conv4_block9_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_conv (Conv2D)    (None, 32, 32, 256)  262144      conv4_block9_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_bn (BatchNormali (None, 32, 32, 256)  1024        conv4_block9_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_relu (Activation (None, 32, 32, 256)  0           conv4_block9_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_2_pad (ZeroPadding (None, 34, 34, 256)  0           conv4_block9_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_2_conv (Conv2D)    (None, 32, 32, 256)  589824      conv4_block9_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_2_bn (BatchNormali (None, 32, 32, 256)  1024        conv4_block9_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_2_relu (Activation (None, 32, 32, 256)  0           conv4_block9_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_3_conv (Conv2D)    (None, 32, 32, 1024) 263168      conv4_block9_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_out (Add)          (None, 32, 32, 1024) 0           conv4_block8_out[0][0]           \n",
      "                                                                 conv4_block9_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_preact_bn (BatchN (None, 32, 32, 1024) 4096        conv4_block9_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_preact_relu (Acti (None, 32, 32, 1024) 0           conv4_block10_preact_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_conv (Conv2D)   (None, 32, 32, 256)  262144      conv4_block10_preact_relu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_bn (BatchNormal (None, 32, 32, 256)  1024        conv4_block10_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_relu (Activatio (None, 32, 32, 256)  0           conv4_block10_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_2_pad (ZeroPaddin (None, 34, 34, 256)  0           conv4_block10_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_2_conv (Conv2D)   (None, 32, 32, 256)  589824      conv4_block10_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_2_bn (BatchNormal (None, 32, 32, 256)  1024        conv4_block10_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_2_relu (Activatio (None, 32, 32, 256)  0           conv4_block10_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_3_conv (Conv2D)   (None, 32, 32, 1024) 263168      conv4_block10_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_out (Add)         (None, 32, 32, 1024) 0           conv4_block9_out[0][0]           \n",
      "                                                                 conv4_block10_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_preact_bn (BatchN (None, 32, 32, 1024) 4096        conv4_block10_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_preact_relu (Acti (None, 32, 32, 1024) 0           conv4_block11_preact_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_1_conv (Conv2D)   (None, 32, 32, 256)  262144      conv4_block11_preact_relu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_1_bn (BatchNormal (None, 32, 32, 256)  1024        conv4_block11_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_1_relu (Activatio (None, 32, 32, 256)  0           conv4_block11_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_2_pad (ZeroPaddin (None, 34, 34, 256)  0           conv4_block11_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_2_conv (Conv2D)   (None, 32, 32, 256)  589824      conv4_block11_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_2_bn (BatchNormal (None, 32, 32, 256)  1024        conv4_block11_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_2_relu (Activatio (None, 32, 32, 256)  0           conv4_block11_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_3_conv (Conv2D)   (None, 32, 32, 1024) 263168      conv4_block11_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_out (Add)         (None, 32, 32, 1024) 0           conv4_block10_out[0][0]          \n",
      "                                                                 conv4_block11_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_preact_bn (BatchN (None, 32, 32, 1024) 4096        conv4_block11_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_preact_relu (Acti (None, 32, 32, 1024) 0           conv4_block12_preact_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_1_conv (Conv2D)   (None, 32, 32, 256)  262144      conv4_block12_preact_relu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_1_bn (BatchNormal (None, 32, 32, 256)  1024        conv4_block12_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_1_relu (Activatio (None, 32, 32, 256)  0           conv4_block12_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_2_pad (ZeroPaddin (None, 34, 34, 256)  0           conv4_block12_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_2_conv (Conv2D)   (None, 32, 32, 256)  589824      conv4_block12_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_2_bn (BatchNormal (None, 32, 32, 256)  1024        conv4_block12_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_2_relu (Activatio (None, 32, 32, 256)  0           conv4_block12_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_3_conv (Conv2D)   (None, 32, 32, 1024) 263168      conv4_block12_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_out (Add)         (None, 32, 32, 1024) 0           conv4_block11_out[0][0]          \n",
      "                                                                 conv4_block12_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_preact_bn (BatchN (None, 32, 32, 1024) 4096        conv4_block12_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_preact_relu (Acti (None, 32, 32, 1024) 0           conv4_block13_preact_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_1_conv (Conv2D)   (None, 32, 32, 256)  262144      conv4_block13_preact_relu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_1_bn (BatchNormal (None, 32, 32, 256)  1024        conv4_block13_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_1_relu (Activatio (None, 32, 32, 256)  0           conv4_block13_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_2_pad (ZeroPaddin (None, 34, 34, 256)  0           conv4_block13_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_2_conv (Conv2D)   (None, 32, 32, 256)  589824      conv4_block13_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_2_bn (BatchNormal (None, 32, 32, 256)  1024        conv4_block13_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_2_relu (Activatio (None, 32, 32, 256)  0           conv4_block13_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_3_conv (Conv2D)   (None, 32, 32, 1024) 263168      conv4_block13_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_out (Add)         (None, 32, 32, 1024) 0           conv4_block12_out[0][0]          \n",
      "                                                                 conv4_block13_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_preact_bn (BatchN (None, 32, 32, 1024) 4096        conv4_block13_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_preact_relu (Acti (None, 32, 32, 1024) 0           conv4_block14_preact_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_1_conv (Conv2D)   (None, 32, 32, 256)  262144      conv4_block14_preact_relu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_1_bn (BatchNormal (None, 32, 32, 256)  1024        conv4_block14_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_1_relu (Activatio (None, 32, 32, 256)  0           conv4_block14_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_2_pad (ZeroPaddin (None, 34, 34, 256)  0           conv4_block14_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_2_conv (Conv2D)   (None, 32, 32, 256)  589824      conv4_block14_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_2_bn (BatchNormal (None, 32, 32, 256)  1024        conv4_block14_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_2_relu (Activatio (None, 32, 32, 256)  0           conv4_block14_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_3_conv (Conv2D)   (None, 32, 32, 1024) 263168      conv4_block14_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_out (Add)         (None, 32, 32, 1024) 0           conv4_block13_out[0][0]          \n",
      "                                                                 conv4_block14_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_preact_bn (BatchN (None, 32, 32, 1024) 4096        conv4_block14_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_preact_relu (Acti (None, 32, 32, 1024) 0           conv4_block15_preact_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_1_conv (Conv2D)   (None, 32, 32, 256)  262144      conv4_block15_preact_relu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_1_bn (BatchNormal (None, 32, 32, 256)  1024        conv4_block15_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_1_relu (Activatio (None, 32, 32, 256)  0           conv4_block15_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_2_pad (ZeroPaddin (None, 34, 34, 256)  0           conv4_block15_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_2_conv (Conv2D)   (None, 32, 32, 256)  589824      conv4_block15_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_2_bn (BatchNormal (None, 32, 32, 256)  1024        conv4_block15_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_2_relu (Activatio (None, 32, 32, 256)  0           conv4_block15_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_3_conv (Conv2D)   (None, 32, 32, 1024) 263168      conv4_block15_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_out (Add)         (None, 32, 32, 1024) 0           conv4_block14_out[0][0]          \n",
      "                                                                 conv4_block15_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_preact_bn (BatchN (None, 32, 32, 1024) 4096        conv4_block15_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_preact_relu (Acti (None, 32, 32, 1024) 0           conv4_block16_preact_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_1_conv (Conv2D)   (None, 32, 32, 256)  262144      conv4_block16_preact_relu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_1_bn (BatchNormal (None, 32, 32, 256)  1024        conv4_block16_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_1_relu (Activatio (None, 32, 32, 256)  0           conv4_block16_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_2_pad (ZeroPaddin (None, 34, 34, 256)  0           conv4_block16_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_2_conv (Conv2D)   (None, 32, 32, 256)  589824      conv4_block16_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_2_bn (BatchNormal (None, 32, 32, 256)  1024        conv4_block16_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_2_relu (Activatio (None, 32, 32, 256)  0           conv4_block16_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_3_conv (Conv2D)   (None, 32, 32, 1024) 263168      conv4_block16_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_out (Add)         (None, 32, 32, 1024) 0           conv4_block15_out[0][0]          \n",
      "                                                                 conv4_block16_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_preact_bn (BatchN (None, 32, 32, 1024) 4096        conv4_block16_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_preact_relu (Acti (None, 32, 32, 1024) 0           conv4_block17_preact_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_1_conv (Conv2D)   (None, 32, 32, 256)  262144      conv4_block17_preact_relu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_1_bn (BatchNormal (None, 32, 32, 256)  1024        conv4_block17_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_1_relu (Activatio (None, 32, 32, 256)  0           conv4_block17_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_2_pad (ZeroPaddin (None, 34, 34, 256)  0           conv4_block17_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_2_conv (Conv2D)   (None, 32, 32, 256)  589824      conv4_block17_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_2_bn (BatchNormal (None, 32, 32, 256)  1024        conv4_block17_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_2_relu (Activatio (None, 32, 32, 256)  0           conv4_block17_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_3_conv (Conv2D)   (None, 32, 32, 1024) 263168      conv4_block17_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_out (Add)         (None, 32, 32, 1024) 0           conv4_block16_out[0][0]          \n",
      "                                                                 conv4_block17_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_preact_bn (BatchN (None, 32, 32, 1024) 4096        conv4_block17_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_preact_relu (Acti (None, 32, 32, 1024) 0           conv4_block18_preact_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_1_conv (Conv2D)   (None, 32, 32, 256)  262144      conv4_block18_preact_relu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_1_bn (BatchNormal (None, 32, 32, 256)  1024        conv4_block18_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_1_relu (Activatio (None, 32, 32, 256)  0           conv4_block18_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_2_pad (ZeroPaddin (None, 34, 34, 256)  0           conv4_block18_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_2_conv (Conv2D)   (None, 32, 32, 256)  589824      conv4_block18_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_2_bn (BatchNormal (None, 32, 32, 256)  1024        conv4_block18_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_2_relu (Activatio (None, 32, 32, 256)  0           conv4_block18_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_3_conv (Conv2D)   (None, 32, 32, 1024) 263168      conv4_block18_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_out (Add)         (None, 32, 32, 1024) 0           conv4_block17_out[0][0]          \n",
      "                                                                 conv4_block18_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_preact_bn (BatchN (None, 32, 32, 1024) 4096        conv4_block18_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_preact_relu (Acti (None, 32, 32, 1024) 0           conv4_block19_preact_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_1_conv (Conv2D)   (None, 32, 32, 256)  262144      conv4_block19_preact_relu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_1_bn (BatchNormal (None, 32, 32, 256)  1024        conv4_block19_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_1_relu (Activatio (None, 32, 32, 256)  0           conv4_block19_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_2_pad (ZeroPaddin (None, 34, 34, 256)  0           conv4_block19_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_2_conv (Conv2D)   (None, 32, 32, 256)  589824      conv4_block19_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_2_bn (BatchNormal (None, 32, 32, 256)  1024        conv4_block19_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_2_relu (Activatio (None, 32, 32, 256)  0           conv4_block19_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_3_conv (Conv2D)   (None, 32, 32, 1024) 263168      conv4_block19_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_out (Add)         (None, 32, 32, 1024) 0           conv4_block18_out[0][0]          \n",
      "                                                                 conv4_block19_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_preact_bn (BatchN (None, 32, 32, 1024) 4096        conv4_block19_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_preact_relu (Acti (None, 32, 32, 1024) 0           conv4_block20_preact_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_1_conv (Conv2D)   (None, 32, 32, 256)  262144      conv4_block20_preact_relu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_1_bn (BatchNormal (None, 32, 32, 256)  1024        conv4_block20_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_1_relu (Activatio (None, 32, 32, 256)  0           conv4_block20_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_2_pad (ZeroPaddin (None, 34, 34, 256)  0           conv4_block20_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_2_conv (Conv2D)   (None, 32, 32, 256)  589824      conv4_block20_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_2_bn (BatchNormal (None, 32, 32, 256)  1024        conv4_block20_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_2_relu (Activatio (None, 32, 32, 256)  0           conv4_block20_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_3_conv (Conv2D)   (None, 32, 32, 1024) 263168      conv4_block20_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_out (Add)         (None, 32, 32, 1024) 0           conv4_block19_out[0][0]          \n",
      "                                                                 conv4_block20_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_preact_bn (BatchN (None, 32, 32, 1024) 4096        conv4_block20_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_preact_relu (Acti (None, 32, 32, 1024) 0           conv4_block21_preact_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_1_conv (Conv2D)   (None, 32, 32, 256)  262144      conv4_block21_preact_relu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_1_bn (BatchNormal (None, 32, 32, 256)  1024        conv4_block21_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_1_relu (Activatio (None, 32, 32, 256)  0           conv4_block21_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_2_pad (ZeroPaddin (None, 34, 34, 256)  0           conv4_block21_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_2_conv (Conv2D)   (None, 32, 32, 256)  589824      conv4_block21_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_2_bn (BatchNormal (None, 32, 32, 256)  1024        conv4_block21_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_2_relu (Activatio (None, 32, 32, 256)  0           conv4_block21_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_3_conv (Conv2D)   (None, 32, 32, 1024) 263168      conv4_block21_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_out (Add)         (None, 32, 32, 1024) 0           conv4_block20_out[0][0]          \n",
      "                                                                 conv4_block21_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_preact_bn (BatchN (None, 32, 32, 1024) 4096        conv4_block21_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_preact_relu (Acti (None, 32, 32, 1024) 0           conv4_block22_preact_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_1_conv (Conv2D)   (None, 32, 32, 256)  262144      conv4_block22_preact_relu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_1_bn (BatchNormal (None, 32, 32, 256)  1024        conv4_block22_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_1_relu (Activatio (None, 32, 32, 256)  0           conv4_block22_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_2_pad (ZeroPaddin (None, 34, 34, 256)  0           conv4_block22_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_2_conv (Conv2D)   (None, 32, 32, 256)  589824      conv4_block22_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_2_bn (BatchNormal (None, 32, 32, 256)  1024        conv4_block22_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_2_relu (Activatio (None, 32, 32, 256)  0           conv4_block22_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_3_conv (Conv2D)   (None, 32, 32, 1024) 263168      conv4_block22_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_out (Add)         (None, 32, 32, 1024) 0           conv4_block21_out[0][0]          \n",
      "                                                                 conv4_block22_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_preact_bn (BatchN (None, 32, 32, 1024) 4096        conv4_block22_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_preact_relu (Acti (None, 32, 32, 1024) 0           conv4_block23_preact_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_1_conv (Conv2D)   (None, 32, 32, 256)  262144      conv4_block23_preact_relu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_1_bn (BatchNormal (None, 32, 32, 256)  1024        conv4_block23_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_1_relu (Activatio (None, 32, 32, 256)  0           conv4_block23_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_2_pad (ZeroPaddin (None, 34, 34, 256)  0           conv4_block23_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_2_conv (Conv2D)   (None, 32, 32, 256)  589824      conv4_block23_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_2_bn (BatchNormal (None, 32, 32, 256)  1024        conv4_block23_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_2_relu (Activatio (None, 32, 32, 256)  0           conv4_block23_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_3_conv (Conv2D)   (None, 32, 32, 1024) 263168      conv4_block23_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_out (Add)         (None, 32, 32, 1024) 0           conv4_block22_out[0][0]          \n",
      "                                                                 conv4_block23_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_preact_bn (BatchN (None, 32, 32, 1024) 4096        conv4_block23_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_preact_relu (Acti (None, 32, 32, 1024) 0           conv4_block24_preact_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_1_conv (Conv2D)   (None, 32, 32, 256)  262144      conv4_block24_preact_relu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_1_bn (BatchNormal (None, 32, 32, 256)  1024        conv4_block24_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_1_relu (Activatio (None, 32, 32, 256)  0           conv4_block24_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_2_pad (ZeroPaddin (None, 34, 34, 256)  0           conv4_block24_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_2_conv (Conv2D)   (None, 32, 32, 256)  589824      conv4_block24_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_2_bn (BatchNormal (None, 32, 32, 256)  1024        conv4_block24_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_2_relu (Activatio (None, 32, 32, 256)  0           conv4_block24_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_3_conv (Conv2D)   (None, 32, 32, 1024) 263168      conv4_block24_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_out (Add)         (None, 32, 32, 1024) 0           conv4_block23_out[0][0]          \n",
      "                                                                 conv4_block24_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block25_preact_bn (BatchN (None, 32, 32, 1024) 4096        conv4_block24_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block25_preact_relu (Acti (None, 32, 32, 1024) 0           conv4_block25_preact_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block25_1_conv (Conv2D)   (None, 32, 32, 256)  262144      conv4_block25_preact_relu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block25_1_bn (BatchNormal (None, 32, 32, 256)  1024        conv4_block25_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block25_1_relu (Activatio (None, 32, 32, 256)  0           conv4_block25_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block25_2_pad (ZeroPaddin (None, 34, 34, 256)  0           conv4_block25_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block25_2_conv (Conv2D)   (None, 32, 32, 256)  589824      conv4_block25_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block25_2_bn (BatchNormal (None, 32, 32, 256)  1024        conv4_block25_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block25_2_relu (Activatio (None, 32, 32, 256)  0           conv4_block25_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block25_3_conv (Conv2D)   (None, 32, 32, 1024) 263168      conv4_block25_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block25_out (Add)         (None, 32, 32, 1024) 0           conv4_block24_out[0][0]          \n",
      "                                                                 conv4_block25_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block26_preact_bn (BatchN (None, 32, 32, 1024) 4096        conv4_block25_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block26_preact_relu (Acti (None, 32, 32, 1024) 0           conv4_block26_preact_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block26_1_conv (Conv2D)   (None, 32, 32, 256)  262144      conv4_block26_preact_relu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block26_1_bn (BatchNormal (None, 32, 32, 256)  1024        conv4_block26_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block26_1_relu (Activatio (None, 32, 32, 256)  0           conv4_block26_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block26_2_pad (ZeroPaddin (None, 34, 34, 256)  0           conv4_block26_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block26_2_conv (Conv2D)   (None, 32, 32, 256)  589824      conv4_block26_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block26_2_bn (BatchNormal (None, 32, 32, 256)  1024        conv4_block26_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block26_2_relu (Activatio (None, 32, 32, 256)  0           conv4_block26_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block26_3_conv (Conv2D)   (None, 32, 32, 1024) 263168      conv4_block26_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block26_out (Add)         (None, 32, 32, 1024) 0           conv4_block25_out[0][0]          \n",
      "                                                                 conv4_block26_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block27_preact_bn (BatchN (None, 32, 32, 1024) 4096        conv4_block26_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block27_preact_relu (Acti (None, 32, 32, 1024) 0           conv4_block27_preact_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block27_1_conv (Conv2D)   (None, 32, 32, 256)  262144      conv4_block27_preact_relu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block27_1_bn (BatchNormal (None, 32, 32, 256)  1024        conv4_block27_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block27_1_relu (Activatio (None, 32, 32, 256)  0           conv4_block27_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block27_2_pad (ZeroPaddin (None, 34, 34, 256)  0           conv4_block27_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block27_2_conv (Conv2D)   (None, 32, 32, 256)  589824      conv4_block27_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block27_2_bn (BatchNormal (None, 32, 32, 256)  1024        conv4_block27_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block27_2_relu (Activatio (None, 32, 32, 256)  0           conv4_block27_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block27_3_conv (Conv2D)   (None, 32, 32, 1024) 263168      conv4_block27_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block27_out (Add)         (None, 32, 32, 1024) 0           conv4_block26_out[0][0]          \n",
      "                                                                 conv4_block27_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block28_preact_bn (BatchN (None, 32, 32, 1024) 4096        conv4_block27_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block28_preact_relu (Acti (None, 32, 32, 1024) 0           conv4_block28_preact_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block28_1_conv (Conv2D)   (None, 32, 32, 256)  262144      conv4_block28_preact_relu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block28_1_bn (BatchNormal (None, 32, 32, 256)  1024        conv4_block28_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block28_1_relu (Activatio (None, 32, 32, 256)  0           conv4_block28_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block28_2_pad (ZeroPaddin (None, 34, 34, 256)  0           conv4_block28_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block28_2_conv (Conv2D)   (None, 32, 32, 256)  589824      conv4_block28_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block28_2_bn (BatchNormal (None, 32, 32, 256)  1024        conv4_block28_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block28_2_relu (Activatio (None, 32, 32, 256)  0           conv4_block28_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block28_3_conv (Conv2D)   (None, 32, 32, 1024) 263168      conv4_block28_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block28_out (Add)         (None, 32, 32, 1024) 0           conv4_block27_out[0][0]          \n",
      "                                                                 conv4_block28_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block29_preact_bn (BatchN (None, 32, 32, 1024) 4096        conv4_block28_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block29_preact_relu (Acti (None, 32, 32, 1024) 0           conv4_block29_preact_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block29_1_conv (Conv2D)   (None, 32, 32, 256)  262144      conv4_block29_preact_relu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block29_1_bn (BatchNormal (None, 32, 32, 256)  1024        conv4_block29_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block29_1_relu (Activatio (None, 32, 32, 256)  0           conv4_block29_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block29_2_pad (ZeroPaddin (None, 34, 34, 256)  0           conv4_block29_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block29_2_conv (Conv2D)   (None, 32, 32, 256)  589824      conv4_block29_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block29_2_bn (BatchNormal (None, 32, 32, 256)  1024        conv4_block29_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block29_2_relu (Activatio (None, 32, 32, 256)  0           conv4_block29_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block29_3_conv (Conv2D)   (None, 32, 32, 1024) 263168      conv4_block29_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block29_out (Add)         (None, 32, 32, 1024) 0           conv4_block28_out[0][0]          \n",
      "                                                                 conv4_block29_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block30_preact_bn (BatchN (None, 32, 32, 1024) 4096        conv4_block29_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block30_preact_relu (Acti (None, 32, 32, 1024) 0           conv4_block30_preact_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block30_1_conv (Conv2D)   (None, 32, 32, 256)  262144      conv4_block30_preact_relu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block30_1_bn (BatchNormal (None, 32, 32, 256)  1024        conv4_block30_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block30_1_relu (Activatio (None, 32, 32, 256)  0           conv4_block30_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block30_2_pad (ZeroPaddin (None, 34, 34, 256)  0           conv4_block30_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block30_2_conv (Conv2D)   (None, 32, 32, 256)  589824      conv4_block30_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block30_2_bn (BatchNormal (None, 32, 32, 256)  1024        conv4_block30_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block30_2_relu (Activatio (None, 32, 32, 256)  0           conv4_block30_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block30_3_conv (Conv2D)   (None, 32, 32, 1024) 263168      conv4_block30_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block30_out (Add)         (None, 32, 32, 1024) 0           conv4_block29_out[0][0]          \n",
      "                                                                 conv4_block30_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block31_preact_bn (BatchN (None, 32, 32, 1024) 4096        conv4_block30_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block31_preact_relu (Acti (None, 32, 32, 1024) 0           conv4_block31_preact_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block31_1_conv (Conv2D)   (None, 32, 32, 256)  262144      conv4_block31_preact_relu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block31_1_bn (BatchNormal (None, 32, 32, 256)  1024        conv4_block31_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block31_1_relu (Activatio (None, 32, 32, 256)  0           conv4_block31_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block31_2_pad (ZeroPaddin (None, 34, 34, 256)  0           conv4_block31_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block31_2_conv (Conv2D)   (None, 32, 32, 256)  589824      conv4_block31_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block31_2_bn (BatchNormal (None, 32, 32, 256)  1024        conv4_block31_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block31_2_relu (Activatio (None, 32, 32, 256)  0           conv4_block31_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block31_3_conv (Conv2D)   (None, 32, 32, 1024) 263168      conv4_block31_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block31_out (Add)         (None, 32, 32, 1024) 0           conv4_block30_out[0][0]          \n",
      "                                                                 conv4_block31_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block32_preact_bn (BatchN (None, 32, 32, 1024) 4096        conv4_block31_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block32_preact_relu (Acti (None, 32, 32, 1024) 0           conv4_block32_preact_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block32_1_conv (Conv2D)   (None, 32, 32, 256)  262144      conv4_block32_preact_relu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block32_1_bn (BatchNormal (None, 32, 32, 256)  1024        conv4_block32_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block32_1_relu (Activatio (None, 32, 32, 256)  0           conv4_block32_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block32_2_pad (ZeroPaddin (None, 34, 34, 256)  0           conv4_block32_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block32_2_conv (Conv2D)   (None, 32, 32, 256)  589824      conv4_block32_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block32_2_bn (BatchNormal (None, 32, 32, 256)  1024        conv4_block32_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block32_2_relu (Activatio (None, 32, 32, 256)  0           conv4_block32_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block32_3_conv (Conv2D)   (None, 32, 32, 1024) 263168      conv4_block32_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block32_out (Add)         (None, 32, 32, 1024) 0           conv4_block31_out[0][0]          \n",
      "                                                                 conv4_block32_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block33_preact_bn (BatchN (None, 32, 32, 1024) 4096        conv4_block32_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block33_preact_relu (Acti (None, 32, 32, 1024) 0           conv4_block33_preact_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block33_1_conv (Conv2D)   (None, 32, 32, 256)  262144      conv4_block33_preact_relu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block33_1_bn (BatchNormal (None, 32, 32, 256)  1024        conv4_block33_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block33_1_relu (Activatio (None, 32, 32, 256)  0           conv4_block33_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block33_2_pad (ZeroPaddin (None, 34, 34, 256)  0           conv4_block33_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block33_2_conv (Conv2D)   (None, 32, 32, 256)  589824      conv4_block33_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block33_2_bn (BatchNormal (None, 32, 32, 256)  1024        conv4_block33_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block33_2_relu (Activatio (None, 32, 32, 256)  0           conv4_block33_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block33_3_conv (Conv2D)   (None, 32, 32, 1024) 263168      conv4_block33_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block33_out (Add)         (None, 32, 32, 1024) 0           conv4_block32_out[0][0]          \n",
      "                                                                 conv4_block33_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block34_preact_bn (BatchN (None, 32, 32, 1024) 4096        conv4_block33_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block34_preact_relu (Acti (None, 32, 32, 1024) 0           conv4_block34_preact_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block34_1_conv (Conv2D)   (None, 32, 32, 256)  262144      conv4_block34_preact_relu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block34_1_bn (BatchNormal (None, 32, 32, 256)  1024        conv4_block34_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block34_1_relu (Activatio (None, 32, 32, 256)  0           conv4_block34_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block34_2_pad (ZeroPaddin (None, 34, 34, 256)  0           conv4_block34_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block34_2_conv (Conv2D)   (None, 32, 32, 256)  589824      conv4_block34_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block34_2_bn (BatchNormal (None, 32, 32, 256)  1024        conv4_block34_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block34_2_relu (Activatio (None, 32, 32, 256)  0           conv4_block34_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block34_3_conv (Conv2D)   (None, 32, 32, 1024) 263168      conv4_block34_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block34_out (Add)         (None, 32, 32, 1024) 0           conv4_block33_out[0][0]          \n",
      "                                                                 conv4_block34_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block35_preact_bn (BatchN (None, 32, 32, 1024) 4096        conv4_block34_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block35_preact_relu (Acti (None, 32, 32, 1024) 0           conv4_block35_preact_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block35_1_conv (Conv2D)   (None, 32, 32, 256)  262144      conv4_block35_preact_relu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block35_1_bn (BatchNormal (None, 32, 32, 256)  1024        conv4_block35_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block35_1_relu (Activatio (None, 32, 32, 256)  0           conv4_block35_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block35_2_pad (ZeroPaddin (None, 34, 34, 256)  0           conv4_block35_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block35_2_conv (Conv2D)   (None, 32, 32, 256)  589824      conv4_block35_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block35_2_bn (BatchNormal (None, 32, 32, 256)  1024        conv4_block35_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block35_2_relu (Activatio (None, 32, 32, 256)  0           conv4_block35_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block35_3_conv (Conv2D)   (None, 32, 32, 1024) 263168      conv4_block35_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block35_out (Add)         (None, 32, 32, 1024) 0           conv4_block34_out[0][0]          \n",
      "                                                                 conv4_block35_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block36_preact_bn (BatchN (None, 32, 32, 1024) 4096        conv4_block35_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block36_preact_relu (Acti (None, 32, 32, 1024) 0           conv4_block36_preact_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block36_1_conv (Conv2D)   (None, 32, 32, 256)  262144      conv4_block36_preact_relu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block36_1_bn (BatchNormal (None, 32, 32, 256)  1024        conv4_block36_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block36_1_relu (Activatio (None, 32, 32, 256)  0           conv4_block36_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block36_2_pad (ZeroPaddin (None, 34, 34, 256)  0           conv4_block36_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block36_2_conv (Conv2D)   (None, 16, 16, 256)  589824      conv4_block36_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block36_2_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block36_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block36_2_relu (Activatio (None, 16, 16, 256)  0           conv4_block36_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 16, 16, 1024) 0           conv4_block35_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block36_3_conv (Conv2D)   (None, 16, 16, 1024) 263168      conv4_block36_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block36_out (Add)         (None, 16, 16, 1024) 0           max_pooling2d_2[0][0]            \n",
      "                                                                 conv4_block36_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_preact_bn (BatchNo (None, 16, 16, 1024) 4096        conv4_block36_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_preact_relu (Activ (None, 16, 16, 1024) 0           conv5_block1_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, 16, 16, 512)  524288      conv5_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, 16, 16, 512)  2048        conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, 16, 16, 512)  0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_pad (ZeroPadding (None, 18, 18, 512)  0           conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, 16, 16, 512)  2359296     conv5_block1_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_bn (BatchNormali (None, 16, 16, 512)  2048        conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_relu (Activation (None, 16, 16, 512)  0           conv5_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_conv (Conv2D)    (None, 16, 16, 2048) 2099200     conv5_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_conv (Conv2D)    (None, 16, 16, 2048) 1050624     conv5_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_out (Add)          (None, 16, 16, 2048) 0           conv5_block1_0_conv[0][0]        \n",
      "                                                                 conv5_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_preact_bn (BatchNo (None, 16, 16, 2048) 8192        conv5_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_preact_relu (Activ (None, 16, 16, 2048) 0           conv5_block2_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, 16, 16, 512)  1048576     conv5_block2_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, 16, 16, 512)  2048        conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, 16, 16, 512)  0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_pad (ZeroPadding (None, 18, 18, 512)  0           conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, 16, 16, 512)  2359296     conv5_block2_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_bn (BatchNormali (None, 16, 16, 512)  2048        conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_relu (Activation (None, 16, 16, 512)  0           conv5_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_conv (Conv2D)    (None, 16, 16, 2048) 1050624     conv5_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_out (Add)          (None, 16, 16, 2048) 0           conv5_block1_out[0][0]           \n",
      "                                                                 conv5_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_preact_bn (BatchNo (None, 16, 16, 2048) 8192        conv5_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_preact_relu (Activ (None, 16, 16, 2048) 0           conv5_block3_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, 16, 16, 512)  1048576     conv5_block3_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, 16, 16, 512)  2048        conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation (None, 16, 16, 512)  0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_pad (ZeroPadding (None, 18, 18, 512)  0           conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)    (None, 16, 16, 512)  2359296     conv5_block3_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_bn (BatchNormali (None, 16, 16, 512)  2048        conv5_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_relu (Activation (None, 16, 16, 512)  0           conv5_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_conv (Conv2D)    (None, 16, 16, 2048) 1050624     conv5_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_out (Add)          (None, 16, 16, 2048) 0           conv5_block2_out[0][0]           \n",
      "                                                                 conv5_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "post_bn (BatchNormalization)    (None, 16, 16, 2048) 8192        conv5_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "post_relu (Activation)          (None, 16, 16, 2048) 0           post_bn[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d (Globa (None, 2048)         0           post_relu[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 2048)         8192        global_average_pooling2d[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 2048)         0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 512)          1049088     dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 512)          2048        dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 512)          0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 2)            1026        dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 59,392,002\n",
      "Trainable params: 1,198,978\n",
      "Non-trainable params: 58,193,024\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 883 steps, validate for 111 steps\n",
      "Epoch 1/25\n",
      "883/883 [==============================] - 410s 465ms/step - loss: 0.6535 - acc: 0.7081 - val_loss: 0.5303 - val_acc: 0.7562\n",
      "Epoch 2/25\n",
      "883/883 [==============================] - 379s 429ms/step - loss: 0.4619 - acc: 0.7881 - val_loss: 0.3744 - val_acc: 0.8362\n",
      "Epoch 3/25\n",
      "883/883 [==============================] - 379s 430ms/step - loss: 0.4008 - acc: 0.8244 - val_loss: 0.3418 - val_acc: 0.8532\n",
      "Epoch 4/25\n",
      "883/883 [==============================] - 379s 429ms/step - loss: 0.3599 - acc: 0.8496 - val_loss: 0.3161 - val_acc: 0.8730\n",
      "Epoch 5/25\n",
      "883/883 [==============================] - 379s 429ms/step - loss: 0.3365 - acc: 0.8583 - val_loss: 0.3033 - val_acc: 0.8787\n",
      "Epoch 6/25\n",
      "883/883 [==============================] - 379s 429ms/step - loss: 0.3165 - acc: 0.8692 - val_loss: 0.2875 - val_acc: 0.8912\n",
      "Epoch 7/25\n",
      "883/883 [==============================] - 379s 430ms/step - loss: 0.2922 - acc: 0.8821 - val_loss: 0.3053 - val_acc: 0.8957\n",
      "Epoch 8/25\n",
      "499/883 [===============>..............] - ETA: 2:37 - loss: 0.2998 - acc: 0.8801"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-19d382386014>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m                     \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSTEPS_PER_EPOCH\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m                     \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mVAL_STEPS_PER_EPOCH\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                     callbacks=[])\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2.1-conda/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/anaconda3/envs/tf2.1-conda/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    340\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    343\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2.1-conda/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    126\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    127\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2.1-conda/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 98\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2.1-conda/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 568\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2.1-conda/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    597\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    600\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2.1-conda/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2361\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2362\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2363\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2365\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2.1-conda/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1609\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1611\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1613\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2.1-conda/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1690\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1692\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2.1-conda/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/anaconda3/envs/tf2.1-conda/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "STEPS_PER_EPOCH = len(train_generator) \n",
    "VAL_STEPS_PER_EPOCH = len(valid_generator) \n",
    "\n",
    "print(\"\")\n",
    "print(\"Arch: \", \"ResNet152V2\")\n",
    "    \n",
    "\n",
    "\n",
    "#optimizer = tf.keras.optimizers.SGD(lr=lr, momentum=0.9, decay=1e-6, nesterov=True)\n",
    "    \n",
    "#optimizer = tf.keras.optimizers.RMSprop(lr=lr)\n",
    "#optimizer = tf.keras.optimizers.Adam(lr=lr)\n",
    "optimizer = tf.keras.optimizers.Nadam(lr=lr)\n",
    "    \n",
    "\n",
    "model = create_model()\n",
    "\n",
    "model.summary()\n",
    "        \n",
    "        \n",
    "model.compile(optimizer=optimizer,loss=tf.keras.losses.BinaryCrossentropy(from_logits=False),metrics=['acc'])\n",
    "    \n",
    "history = model.fit(train_generator,\n",
    "                    epochs=EPOCHS,\n",
    "                    validation_data=valid_generator, \n",
    "                    steps_per_epoch=STEPS_PER_EPOCH, \n",
    "                    validation_steps=VAL_STEPS_PER_EPOCH,\n",
    "                    callbacks=[])\n",
    "        \n",
    "        \n",
    "        \n",
    "print(\"\")\n",
    "print(\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p saved_model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['val_loss'])\n",
    "plt.ylabel(\"loss\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.title(\"Validation Loss Curve\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.ylabel(\"loss\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.title(\"Training Loss Curve\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('saved_model2/my_model_weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy = mixed_precision.Policy('float32')\n",
    "mixed_precision.set_policy(policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_model = create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_model.load_weights('saved_model2/my_model_weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = valid_generator.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(x[0]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMAGE_PATH = '/opt/AIStorage/PLAYGROUND/images/512/filtered/data_filtered/train/data_filtered/positive/2.25.29063837649503765322829207716135903912.png'\n",
    "#IMAGE_PATH = '/opt/AIStorage/PLAYGROUND/images/512/positive/2.25.293051404113555009465480448588513430295.png'\n",
    "IMAGE_PATH = '/opt/AIStorage/PLAYGROUND/images/512/positive/2.25.181219916381488720424316063428743387152.png'\n",
    "img = tf.keras.preprocessing.image.load_img(IMAGE_PATH, target_size=(512, 512))\n",
    "img = tf.keras.preprocessing.image.img_to_array(img)\n",
    "\n",
    "img = img/255.0\n",
    "\n",
    "\n",
    "data = ([img], None)\n",
    "\n",
    "index = 0\n",
    "explainer = GradCAM()\n",
    "        \n",
    "saved_model.trainable = True\n",
    "        \n",
    "#layer ='conv2_block1_1_conv'\n",
    "layer ='conv5_block32_2_conv'\n",
    "    \n",
    "grid = explainer.explain(data, saved_model, class_index=index, image_weight=0.75, layer_name=layer)\n",
    "    \n",
    "explainer.save(grid, \".\", \"grad_cam_gpu2.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2.1-conda",
   "language": "python",
   "name": "tf2.1-conda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
