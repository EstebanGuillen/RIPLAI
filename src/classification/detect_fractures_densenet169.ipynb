{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.mixed_precision import experimental as mixed_precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  2\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/device:GPU:0'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.gpu_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython.display as display\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#policy = tf.keras.mixed_precision.experimental.Policy('mixed_float16')\n",
    "#mixed_precision.set_policy(policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.0'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "#data_dir = tf.keras.utils.get_file(origin='https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz',\n",
    "#                                         fname='flower_photos', untar=True)\n",
    "\n",
    "val_data_dir = '/opt/AIStorage/PLAYGROUND/data/validation'\n",
    "val_data_dir = pathlib.Path(val_data_dir)\n",
    "\n",
    "data_dir = '/opt/AIStorage/PLAYGROUND/data/train'\n",
    "data_dir = pathlib.Path(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3196"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_count = len(list(data_dir.glob('*/*.png')))\n",
    "image_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "798"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_image_count = len(list(val_data_dir.glob('*/*.png')))\n",
    "val_image_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['positive', 'negative'], dtype='<U8')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CLASS_NAMES = np.array([item.name for item in data_dir.glob('*') if item.name != \"LICENSE.txt\"])\n",
    "CLASS_NAMES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#img = list(data_dir.glob('positive/*'))\n",
    "\n",
    "#for image_path in img[:4]:\n",
    "    #display.display(Image.open(str(image_path)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The 1./255 is to convert from uint8 to float32 in range [0,1].\n",
    "val_image_generator = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "#image_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "                    #rescale=1./255,\n",
    "                    #rotation_range=15,\n",
    "                    #horizontal_flip=True,\n",
    "                    #zoom_range=0.0\n",
    "                    #)\n",
    "\n",
    "image_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "                    rescale=1./255\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 8\n",
    "#IMG_HEIGHT = 224\n",
    "#IMG_WIDTH = 224\n",
    "IMG_HEIGHT = 512\n",
    "IMG_WIDTH = 512\n",
    "STEPS_PER_EPOCH = np.ceil(image_count/BATCH_SIZE)\n",
    "VAL_STEPS_PER_EPOCH = np.ceil(val_image_count/BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3196 images belonging to 2 classes.\n",
      "Found 798 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_data_gen = image_generator.flow_from_directory(directory=str(data_dir),\n",
    "                                                     batch_size=BATCH_SIZE,\n",
    "                                                     shuffle=True,\n",
    "                                                     target_size=(IMG_HEIGHT, IMG_WIDTH))\n",
    "\n",
    "validation_data_gen = val_image_generator.flow_from_directory(directory=str(val_data_dir),\n",
    "                                                     batch_size=BATCH_SIZE,\n",
    "                                                     target_size=(IMG_HEIGHT, IMG_WIDTH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_batch(image_batch, label_batch):\n",
    "  plt.figure(figsize=(20,20))\n",
    "  for n in range(4):\n",
    "      ax = plt.subplot(2,2,n+1)\n",
    "      plt.imshow(image_batch[n])\n",
    "      #plt.title(CLASS_NAMES[label_batch[n]==1][0].title())\n",
    "      plt.axis('on')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#image_batch, label_batch = next(train_data_gen)\n",
    "#show_batch(image_batch, label_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#label_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#val_image_batch, val_label_batch = next(validation_data_gen)\n",
    "#show_batch(val_image_batch, val_label_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#val_label_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LRFinder(Callback):\n",
    "    \"\"\"Callback that exponentially adjusts the learning rate after each training batch between start_lr and\n",
    "    end_lr for a maximum number of batches: max_step. The loss and learning rate are recorded at each step allowing\n",
    "    visually finding a good learning rate as per https://sgugger.github.io/how-do-you-find-a-good-learning-rate.html via\n",
    "    the plot method.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, start_lr: float = 1e-7, end_lr: float = 10, max_steps: int = 400, smoothing=0.9):\n",
    "        super(LRFinder, self).__init__()\n",
    "        self.start_lr, self.end_lr = start_lr, end_lr\n",
    "        self.max_steps = max_steps\n",
    "        self.smoothing = smoothing\n",
    "        self.step, self.best_loss, self.avg_loss, self.lr = 0, 0, 0, 0\n",
    "        self.lrs, self.losses = [], []\n",
    "\n",
    "    def on_train_begin(self, logs=None):\n",
    "        self.step, self.best_loss, self.avg_loss, self.lr = 0, 0, 0, 0\n",
    "        self.lrs, self.losses = [], []\n",
    "\n",
    "    def on_train_batch_begin(self, batch, logs=None):\n",
    "        self.lr = self.exp_annealing(self.step)\n",
    "        tf.keras.backend.set_value(self.model.optimizer.lr, self.lr)\n",
    "\n",
    "    def on_train_batch_end(self, batch, logs=None):\n",
    "        logs = logs or {}\n",
    "        loss = logs.get('loss')\n",
    "        step = self.step\n",
    "        if loss:\n",
    "            self.avg_loss = self.smoothing * self.avg_loss + (1 - self.smoothing) * loss\n",
    "            smooth_loss = self.avg_loss / (1 - self.smoothing ** (self.step + 1))\n",
    "            self.losses.append(smooth_loss)\n",
    "            self.lrs.append(self.lr)\n",
    "\n",
    "            if step == 0 or loss < self.best_loss:\n",
    "                self.best_loss = loss\n",
    "\n",
    "            if smooth_loss > 4 * self.best_loss or tf.math.is_nan(smooth_loss):\n",
    "                self.model.stop_training = True\n",
    "\n",
    "        if step == self.max_steps:\n",
    "            self.model.stop_training = True\n",
    "\n",
    "        self.step += 1\n",
    "\n",
    "    def exp_annealing(self, step):\n",
    "        return self.start_lr * (self.end_lr / self.start_lr) ** (step * 1. / self.max_steps)\n",
    "\n",
    "    def plot(self):\n",
    "        fig, ax = plt.subplots(1, 1)\n",
    "        ax.set_ylabel('Loss')\n",
    "        ax.set_xlabel('Learning Rate (log scale)')\n",
    "        ax.set_xscale('log')\n",
    "        ax.xaxis.set_major_formatter(plt.FormatStrFormatter('%.0e'))\n",
    "        ax.plot(self.lrs, self.losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CosineAnnealer:\n",
    "    \n",
    "    def __init__(self, start, end, steps):\n",
    "        self.start = start\n",
    "        self.end = end\n",
    "        self.steps = steps\n",
    "        self.n = 0\n",
    "        \n",
    "    def step(self):\n",
    "        self.n += 1\n",
    "        cos = np.cos(np.pi * (self.n / self.steps)) + 1\n",
    "        return self.end + (self.start - self.end) / 2. * cos\n",
    "\n",
    "\n",
    "class OneCycleScheduler(Callback):\n",
    " \n",
    "\n",
    "    def __init__(self, lr_max, steps, mom_min=0.85, mom_max=0.95, phase_1_pct=0.3, div_factor=25.):\n",
    "        super(OneCycleScheduler, self).__init__()\n",
    "        lr_min = lr_max / div_factor\n",
    "        final_lr = lr_max / (div_factor * 1e4)\n",
    "        phase_1_steps = steps * phase_1_pct\n",
    "        phase_2_steps = steps - phase_1_steps\n",
    "        \n",
    "        self.phase_1_steps = phase_1_steps\n",
    "        self.phase_2_steps = phase_2_steps\n",
    "        self.phase = 0\n",
    "        self.step = 0\n",
    "        \n",
    "        self.phases = [[CosineAnnealer(lr_min, lr_max, phase_1_steps), CosineAnnealer(mom_max, mom_min, phase_1_steps)], \n",
    "                 [CosineAnnealer(lr_max, final_lr, phase_2_steps), CosineAnnealer(mom_min, mom_max, phase_2_steps)]]\n",
    "        \n",
    "        self.lrs = []\n",
    "        self.moms = []\n",
    "\n",
    "    def on_train_begin(self, logs=None):\n",
    "        self.phase = 0\n",
    "        self.step = 0\n",
    "\n",
    "        self.set_lr(self.lr_schedule().start)\n",
    "        self.set_momentum(self.mom_schedule().start)\n",
    "        \n",
    "    def on_train_batch_begin(self, batch, logs=None):\n",
    "        self.lrs.append(self.get_lr())\n",
    "        self.moms.append(self.get_momentum())\n",
    "\n",
    "    def on_train_batch_end(self, batch, logs=None):\n",
    "        self.step += 1\n",
    "        if self.step >= self.phase_1_steps:\n",
    "            self.phase = 1\n",
    "            \n",
    "        self.set_lr(self.lr_schedule().step())\n",
    "        self.set_momentum(self.mom_schedule().step())\n",
    "        \n",
    "    def get_lr(self):\n",
    "        try:\n",
    "            return tf.keras.backend.get_value(self.model.optimizer.lr)\n",
    "        except AttributeError:\n",
    "            print('get lr error')\n",
    "            return None\n",
    "        \n",
    "    def get_momentum(self):\n",
    "        try:\n",
    "            return tf.keras.backend.get_value(self.model.optimizer.momentum)\n",
    "        except AttributeError:\n",
    "            print('get momentum error')\n",
    "            return None\n",
    "        \n",
    "    def set_lr(self, lr):\n",
    "        try:\n",
    "            tf.keras.backend.set_value(self.model.optimizer.lr, lr)\n",
    "        except AttributeError:\n",
    "            print('set lr error')\n",
    "            pass # ignore\n",
    "        \n",
    "    def set_momentum(self, mom):\n",
    "        try:\n",
    "            tf.keras.backend.set_value(self.model.optimizer.momentum, mom)\n",
    "        except AttributeError:\n",
    "            print('set momentum error')\n",
    "            pass # ignore\n",
    "\n",
    "    def lr_schedule(self):\n",
    "        return self.phases[self.phase][0]\n",
    "    \n",
    "    def mom_schedule(self):\n",
    "        return self.phases[self.phase][1]\n",
    "    \n",
    "    def plot(self):\n",
    "        ax = plt.subplot(1, 2, 1)\n",
    "        ax.plot(self.lrs)\n",
    "        ax.set_title('Learning Rate')\n",
    "        ax = plt.subplot(1, 2, 2)\n",
    "        ax.plot(self.moms)\n",
    "        ax.set_title('Momentum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 6\n",
    "lr = 3e-3\n",
    "steps = np.ceil(image_count / BATCH_SIZE) * epochs\n",
    "lr_schedule = OneCycleScheduler(lr, steps)\n",
    "\n",
    "\n",
    "#optimizer = tf.keras.optimizers.RMSprop(lr=lr)\n",
    "optimizer = tf.keras.optimizers.SGD(lr=lr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2400.0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SHAPE = (IMG_HEIGHT, IMG_WIDTH, 3)\n",
    "base_model = tf.keras.applications.DenseNet169(input_shape=IMG_SHAPE,\n",
    "                                               include_top=False,\n",
    "                                               weights='imagenet')\n",
    "base_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"densenet169\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 512, 512, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d (ZeroPadding2D)  (None, 518, 518, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1/conv (Conv2D)             (None, 256, 256, 64) 9408        zero_padding2d[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1/bn (BatchNormalization)   (None, 256, 256, 64) 256         conv1/conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1/relu (Activation)         (None, 256, 256, 64) 0           conv1/bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_1 (ZeroPadding2D (None, 258, 258, 64) 0           conv1/relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1 (MaxPooling2D)            (None, 128, 128, 64) 0           zero_padding2d_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_bn (BatchNormali (None, 128, 128, 64) 256         pool1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_relu (Activation (None, 128, 128, 64) 0           conv2_block1_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, 128, 128, 128 8192        conv2_block1_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, 128, 128, 128 512         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, 128, 128, 128 0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, 128, 128, 32) 36864       conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_concat (Concatenat (None, 128, 128, 96) 0           pool1[0][0]                      \n",
      "                                                                 conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_0_bn (BatchNormali (None, 128, 128, 96) 384         conv2_block1_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_0_relu (Activation (None, 128, 128, 96) 0           conv2_block2_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, 128, 128, 128 12288       conv2_block2_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, 128, 128, 128 512         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, 128, 128, 128 0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, 128, 128, 32) 36864       conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_concat (Concatenat (None, 128, 128, 128 0           conv2_block1_concat[0][0]        \n",
      "                                                                 conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_0_bn (BatchNormali (None, 128, 128, 128 512         conv2_block2_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_0_relu (Activation (None, 128, 128, 128 0           conv2_block3_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, 128, 128, 128 16384       conv2_block3_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, 128, 128, 128 512         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, 128, 128, 128 0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, 128, 128, 32) 36864       conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_concat (Concatenat (None, 128, 128, 160 0           conv2_block2_concat[0][0]        \n",
      "                                                                 conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_0_bn (BatchNormali (None, 128, 128, 160 640         conv2_block3_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_0_relu (Activation (None, 128, 128, 160 0           conv2_block4_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_1_conv (Conv2D)    (None, 128, 128, 128 20480       conv2_block4_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_1_bn (BatchNormali (None, 128, 128, 128 512         conv2_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_1_relu (Activation (None, 128, 128, 128 0           conv2_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_2_conv (Conv2D)    (None, 128, 128, 32) 36864       conv2_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_concat (Concatenat (None, 128, 128, 192 0           conv2_block3_concat[0][0]        \n",
      "                                                                 conv2_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_0_bn (BatchNormali (None, 128, 128, 192 768         conv2_block4_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_0_relu (Activation (None, 128, 128, 192 0           conv2_block5_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_1_conv (Conv2D)    (None, 128, 128, 128 24576       conv2_block5_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_1_bn (BatchNormali (None, 128, 128, 128 512         conv2_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_1_relu (Activation (None, 128, 128, 128 0           conv2_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_2_conv (Conv2D)    (None, 128, 128, 32) 36864       conv2_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_concat (Concatenat (None, 128, 128, 224 0           conv2_block4_concat[0][0]        \n",
      "                                                                 conv2_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_0_bn (BatchNormali (None, 128, 128, 224 896         conv2_block5_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_0_relu (Activation (None, 128, 128, 224 0           conv2_block6_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_1_conv (Conv2D)    (None, 128, 128, 128 28672       conv2_block6_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_1_bn (BatchNormali (None, 128, 128, 128 512         conv2_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_1_relu (Activation (None, 128, 128, 128 0           conv2_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_2_conv (Conv2D)    (None, 128, 128, 32) 36864       conv2_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_concat (Concatenat (None, 128, 128, 256 0           conv2_block5_concat[0][0]        \n",
      "                                                                 conv2_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "pool2_bn (BatchNormalization)   (None, 128, 128, 256 1024        conv2_block6_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "pool2_relu (Activation)         (None, 128, 128, 256 0           pool2_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool2_conv (Conv2D)             (None, 128, 128, 128 32768       pool2_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool2_pool (AveragePooling2D)   (None, 64, 64, 128)  0           pool2_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_bn (BatchNormali (None, 64, 64, 128)  512         pool2_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_relu (Activation (None, 64, 64, 128)  0           conv3_block1_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, 64, 64, 128)  16384       conv3_block1_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, 64, 64, 128)  512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, 64, 64, 128)  0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, 64, 64, 32)   36864       conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_concat (Concatenat (None, 64, 64, 160)  0           pool2_pool[0][0]                 \n",
      "                                                                 conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_0_bn (BatchNormali (None, 64, 64, 160)  640         conv3_block1_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_0_relu (Activation (None, 64, 64, 160)  0           conv3_block2_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, 64, 64, 128)  20480       conv3_block2_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, 64, 64, 128)  512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, 64, 64, 128)  0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, 64, 64, 32)   36864       conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_concat (Concatenat (None, 64, 64, 192)  0           conv3_block1_concat[0][0]        \n",
      "                                                                 conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_0_bn (BatchNormali (None, 64, 64, 192)  768         conv3_block2_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_0_relu (Activation (None, 64, 64, 192)  0           conv3_block3_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, 64, 64, 128)  24576       conv3_block3_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, 64, 64, 128)  512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, 64, 64, 128)  0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, 64, 64, 32)   36864       conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_concat (Concatenat (None, 64, 64, 224)  0           conv3_block2_concat[0][0]        \n",
      "                                                                 conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_0_bn (BatchNormali (None, 64, 64, 224)  896         conv3_block3_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_0_relu (Activation (None, 64, 64, 224)  0           conv3_block4_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, 64, 64, 128)  28672       conv3_block4_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, 64, 64, 128)  512         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, 64, 64, 128)  0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, 64, 64, 32)   36864       conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_concat (Concatenat (None, 64, 64, 256)  0           conv3_block3_concat[0][0]        \n",
      "                                                                 conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_0_bn (BatchNormali (None, 64, 64, 256)  1024        conv3_block4_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_0_relu (Activation (None, 64, 64, 256)  0           conv3_block5_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_1_conv (Conv2D)    (None, 64, 64, 128)  32768       conv3_block5_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_1_bn (BatchNormali (None, 64, 64, 128)  512         conv3_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_1_relu (Activation (None, 64, 64, 128)  0           conv3_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_2_conv (Conv2D)    (None, 64, 64, 32)   36864       conv3_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_concat (Concatenat (None, 64, 64, 288)  0           conv3_block4_concat[0][0]        \n",
      "                                                                 conv3_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_0_bn (BatchNormali (None, 64, 64, 288)  1152        conv3_block5_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_0_relu (Activation (None, 64, 64, 288)  0           conv3_block6_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_1_conv (Conv2D)    (None, 64, 64, 128)  36864       conv3_block6_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_1_bn (BatchNormali (None, 64, 64, 128)  512         conv3_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_1_relu (Activation (None, 64, 64, 128)  0           conv3_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_2_conv (Conv2D)    (None, 64, 64, 32)   36864       conv3_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_concat (Concatenat (None, 64, 64, 320)  0           conv3_block5_concat[0][0]        \n",
      "                                                                 conv3_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_0_bn (BatchNormali (None, 64, 64, 320)  1280        conv3_block6_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_0_relu (Activation (None, 64, 64, 320)  0           conv3_block7_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_1_conv (Conv2D)    (None, 64, 64, 128)  40960       conv3_block7_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_1_bn (BatchNormali (None, 64, 64, 128)  512         conv3_block7_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_1_relu (Activation (None, 64, 64, 128)  0           conv3_block7_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_2_conv (Conv2D)    (None, 64, 64, 32)   36864       conv3_block7_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_concat (Concatenat (None, 64, 64, 352)  0           conv3_block6_concat[0][0]        \n",
      "                                                                 conv3_block7_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_0_bn (BatchNormali (None, 64, 64, 352)  1408        conv3_block7_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_0_relu (Activation (None, 64, 64, 352)  0           conv3_block8_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_1_conv (Conv2D)    (None, 64, 64, 128)  45056       conv3_block8_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_1_bn (BatchNormali (None, 64, 64, 128)  512         conv3_block8_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_1_relu (Activation (None, 64, 64, 128)  0           conv3_block8_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_2_conv (Conv2D)    (None, 64, 64, 32)   36864       conv3_block8_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_concat (Concatenat (None, 64, 64, 384)  0           conv3_block7_concat[0][0]        \n",
      "                                                                 conv3_block8_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_0_bn (BatchNormali (None, 64, 64, 384)  1536        conv3_block8_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_0_relu (Activation (None, 64, 64, 384)  0           conv3_block9_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_1_conv (Conv2D)    (None, 64, 64, 128)  49152       conv3_block9_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_1_bn (BatchNormali (None, 64, 64, 128)  512         conv3_block9_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_1_relu (Activation (None, 64, 64, 128)  0           conv3_block9_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_2_conv (Conv2D)    (None, 64, 64, 32)   36864       conv3_block9_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_concat (Concatenat (None, 64, 64, 416)  0           conv3_block8_concat[0][0]        \n",
      "                                                                 conv3_block9_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_0_bn (BatchNormal (None, 64, 64, 416)  1664        conv3_block9_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_0_relu (Activatio (None, 64, 64, 416)  0           conv3_block10_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_1_conv (Conv2D)   (None, 64, 64, 128)  53248       conv3_block10_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_1_bn (BatchNormal (None, 64, 64, 128)  512         conv3_block10_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_1_relu (Activatio (None, 64, 64, 128)  0           conv3_block10_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_2_conv (Conv2D)   (None, 64, 64, 32)   36864       conv3_block10_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_concat (Concatena (None, 64, 64, 448)  0           conv3_block9_concat[0][0]        \n",
      "                                                                 conv3_block10_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_0_bn (BatchNormal (None, 64, 64, 448)  1792        conv3_block10_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_0_relu (Activatio (None, 64, 64, 448)  0           conv3_block11_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_1_conv (Conv2D)   (None, 64, 64, 128)  57344       conv3_block11_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_1_bn (BatchNormal (None, 64, 64, 128)  512         conv3_block11_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_1_relu (Activatio (None, 64, 64, 128)  0           conv3_block11_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_2_conv (Conv2D)   (None, 64, 64, 32)   36864       conv3_block11_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_concat (Concatena (None, 64, 64, 480)  0           conv3_block10_concat[0][0]       \n",
      "                                                                 conv3_block11_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_0_bn (BatchNormal (None, 64, 64, 480)  1920        conv3_block11_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_0_relu (Activatio (None, 64, 64, 480)  0           conv3_block12_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_1_conv (Conv2D)   (None, 64, 64, 128)  61440       conv3_block12_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_1_bn (BatchNormal (None, 64, 64, 128)  512         conv3_block12_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_1_relu (Activatio (None, 64, 64, 128)  0           conv3_block12_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_2_conv (Conv2D)   (None, 64, 64, 32)   36864       conv3_block12_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_concat (Concatena (None, 64, 64, 512)  0           conv3_block11_concat[0][0]       \n",
      "                                                                 conv3_block12_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool3_bn (BatchNormalization)   (None, 64, 64, 512)  2048        conv3_block12_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool3_relu (Activation)         (None, 64, 64, 512)  0           pool3_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool3_conv (Conv2D)             (None, 64, 64, 256)  131072      pool3_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool3_pool (AveragePooling2D)   (None, 32, 32, 256)  0           pool3_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_bn (BatchNormali (None, 32, 32, 256)  1024        pool3_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_relu (Activation (None, 32, 32, 256)  0           conv4_block1_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, 32, 32, 128)  32768       conv4_block1_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, 32, 32, 128)  512         conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, 32, 32, 128)  0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, 32, 32, 32)   36864       conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_concat (Concatenat (None, 32, 32, 288)  0           pool3_pool[0][0]                 \n",
      "                                                                 conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_0_bn (BatchNormali (None, 32, 32, 288)  1152        conv4_block1_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_0_relu (Activation (None, 32, 32, 288)  0           conv4_block2_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, 32, 32, 128)  36864       conv4_block2_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, 32, 32, 128)  512         conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, 32, 32, 128)  0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, 32, 32, 32)   36864       conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_concat (Concatenat (None, 32, 32, 320)  0           conv4_block1_concat[0][0]        \n",
      "                                                                 conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_0_bn (BatchNormali (None, 32, 32, 320)  1280        conv4_block2_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_0_relu (Activation (None, 32, 32, 320)  0           conv4_block3_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, 32, 32, 128)  40960       conv4_block3_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, 32, 32, 128)  512         conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, 32, 32, 128)  0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, 32, 32, 32)   36864       conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_concat (Concatenat (None, 32, 32, 352)  0           conv4_block2_concat[0][0]        \n",
      "                                                                 conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_0_bn (BatchNormali (None, 32, 32, 352)  1408        conv4_block3_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_0_relu (Activation (None, 32, 32, 352)  0           conv4_block4_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, 32, 32, 128)  45056       conv4_block4_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, 32, 32, 128)  512         conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, 32, 32, 128)  0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, 32, 32, 32)   36864       conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_concat (Concatenat (None, 32, 32, 384)  0           conv4_block3_concat[0][0]        \n",
      "                                                                 conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_0_bn (BatchNormali (None, 32, 32, 384)  1536        conv4_block4_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_0_relu (Activation (None, 32, 32, 384)  0           conv4_block5_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, 32, 32, 128)  49152       conv4_block5_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, 32, 32, 128)  512         conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, 32, 32, 128)  0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, 32, 32, 32)   36864       conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_concat (Concatenat (None, 32, 32, 416)  0           conv4_block4_concat[0][0]        \n",
      "                                                                 conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_0_bn (BatchNormali (None, 32, 32, 416)  1664        conv4_block5_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_0_relu (Activation (None, 32, 32, 416)  0           conv4_block6_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, 32, 32, 128)  53248       conv4_block6_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, 32, 32, 128)  512         conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, 32, 32, 128)  0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, 32, 32, 32)   36864       conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_concat (Concatenat (None, 32, 32, 448)  0           conv4_block5_concat[0][0]        \n",
      "                                                                 conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_0_bn (BatchNormali (None, 32, 32, 448)  1792        conv4_block6_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_0_relu (Activation (None, 32, 32, 448)  0           conv4_block7_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_1_conv (Conv2D)    (None, 32, 32, 128)  57344       conv4_block7_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_1_bn (BatchNormali (None, 32, 32, 128)  512         conv4_block7_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_1_relu (Activation (None, 32, 32, 128)  0           conv4_block7_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_2_conv (Conv2D)    (None, 32, 32, 32)   36864       conv4_block7_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_concat (Concatenat (None, 32, 32, 480)  0           conv4_block6_concat[0][0]        \n",
      "                                                                 conv4_block7_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_0_bn (BatchNormali (None, 32, 32, 480)  1920        conv4_block7_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_0_relu (Activation (None, 32, 32, 480)  0           conv4_block8_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_conv (Conv2D)    (None, 32, 32, 128)  61440       conv4_block8_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_bn (BatchNormali (None, 32, 32, 128)  512         conv4_block8_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_relu (Activation (None, 32, 32, 128)  0           conv4_block8_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_2_conv (Conv2D)    (None, 32, 32, 32)   36864       conv4_block8_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_concat (Concatenat (None, 32, 32, 512)  0           conv4_block7_concat[0][0]        \n",
      "                                                                 conv4_block8_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_0_bn (BatchNormali (None, 32, 32, 512)  2048        conv4_block8_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_0_relu (Activation (None, 32, 32, 512)  0           conv4_block9_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_conv (Conv2D)    (None, 32, 32, 128)  65536       conv4_block9_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_bn (BatchNormali (None, 32, 32, 128)  512         conv4_block9_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_relu (Activation (None, 32, 32, 128)  0           conv4_block9_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_2_conv (Conv2D)    (None, 32, 32, 32)   36864       conv4_block9_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_concat (Concatenat (None, 32, 32, 544)  0           conv4_block8_concat[0][0]        \n",
      "                                                                 conv4_block9_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_0_bn (BatchNormal (None, 32, 32, 544)  2176        conv4_block9_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_0_relu (Activatio (None, 32, 32, 544)  0           conv4_block10_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_conv (Conv2D)   (None, 32, 32, 128)  69632       conv4_block10_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_bn (BatchNormal (None, 32, 32, 128)  512         conv4_block10_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_relu (Activatio (None, 32, 32, 128)  0           conv4_block10_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_2_conv (Conv2D)   (None, 32, 32, 32)   36864       conv4_block10_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_concat (Concatena (None, 32, 32, 576)  0           conv4_block9_concat[0][0]        \n",
      "                                                                 conv4_block10_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_0_bn (BatchNormal (None, 32, 32, 576)  2304        conv4_block10_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_0_relu (Activatio (None, 32, 32, 576)  0           conv4_block11_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_1_conv (Conv2D)   (None, 32, 32, 128)  73728       conv4_block11_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_1_bn (BatchNormal (None, 32, 32, 128)  512         conv4_block11_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_1_relu (Activatio (None, 32, 32, 128)  0           conv4_block11_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_2_conv (Conv2D)   (None, 32, 32, 32)   36864       conv4_block11_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_concat (Concatena (None, 32, 32, 608)  0           conv4_block10_concat[0][0]       \n",
      "                                                                 conv4_block11_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_0_bn (BatchNormal (None, 32, 32, 608)  2432        conv4_block11_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_0_relu (Activatio (None, 32, 32, 608)  0           conv4_block12_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_1_conv (Conv2D)   (None, 32, 32, 128)  77824       conv4_block12_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_1_bn (BatchNormal (None, 32, 32, 128)  512         conv4_block12_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_1_relu (Activatio (None, 32, 32, 128)  0           conv4_block12_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_2_conv (Conv2D)   (None, 32, 32, 32)   36864       conv4_block12_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_concat (Concatena (None, 32, 32, 640)  0           conv4_block11_concat[0][0]       \n",
      "                                                                 conv4_block12_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_0_bn (BatchNormal (None, 32, 32, 640)  2560        conv4_block12_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_0_relu (Activatio (None, 32, 32, 640)  0           conv4_block13_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_1_conv (Conv2D)   (None, 32, 32, 128)  81920       conv4_block13_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_1_bn (BatchNormal (None, 32, 32, 128)  512         conv4_block13_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_1_relu (Activatio (None, 32, 32, 128)  0           conv4_block13_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_2_conv (Conv2D)   (None, 32, 32, 32)   36864       conv4_block13_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_concat (Concatena (None, 32, 32, 672)  0           conv4_block12_concat[0][0]       \n",
      "                                                                 conv4_block13_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_0_bn (BatchNormal (None, 32, 32, 672)  2688        conv4_block13_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_0_relu (Activatio (None, 32, 32, 672)  0           conv4_block14_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_1_conv (Conv2D)   (None, 32, 32, 128)  86016       conv4_block14_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_1_bn (BatchNormal (None, 32, 32, 128)  512         conv4_block14_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_1_relu (Activatio (None, 32, 32, 128)  0           conv4_block14_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_2_conv (Conv2D)   (None, 32, 32, 32)   36864       conv4_block14_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_concat (Concatena (None, 32, 32, 704)  0           conv4_block13_concat[0][0]       \n",
      "                                                                 conv4_block14_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_0_bn (BatchNormal (None, 32, 32, 704)  2816        conv4_block14_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_0_relu (Activatio (None, 32, 32, 704)  0           conv4_block15_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_1_conv (Conv2D)   (None, 32, 32, 128)  90112       conv4_block15_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_1_bn (BatchNormal (None, 32, 32, 128)  512         conv4_block15_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_1_relu (Activatio (None, 32, 32, 128)  0           conv4_block15_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_2_conv (Conv2D)   (None, 32, 32, 32)   36864       conv4_block15_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_concat (Concatena (None, 32, 32, 736)  0           conv4_block14_concat[0][0]       \n",
      "                                                                 conv4_block15_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_0_bn (BatchNormal (None, 32, 32, 736)  2944        conv4_block15_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_0_relu (Activatio (None, 32, 32, 736)  0           conv4_block16_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_1_conv (Conv2D)   (None, 32, 32, 128)  94208       conv4_block16_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_1_bn (BatchNormal (None, 32, 32, 128)  512         conv4_block16_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_1_relu (Activatio (None, 32, 32, 128)  0           conv4_block16_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_2_conv (Conv2D)   (None, 32, 32, 32)   36864       conv4_block16_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_concat (Concatena (None, 32, 32, 768)  0           conv4_block15_concat[0][0]       \n",
      "                                                                 conv4_block16_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_0_bn (BatchNormal (None, 32, 32, 768)  3072        conv4_block16_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_0_relu (Activatio (None, 32, 32, 768)  0           conv4_block17_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_1_conv (Conv2D)   (None, 32, 32, 128)  98304       conv4_block17_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_1_bn (BatchNormal (None, 32, 32, 128)  512         conv4_block17_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_1_relu (Activatio (None, 32, 32, 128)  0           conv4_block17_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_2_conv (Conv2D)   (None, 32, 32, 32)   36864       conv4_block17_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_concat (Concatena (None, 32, 32, 800)  0           conv4_block16_concat[0][0]       \n",
      "                                                                 conv4_block17_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_0_bn (BatchNormal (None, 32, 32, 800)  3200        conv4_block17_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_0_relu (Activatio (None, 32, 32, 800)  0           conv4_block18_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_1_conv (Conv2D)   (None, 32, 32, 128)  102400      conv4_block18_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_1_bn (BatchNormal (None, 32, 32, 128)  512         conv4_block18_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_1_relu (Activatio (None, 32, 32, 128)  0           conv4_block18_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_2_conv (Conv2D)   (None, 32, 32, 32)   36864       conv4_block18_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_concat (Concatena (None, 32, 32, 832)  0           conv4_block17_concat[0][0]       \n",
      "                                                                 conv4_block18_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_0_bn (BatchNormal (None, 32, 32, 832)  3328        conv4_block18_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_0_relu (Activatio (None, 32, 32, 832)  0           conv4_block19_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_1_conv (Conv2D)   (None, 32, 32, 128)  106496      conv4_block19_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_1_bn (BatchNormal (None, 32, 32, 128)  512         conv4_block19_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_1_relu (Activatio (None, 32, 32, 128)  0           conv4_block19_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_2_conv (Conv2D)   (None, 32, 32, 32)   36864       conv4_block19_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_concat (Concatena (None, 32, 32, 864)  0           conv4_block18_concat[0][0]       \n",
      "                                                                 conv4_block19_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_0_bn (BatchNormal (None, 32, 32, 864)  3456        conv4_block19_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_0_relu (Activatio (None, 32, 32, 864)  0           conv4_block20_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_1_conv (Conv2D)   (None, 32, 32, 128)  110592      conv4_block20_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_1_bn (BatchNormal (None, 32, 32, 128)  512         conv4_block20_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_1_relu (Activatio (None, 32, 32, 128)  0           conv4_block20_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_2_conv (Conv2D)   (None, 32, 32, 32)   36864       conv4_block20_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_concat (Concatena (None, 32, 32, 896)  0           conv4_block19_concat[0][0]       \n",
      "                                                                 conv4_block20_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_0_bn (BatchNormal (None, 32, 32, 896)  3584        conv4_block20_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_0_relu (Activatio (None, 32, 32, 896)  0           conv4_block21_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_1_conv (Conv2D)   (None, 32, 32, 128)  114688      conv4_block21_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_1_bn (BatchNormal (None, 32, 32, 128)  512         conv4_block21_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_1_relu (Activatio (None, 32, 32, 128)  0           conv4_block21_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_2_conv (Conv2D)   (None, 32, 32, 32)   36864       conv4_block21_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_concat (Concatena (None, 32, 32, 928)  0           conv4_block20_concat[0][0]       \n",
      "                                                                 conv4_block21_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_0_bn (BatchNormal (None, 32, 32, 928)  3712        conv4_block21_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_0_relu (Activatio (None, 32, 32, 928)  0           conv4_block22_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_1_conv (Conv2D)   (None, 32, 32, 128)  118784      conv4_block22_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_1_bn (BatchNormal (None, 32, 32, 128)  512         conv4_block22_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_1_relu (Activatio (None, 32, 32, 128)  0           conv4_block22_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_2_conv (Conv2D)   (None, 32, 32, 32)   36864       conv4_block22_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_concat (Concatena (None, 32, 32, 960)  0           conv4_block21_concat[0][0]       \n",
      "                                                                 conv4_block22_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_0_bn (BatchNormal (None, 32, 32, 960)  3840        conv4_block22_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_0_relu (Activatio (None, 32, 32, 960)  0           conv4_block23_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_1_conv (Conv2D)   (None, 32, 32, 128)  122880      conv4_block23_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_1_bn (BatchNormal (None, 32, 32, 128)  512         conv4_block23_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_1_relu (Activatio (None, 32, 32, 128)  0           conv4_block23_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_2_conv (Conv2D)   (None, 32, 32, 32)   36864       conv4_block23_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_concat (Concatena (None, 32, 32, 992)  0           conv4_block22_concat[0][0]       \n",
      "                                                                 conv4_block23_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_0_bn (BatchNormal (None, 32, 32, 992)  3968        conv4_block23_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_0_relu (Activatio (None, 32, 32, 992)  0           conv4_block24_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_1_conv (Conv2D)   (None, 32, 32, 128)  126976      conv4_block24_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_1_bn (BatchNormal (None, 32, 32, 128)  512         conv4_block24_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_1_relu (Activatio (None, 32, 32, 128)  0           conv4_block24_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_2_conv (Conv2D)   (None, 32, 32, 32)   36864       conv4_block24_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_concat (Concatena (None, 32, 32, 1024) 0           conv4_block23_concat[0][0]       \n",
      "                                                                 conv4_block24_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block25_0_bn (BatchNormal (None, 32, 32, 1024) 4096        conv4_block24_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block25_0_relu (Activatio (None, 32, 32, 1024) 0           conv4_block25_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block25_1_conv (Conv2D)   (None, 32, 32, 128)  131072      conv4_block25_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block25_1_bn (BatchNormal (None, 32, 32, 128)  512         conv4_block25_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block25_1_relu (Activatio (None, 32, 32, 128)  0           conv4_block25_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block25_2_conv (Conv2D)   (None, 32, 32, 32)   36864       conv4_block25_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block25_concat (Concatena (None, 32, 32, 1056) 0           conv4_block24_concat[0][0]       \n",
      "                                                                 conv4_block25_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block26_0_bn (BatchNormal (None, 32, 32, 1056) 4224        conv4_block25_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block26_0_relu (Activatio (None, 32, 32, 1056) 0           conv4_block26_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block26_1_conv (Conv2D)   (None, 32, 32, 128)  135168      conv4_block26_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block26_1_bn (BatchNormal (None, 32, 32, 128)  512         conv4_block26_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block26_1_relu (Activatio (None, 32, 32, 128)  0           conv4_block26_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block26_2_conv (Conv2D)   (None, 32, 32, 32)   36864       conv4_block26_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block26_concat (Concatena (None, 32, 32, 1088) 0           conv4_block25_concat[0][0]       \n",
      "                                                                 conv4_block26_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block27_0_bn (BatchNormal (None, 32, 32, 1088) 4352        conv4_block26_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block27_0_relu (Activatio (None, 32, 32, 1088) 0           conv4_block27_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block27_1_conv (Conv2D)   (None, 32, 32, 128)  139264      conv4_block27_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block27_1_bn (BatchNormal (None, 32, 32, 128)  512         conv4_block27_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block27_1_relu (Activatio (None, 32, 32, 128)  0           conv4_block27_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block27_2_conv (Conv2D)   (None, 32, 32, 32)   36864       conv4_block27_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block27_concat (Concatena (None, 32, 32, 1120) 0           conv4_block26_concat[0][0]       \n",
      "                                                                 conv4_block27_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block28_0_bn (BatchNormal (None, 32, 32, 1120) 4480        conv4_block27_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block28_0_relu (Activatio (None, 32, 32, 1120) 0           conv4_block28_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block28_1_conv (Conv2D)   (None, 32, 32, 128)  143360      conv4_block28_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block28_1_bn (BatchNormal (None, 32, 32, 128)  512         conv4_block28_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block28_1_relu (Activatio (None, 32, 32, 128)  0           conv4_block28_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block28_2_conv (Conv2D)   (None, 32, 32, 32)   36864       conv4_block28_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block28_concat (Concatena (None, 32, 32, 1152) 0           conv4_block27_concat[0][0]       \n",
      "                                                                 conv4_block28_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block29_0_bn (BatchNormal (None, 32, 32, 1152) 4608        conv4_block28_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block29_0_relu (Activatio (None, 32, 32, 1152) 0           conv4_block29_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block29_1_conv (Conv2D)   (None, 32, 32, 128)  147456      conv4_block29_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block29_1_bn (BatchNormal (None, 32, 32, 128)  512         conv4_block29_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block29_1_relu (Activatio (None, 32, 32, 128)  0           conv4_block29_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block29_2_conv (Conv2D)   (None, 32, 32, 32)   36864       conv4_block29_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block29_concat (Concatena (None, 32, 32, 1184) 0           conv4_block28_concat[0][0]       \n",
      "                                                                 conv4_block29_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block30_0_bn (BatchNormal (None, 32, 32, 1184) 4736        conv4_block29_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block30_0_relu (Activatio (None, 32, 32, 1184) 0           conv4_block30_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block30_1_conv (Conv2D)   (None, 32, 32, 128)  151552      conv4_block30_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block30_1_bn (BatchNormal (None, 32, 32, 128)  512         conv4_block30_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block30_1_relu (Activatio (None, 32, 32, 128)  0           conv4_block30_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block30_2_conv (Conv2D)   (None, 32, 32, 32)   36864       conv4_block30_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block30_concat (Concatena (None, 32, 32, 1216) 0           conv4_block29_concat[0][0]       \n",
      "                                                                 conv4_block30_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block31_0_bn (BatchNormal (None, 32, 32, 1216) 4864        conv4_block30_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block31_0_relu (Activatio (None, 32, 32, 1216) 0           conv4_block31_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block31_1_conv (Conv2D)   (None, 32, 32, 128)  155648      conv4_block31_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block31_1_bn (BatchNormal (None, 32, 32, 128)  512         conv4_block31_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block31_1_relu (Activatio (None, 32, 32, 128)  0           conv4_block31_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block31_2_conv (Conv2D)   (None, 32, 32, 32)   36864       conv4_block31_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block31_concat (Concatena (None, 32, 32, 1248) 0           conv4_block30_concat[0][0]       \n",
      "                                                                 conv4_block31_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block32_0_bn (BatchNormal (None, 32, 32, 1248) 4992        conv4_block31_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block32_0_relu (Activatio (None, 32, 32, 1248) 0           conv4_block32_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block32_1_conv (Conv2D)   (None, 32, 32, 128)  159744      conv4_block32_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block32_1_bn (BatchNormal (None, 32, 32, 128)  512         conv4_block32_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block32_1_relu (Activatio (None, 32, 32, 128)  0           conv4_block32_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block32_2_conv (Conv2D)   (None, 32, 32, 32)   36864       conv4_block32_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block32_concat (Concatena (None, 32, 32, 1280) 0           conv4_block31_concat[0][0]       \n",
      "                                                                 conv4_block32_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool4_bn (BatchNormalization)   (None, 32, 32, 1280) 5120        conv4_block32_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool4_relu (Activation)         (None, 32, 32, 1280) 0           pool4_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool4_conv (Conv2D)             (None, 32, 32, 640)  819200      pool4_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool4_pool (AveragePooling2D)   (None, 16, 16, 640)  0           pool4_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_bn (BatchNormali (None, 16, 16, 640)  2560        pool4_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_relu (Activation (None, 16, 16, 640)  0           conv5_block1_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, 16, 16, 128)  81920       conv5_block1_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, 16, 16, 128)  512         conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, 16, 16, 128)  0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, 16, 16, 32)   36864       conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_concat (Concatenat (None, 16, 16, 672)  0           pool4_pool[0][0]                 \n",
      "                                                                 conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_0_bn (BatchNormali (None, 16, 16, 672)  2688        conv5_block1_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_0_relu (Activation (None, 16, 16, 672)  0           conv5_block2_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, 16, 16, 128)  86016       conv5_block2_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, 16, 16, 128)  512         conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, 16, 16, 128)  0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, 16, 16, 32)   36864       conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_concat (Concatenat (None, 16, 16, 704)  0           conv5_block1_concat[0][0]        \n",
      "                                                                 conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_0_bn (BatchNormali (None, 16, 16, 704)  2816        conv5_block2_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_0_relu (Activation (None, 16, 16, 704)  0           conv5_block3_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, 16, 16, 128)  90112       conv5_block3_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, 16, 16, 128)  512         conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation (None, 16, 16, 128)  0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)    (None, 16, 16, 32)   36864       conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_concat (Concatenat (None, 16, 16, 736)  0           conv5_block2_concat[0][0]        \n",
      "                                                                 conv5_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_0_bn (BatchNormali (None, 16, 16, 736)  2944        conv5_block3_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_0_relu (Activation (None, 16, 16, 736)  0           conv5_block4_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_1_conv (Conv2D)    (None, 16, 16, 128)  94208       conv5_block4_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_1_bn (BatchNormali (None, 16, 16, 128)  512         conv5_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_1_relu (Activation (None, 16, 16, 128)  0           conv5_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_2_conv (Conv2D)    (None, 16, 16, 32)   36864       conv5_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_concat (Concatenat (None, 16, 16, 768)  0           conv5_block3_concat[0][0]        \n",
      "                                                                 conv5_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_0_bn (BatchNormali (None, 16, 16, 768)  3072        conv5_block4_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_0_relu (Activation (None, 16, 16, 768)  0           conv5_block5_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_1_conv (Conv2D)    (None, 16, 16, 128)  98304       conv5_block5_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_1_bn (BatchNormali (None, 16, 16, 128)  512         conv5_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_1_relu (Activation (None, 16, 16, 128)  0           conv5_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_2_conv (Conv2D)    (None, 16, 16, 32)   36864       conv5_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_concat (Concatenat (None, 16, 16, 800)  0           conv5_block4_concat[0][0]        \n",
      "                                                                 conv5_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_0_bn (BatchNormali (None, 16, 16, 800)  3200        conv5_block5_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_0_relu (Activation (None, 16, 16, 800)  0           conv5_block6_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_1_conv (Conv2D)    (None, 16, 16, 128)  102400      conv5_block6_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_1_bn (BatchNormali (None, 16, 16, 128)  512         conv5_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_1_relu (Activation (None, 16, 16, 128)  0           conv5_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_2_conv (Conv2D)    (None, 16, 16, 32)   36864       conv5_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_concat (Concatenat (None, 16, 16, 832)  0           conv5_block5_concat[0][0]        \n",
      "                                                                 conv5_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_0_bn (BatchNormali (None, 16, 16, 832)  3328        conv5_block6_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_0_relu (Activation (None, 16, 16, 832)  0           conv5_block7_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_1_conv (Conv2D)    (None, 16, 16, 128)  106496      conv5_block7_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_1_bn (BatchNormali (None, 16, 16, 128)  512         conv5_block7_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_1_relu (Activation (None, 16, 16, 128)  0           conv5_block7_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_2_conv (Conv2D)    (None, 16, 16, 32)   36864       conv5_block7_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_concat (Concatenat (None, 16, 16, 864)  0           conv5_block6_concat[0][0]        \n",
      "                                                                 conv5_block7_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_0_bn (BatchNormali (None, 16, 16, 864)  3456        conv5_block7_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_0_relu (Activation (None, 16, 16, 864)  0           conv5_block8_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_1_conv (Conv2D)    (None, 16, 16, 128)  110592      conv5_block8_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_1_bn (BatchNormali (None, 16, 16, 128)  512         conv5_block8_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_1_relu (Activation (None, 16, 16, 128)  0           conv5_block8_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_2_conv (Conv2D)    (None, 16, 16, 32)   36864       conv5_block8_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_concat (Concatenat (None, 16, 16, 896)  0           conv5_block7_concat[0][0]        \n",
      "                                                                 conv5_block8_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_0_bn (BatchNormali (None, 16, 16, 896)  3584        conv5_block8_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_0_relu (Activation (None, 16, 16, 896)  0           conv5_block9_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_1_conv (Conv2D)    (None, 16, 16, 128)  114688      conv5_block9_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_1_bn (BatchNormali (None, 16, 16, 128)  512         conv5_block9_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_1_relu (Activation (None, 16, 16, 128)  0           conv5_block9_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_2_conv (Conv2D)    (None, 16, 16, 32)   36864       conv5_block9_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_concat (Concatenat (None, 16, 16, 928)  0           conv5_block8_concat[0][0]        \n",
      "                                                                 conv5_block9_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_0_bn (BatchNormal (None, 16, 16, 928)  3712        conv5_block9_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_0_relu (Activatio (None, 16, 16, 928)  0           conv5_block10_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_1_conv (Conv2D)   (None, 16, 16, 128)  118784      conv5_block10_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_1_bn (BatchNormal (None, 16, 16, 128)  512         conv5_block10_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_1_relu (Activatio (None, 16, 16, 128)  0           conv5_block10_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_2_conv (Conv2D)   (None, 16, 16, 32)   36864       conv5_block10_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_concat (Concatena (None, 16, 16, 960)  0           conv5_block9_concat[0][0]        \n",
      "                                                                 conv5_block10_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_0_bn (BatchNormal (None, 16, 16, 960)  3840        conv5_block10_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_0_relu (Activatio (None, 16, 16, 960)  0           conv5_block11_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_1_conv (Conv2D)   (None, 16, 16, 128)  122880      conv5_block11_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_1_bn (BatchNormal (None, 16, 16, 128)  512         conv5_block11_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_1_relu (Activatio (None, 16, 16, 128)  0           conv5_block11_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_2_conv (Conv2D)   (None, 16, 16, 32)   36864       conv5_block11_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_concat (Concatena (None, 16, 16, 992)  0           conv5_block10_concat[0][0]       \n",
      "                                                                 conv5_block11_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_0_bn (BatchNormal (None, 16, 16, 992)  3968        conv5_block11_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_0_relu (Activatio (None, 16, 16, 992)  0           conv5_block12_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_1_conv (Conv2D)   (None, 16, 16, 128)  126976      conv5_block12_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_1_bn (BatchNormal (None, 16, 16, 128)  512         conv5_block12_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_1_relu (Activatio (None, 16, 16, 128)  0           conv5_block12_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_2_conv (Conv2D)   (None, 16, 16, 32)   36864       conv5_block12_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_concat (Concatena (None, 16, 16, 1024) 0           conv5_block11_concat[0][0]       \n",
      "                                                                 conv5_block12_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_0_bn (BatchNormal (None, 16, 16, 1024) 4096        conv5_block12_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_0_relu (Activatio (None, 16, 16, 1024) 0           conv5_block13_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_1_conv (Conv2D)   (None, 16, 16, 128)  131072      conv5_block13_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_1_bn (BatchNormal (None, 16, 16, 128)  512         conv5_block13_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_1_relu (Activatio (None, 16, 16, 128)  0           conv5_block13_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_2_conv (Conv2D)   (None, 16, 16, 32)   36864       conv5_block13_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_concat (Concatena (None, 16, 16, 1056) 0           conv5_block12_concat[0][0]       \n",
      "                                                                 conv5_block13_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_0_bn (BatchNormal (None, 16, 16, 1056) 4224        conv5_block13_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_0_relu (Activatio (None, 16, 16, 1056) 0           conv5_block14_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_1_conv (Conv2D)   (None, 16, 16, 128)  135168      conv5_block14_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_1_bn (BatchNormal (None, 16, 16, 128)  512         conv5_block14_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_1_relu (Activatio (None, 16, 16, 128)  0           conv5_block14_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_2_conv (Conv2D)   (None, 16, 16, 32)   36864       conv5_block14_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_concat (Concatena (None, 16, 16, 1088) 0           conv5_block13_concat[0][0]       \n",
      "                                                                 conv5_block14_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_0_bn (BatchNormal (None, 16, 16, 1088) 4352        conv5_block14_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_0_relu (Activatio (None, 16, 16, 1088) 0           conv5_block15_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_1_conv (Conv2D)   (None, 16, 16, 128)  139264      conv5_block15_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_1_bn (BatchNormal (None, 16, 16, 128)  512         conv5_block15_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_1_relu (Activatio (None, 16, 16, 128)  0           conv5_block15_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_2_conv (Conv2D)   (None, 16, 16, 32)   36864       conv5_block15_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_concat (Concatena (None, 16, 16, 1120) 0           conv5_block14_concat[0][0]       \n",
      "                                                                 conv5_block15_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_0_bn (BatchNormal (None, 16, 16, 1120) 4480        conv5_block15_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_0_relu (Activatio (None, 16, 16, 1120) 0           conv5_block16_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_1_conv (Conv2D)   (None, 16, 16, 128)  143360      conv5_block16_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_1_bn (BatchNormal (None, 16, 16, 128)  512         conv5_block16_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_1_relu (Activatio (None, 16, 16, 128)  0           conv5_block16_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_2_conv (Conv2D)   (None, 16, 16, 32)   36864       conv5_block16_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_concat (Concatena (None, 16, 16, 1152) 0           conv5_block15_concat[0][0]       \n",
      "                                                                 conv5_block16_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block17_0_bn (BatchNormal (None, 16, 16, 1152) 4608        conv5_block16_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block17_0_relu (Activatio (None, 16, 16, 1152) 0           conv5_block17_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block17_1_conv (Conv2D)   (None, 16, 16, 128)  147456      conv5_block17_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block17_1_bn (BatchNormal (None, 16, 16, 128)  512         conv5_block17_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block17_1_relu (Activatio (None, 16, 16, 128)  0           conv5_block17_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block17_2_conv (Conv2D)   (None, 16, 16, 32)   36864       conv5_block17_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block17_concat (Concatena (None, 16, 16, 1184) 0           conv5_block16_concat[0][0]       \n",
      "                                                                 conv5_block17_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block18_0_bn (BatchNormal (None, 16, 16, 1184) 4736        conv5_block17_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block18_0_relu (Activatio (None, 16, 16, 1184) 0           conv5_block18_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block18_1_conv (Conv2D)   (None, 16, 16, 128)  151552      conv5_block18_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block18_1_bn (BatchNormal (None, 16, 16, 128)  512         conv5_block18_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block18_1_relu (Activatio (None, 16, 16, 128)  0           conv5_block18_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block18_2_conv (Conv2D)   (None, 16, 16, 32)   36864       conv5_block18_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block18_concat (Concatena (None, 16, 16, 1216) 0           conv5_block17_concat[0][0]       \n",
      "                                                                 conv5_block18_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block19_0_bn (BatchNormal (None, 16, 16, 1216) 4864        conv5_block18_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block19_0_relu (Activatio (None, 16, 16, 1216) 0           conv5_block19_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block19_1_conv (Conv2D)   (None, 16, 16, 128)  155648      conv5_block19_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block19_1_bn (BatchNormal (None, 16, 16, 128)  512         conv5_block19_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block19_1_relu (Activatio (None, 16, 16, 128)  0           conv5_block19_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block19_2_conv (Conv2D)   (None, 16, 16, 32)   36864       conv5_block19_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block19_concat (Concatena (None, 16, 16, 1248) 0           conv5_block18_concat[0][0]       \n",
      "                                                                 conv5_block19_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block20_0_bn (BatchNormal (None, 16, 16, 1248) 4992        conv5_block19_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block20_0_relu (Activatio (None, 16, 16, 1248) 0           conv5_block20_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block20_1_conv (Conv2D)   (None, 16, 16, 128)  159744      conv5_block20_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block20_1_bn (BatchNormal (None, 16, 16, 128)  512         conv5_block20_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block20_1_relu (Activatio (None, 16, 16, 128)  0           conv5_block20_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block20_2_conv (Conv2D)   (None, 16, 16, 32)   36864       conv5_block20_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block20_concat (Concatena (None, 16, 16, 1280) 0           conv5_block19_concat[0][0]       \n",
      "                                                                 conv5_block20_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block21_0_bn (BatchNormal (None, 16, 16, 1280) 5120        conv5_block20_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block21_0_relu (Activatio (None, 16, 16, 1280) 0           conv5_block21_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block21_1_conv (Conv2D)   (None, 16, 16, 128)  163840      conv5_block21_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block21_1_bn (BatchNormal (None, 16, 16, 128)  512         conv5_block21_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block21_1_relu (Activatio (None, 16, 16, 128)  0           conv5_block21_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block21_2_conv (Conv2D)   (None, 16, 16, 32)   36864       conv5_block21_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block21_concat (Concatena (None, 16, 16, 1312) 0           conv5_block20_concat[0][0]       \n",
      "                                                                 conv5_block21_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block22_0_bn (BatchNormal (None, 16, 16, 1312) 5248        conv5_block21_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block22_0_relu (Activatio (None, 16, 16, 1312) 0           conv5_block22_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block22_1_conv (Conv2D)   (None, 16, 16, 128)  167936      conv5_block22_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block22_1_bn (BatchNormal (None, 16, 16, 128)  512         conv5_block22_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block22_1_relu (Activatio (None, 16, 16, 128)  0           conv5_block22_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block22_2_conv (Conv2D)   (None, 16, 16, 32)   36864       conv5_block22_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block22_concat (Concatena (None, 16, 16, 1344) 0           conv5_block21_concat[0][0]       \n",
      "                                                                 conv5_block22_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block23_0_bn (BatchNormal (None, 16, 16, 1344) 5376        conv5_block22_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block23_0_relu (Activatio (None, 16, 16, 1344) 0           conv5_block23_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block23_1_conv (Conv2D)   (None, 16, 16, 128)  172032      conv5_block23_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block23_1_bn (BatchNormal (None, 16, 16, 128)  512         conv5_block23_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block23_1_relu (Activatio (None, 16, 16, 128)  0           conv5_block23_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block23_2_conv (Conv2D)   (None, 16, 16, 32)   36864       conv5_block23_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block23_concat (Concatena (None, 16, 16, 1376) 0           conv5_block22_concat[0][0]       \n",
      "                                                                 conv5_block23_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block24_0_bn (BatchNormal (None, 16, 16, 1376) 5504        conv5_block23_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block24_0_relu (Activatio (None, 16, 16, 1376) 0           conv5_block24_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block24_1_conv (Conv2D)   (None, 16, 16, 128)  176128      conv5_block24_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block24_1_bn (BatchNormal (None, 16, 16, 128)  512         conv5_block24_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block24_1_relu (Activatio (None, 16, 16, 128)  0           conv5_block24_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block24_2_conv (Conv2D)   (None, 16, 16, 32)   36864       conv5_block24_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block24_concat (Concatena (None, 16, 16, 1408) 0           conv5_block23_concat[0][0]       \n",
      "                                                                 conv5_block24_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block25_0_bn (BatchNormal (None, 16, 16, 1408) 5632        conv5_block24_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block25_0_relu (Activatio (None, 16, 16, 1408) 0           conv5_block25_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block25_1_conv (Conv2D)   (None, 16, 16, 128)  180224      conv5_block25_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block25_1_bn (BatchNormal (None, 16, 16, 128)  512         conv5_block25_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block25_1_relu (Activatio (None, 16, 16, 128)  0           conv5_block25_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block25_2_conv (Conv2D)   (None, 16, 16, 32)   36864       conv5_block25_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block25_concat (Concatena (None, 16, 16, 1440) 0           conv5_block24_concat[0][0]       \n",
      "                                                                 conv5_block25_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block26_0_bn (BatchNormal (None, 16, 16, 1440) 5760        conv5_block25_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block26_0_relu (Activatio (None, 16, 16, 1440) 0           conv5_block26_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block26_1_conv (Conv2D)   (None, 16, 16, 128)  184320      conv5_block26_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block26_1_bn (BatchNormal (None, 16, 16, 128)  512         conv5_block26_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block26_1_relu (Activatio (None, 16, 16, 128)  0           conv5_block26_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block26_2_conv (Conv2D)   (None, 16, 16, 32)   36864       conv5_block26_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block26_concat (Concatena (None, 16, 16, 1472) 0           conv5_block25_concat[0][0]       \n",
      "                                                                 conv5_block26_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block27_0_bn (BatchNormal (None, 16, 16, 1472) 5888        conv5_block26_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block27_0_relu (Activatio (None, 16, 16, 1472) 0           conv5_block27_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block27_1_conv (Conv2D)   (None, 16, 16, 128)  188416      conv5_block27_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block27_1_bn (BatchNormal (None, 16, 16, 128)  512         conv5_block27_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block27_1_relu (Activatio (None, 16, 16, 128)  0           conv5_block27_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block27_2_conv (Conv2D)   (None, 16, 16, 32)   36864       conv5_block27_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block27_concat (Concatena (None, 16, 16, 1504) 0           conv5_block26_concat[0][0]       \n",
      "                                                                 conv5_block27_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block28_0_bn (BatchNormal (None, 16, 16, 1504) 6016        conv5_block27_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block28_0_relu (Activatio (None, 16, 16, 1504) 0           conv5_block28_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block28_1_conv (Conv2D)   (None, 16, 16, 128)  192512      conv5_block28_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block28_1_bn (BatchNormal (None, 16, 16, 128)  512         conv5_block28_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block28_1_relu (Activatio (None, 16, 16, 128)  0           conv5_block28_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block28_2_conv (Conv2D)   (None, 16, 16, 32)   36864       conv5_block28_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block28_concat (Concatena (None, 16, 16, 1536) 0           conv5_block27_concat[0][0]       \n",
      "                                                                 conv5_block28_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block29_0_bn (BatchNormal (None, 16, 16, 1536) 6144        conv5_block28_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block29_0_relu (Activatio (None, 16, 16, 1536) 0           conv5_block29_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block29_1_conv (Conv2D)   (None, 16, 16, 128)  196608      conv5_block29_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block29_1_bn (BatchNormal (None, 16, 16, 128)  512         conv5_block29_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block29_1_relu (Activatio (None, 16, 16, 128)  0           conv5_block29_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block29_2_conv (Conv2D)   (None, 16, 16, 32)   36864       conv5_block29_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block29_concat (Concatena (None, 16, 16, 1568) 0           conv5_block28_concat[0][0]       \n",
      "                                                                 conv5_block29_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block30_0_bn (BatchNormal (None, 16, 16, 1568) 6272        conv5_block29_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block30_0_relu (Activatio (None, 16, 16, 1568) 0           conv5_block30_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block30_1_conv (Conv2D)   (None, 16, 16, 128)  200704      conv5_block30_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block30_1_bn (BatchNormal (None, 16, 16, 128)  512         conv5_block30_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block30_1_relu (Activatio (None, 16, 16, 128)  0           conv5_block30_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block30_2_conv (Conv2D)   (None, 16, 16, 32)   36864       conv5_block30_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block30_concat (Concatena (None, 16, 16, 1600) 0           conv5_block29_concat[0][0]       \n",
      "                                                                 conv5_block30_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block31_0_bn (BatchNormal (None, 16, 16, 1600) 6400        conv5_block30_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block31_0_relu (Activatio (None, 16, 16, 1600) 0           conv5_block31_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block31_1_conv (Conv2D)   (None, 16, 16, 128)  204800      conv5_block31_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block31_1_bn (BatchNormal (None, 16, 16, 128)  512         conv5_block31_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block31_1_relu (Activatio (None, 16, 16, 128)  0           conv5_block31_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block31_2_conv (Conv2D)   (None, 16, 16, 32)   36864       conv5_block31_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block31_concat (Concatena (None, 16, 16, 1632) 0           conv5_block30_concat[0][0]       \n",
      "                                                                 conv5_block31_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block32_0_bn (BatchNormal (None, 16, 16, 1632) 6528        conv5_block31_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block32_0_relu (Activatio (None, 16, 16, 1632) 0           conv5_block32_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block32_1_conv (Conv2D)   (None, 16, 16, 128)  208896      conv5_block32_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block32_1_bn (BatchNormal (None, 16, 16, 128)  512         conv5_block32_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block32_1_relu (Activatio (None, 16, 16, 128)  0           conv5_block32_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block32_2_conv (Conv2D)   (None, 16, 16, 32)   36864       conv5_block32_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block32_concat (Concatena (None, 16, 16, 1664) 0           conv5_block31_concat[0][0]       \n",
      "                                                                 conv5_block32_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "bn (BatchNormalization)         (None, 16, 16, 1664) 6656        conv5_block32_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "relu (Activation)               (None, 16, 16, 1664) 0           bn[0][0]                         \n",
      "==================================================================================================\n",
      "Total params: 12,642,880\n",
      "Trainable params: 0\n",
      "Non-trainable params: 12,642,880\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "densenet169 (Model)          (None, 16, 16, 1664)      12642880  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 1664)              0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1664)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 1664)              6656      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1664)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               852480    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 1026      \n",
      "=================================================================\n",
      "Total params: 13,505,090\n",
      "Trainable params: 857,858\n",
      "Non-trainable params: 12,647,232\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "    \n",
    "global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
    "global_max_layer = tf.keras.layers.GlobalMaxPool2D()\n",
    "flatten = tf.keras.layers.Flatten()\n",
    "\n",
    "batch_norm_1 = tf.keras.layers.BatchNormalization()\n",
    "drop_out_1 = tf.keras.layers.Dropout(0.25)\n",
    "dense_layer_1 = tf.keras.layers.Dense(512,activation='relu')\n",
    "\n",
    "batch_norm_2 = tf.keras.layers.BatchNormalization()\n",
    "drop_out_2 = tf.keras.layers.Dropout(0.5)\n",
    "\n",
    "\n",
    "\n",
    "prediction_layer = tf.keras.layers.Dense(2)\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "      base_model,\n",
    "      global_average_layer,\n",
    "      #global_max_layer,\n",
    "      flatten,\n",
    "      batch_norm_1,\n",
    "      drop_out_1,\n",
    "      dense_layer_1,\n",
    "      batch_norm_2,\n",
    "      drop_out_2,\n",
    "      prediction_layer\n",
    "])\n",
    "\n",
    "    \n",
    "model.compile(optimizer=optimizer,\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lr_finder = LRFinder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _ = model.fit_generator(train_data_gen,\n",
    "#                    epochs=1,\n",
    "#                    validation_data=validation_data_gen, \n",
    "#                    steps_per_epoch=STEPS_PER_EPOCH, \n",
    "#                    validation_steps=VAL_STEPS_PER_EPOCH,\n",
    "#                    callbacks=[lr_finder])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lr_finder.plot() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "400/400 [==============================] - 329s 823ms/step - loss: 0.9759 - accuracy: 0.5352 - val_loss: 0.9773 - val_accuracy: 0.5570\n",
      "Epoch 2/6\n",
      "400/400 [==============================] - 324s 811ms/step - loss: 0.8543 - accuracy: 0.5859 - val_loss: 0.9725 - val_accuracy: 0.5846\n",
      "Epoch 3/6\n",
      "400/400 [==============================] - 317s 792ms/step - loss: 0.7271 - accuracy: 0.6330 - val_loss: 1.2535 - val_accuracy: 0.5457\n",
      "Epoch 4/6\n",
      "400/400 [==============================] - 328s 819ms/step - loss: 0.6788 - accuracy: 0.6566 - val_loss: 1.0611 - val_accuracy: 0.5564\n",
      "Epoch 5/6\n",
      "301/400 [=====================>........] - ETA: 1:05 - loss: 0.6847 - accuracy: 0.6458"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(train_data_gen,\n",
    "                    epochs=epochs,\n",
    "                    validation_data=validation_data_gen, \n",
    "                    steps_per_epoch=STEPS_PER_EPOCH, \n",
    "                    validation_steps=VAL_STEPS_PER_EPOCH,\n",
    "                    callbacks=[lr_schedule])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_schedule.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss=history.history['loss']\n",
    "val_loss=history.history['val_loss']\n",
    "\n",
    "epochs_range = range(epochs)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.15399627, 0.15399627, 0.15399627], dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_batch[0][0][6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load using tf.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_ds = tf.data.Dataset.list_files(str(data_dir/'*/*'))\n",
    "\n",
    "val_list_ds = tf.data.Dataset.list_files(str(val_data_dir/'*/*'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'/opt/AIStorage/PLAYGROUND/data/train/negative/2.25.1220173694489917139572089178995042798.png'\n",
      "b'/opt/AIStorage/PLAYGROUND/data/train/negative/2.25.39943569472121983261799650628052841383.png'\n",
      "b'/opt/AIStorage/PLAYGROUND/data/train/negative/2.25.292089496863278377124371205019916419751.png'\n",
      "b'/opt/AIStorage/PLAYGROUND/data/train/positive/2.25.32700430559969432915927465016145140545.png'\n",
      "b'/opt/AIStorage/PLAYGROUND/data/train/positive/2.25.111831954053833773869813754394525291700.png'\n"
     ]
    }
   ],
   "source": [
    "for f in list_ds.take(5):\n",
    "  print(f.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'/opt/AIStorage/PLAYGROUND/data/validation/positive/2.25.148043796131358029584431036706072285921.png'\n",
      "b'/opt/AIStorage/PLAYGROUND/data/validation/negative/2.25.134359765825207226305787747241437173513.png'\n",
      "b'/opt/AIStorage/PLAYGROUND/data/validation/negative/2.25.216719201632140760501910854022855071278.png'\n",
      "b'/opt/AIStorage/PLAYGROUND/data/validation/negative/2.25.147768518981645575690513566047916354745.png'\n",
      "b'/opt/AIStorage/PLAYGROUND/data/validation/negative/2.25.199902571622777137324886246475034902730.png'\n"
     ]
    }
   ],
   "source": [
    "for f in val_list_ds.take(5):\n",
    "  print(f.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(file_path):\n",
    "  # convert the path to a list of path components\n",
    "  parts = tf.strings.split(file_path, os.path.sep)\n",
    "  # The second to last is the class-directory\n",
    "  label = -1\n",
    "  if parts[-2] == 'negative':\n",
    "    label = 0\n",
    "  else:\n",
    "    label = 1\n",
    "  return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_img(img):\n",
    "  # convert the compressed string to a 3D uint8 tensor\n",
    "  img = tf.image.decode_png(img, channels=3)\n",
    "  # Use `convert_image_dtype` to convert to floats in the [0,1] range.\n",
    "  img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "  # resize the image to the desired size.\n",
    "  return tf.image.resize(img, [IMG_WIDTH, IMG_HEIGHT])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_path(file_path):\n",
    "  label = get_label(file_path)\n",
    "  # load the raw data from the file as a string\n",
    "  img = tf.io.read_file(file_path)\n",
    "  img = decode_img(img)\n",
    "  return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set `num_parallel_calls` so multiple images are loaded/processed in parallel.\n",
    "labeled_ds = list_ds.map(process_path, num_parallel_calls=AUTOTUNE)\n",
    "\n",
    "val_labeled_ds = val_list_ds.map(process_path, num_parallel_calls=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape:  (224, 224, 3)\n",
      "Label:  0\n"
     ]
    }
   ],
   "source": [
    "for image, label in labeled_ds.take(1):\n",
    "  print(\"Image shape: \", image.numpy().shape)\n",
    "  print(\"Label: \", label.numpy())\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape:  (224, 224, 3)\n",
      "Label:  0\n"
     ]
    }
   ],
   "source": [
    "for image, label in val_labeled_ds.take(1):\n",
    "  print(\"Image shape: \", image.numpy().shape)\n",
    "  print(\"Label: \", label.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_for_training(ds, shuffle=True, cache=True, shuffle_buffer_size=1000):\n",
    "  # This is a small dataset, only load it once, and keep it in memory.\n",
    "  # use `.cache(filename)` to cache preprocessing work for datasets that don't\n",
    "  # fit in memory.\n",
    "  if cache:\n",
    "    if isinstance(cache, str):\n",
    "      ds = ds.cache(cache)\n",
    "    else:\n",
    "      ds = ds.cache()\n",
    "\n",
    "  if shuffle:\n",
    "    ds = ds.shuffle(buffer_size=shuffle_buffer_size)\n",
    "\n",
    "  # Repeat forever\n",
    "  ds = ds.repeat()\n",
    "\n",
    "  ds = ds.batch(BATCH_SIZE)\n",
    "\n",
    "  # `prefetch` lets the dataset fetch batches in the background while the model\n",
    "  # is training.\n",
    "  ds = ds.prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "  return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = prepare_for_training(labeled_ds)\n",
    "\n",
    "valid_ds = prepare_for_training(val_labeled_ds, shuffle=False)\n",
    "#valid_ds = val_labeled_ds\n",
    "\n",
    "image_batch, label_batch = next(iter(train_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#show_batch(image_batch.numpy(), label_batch.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CosineAnnealer:\n",
    "    \n",
    "    def __init__(self, start, end, steps):\n",
    "        self.start = start\n",
    "        self.end = end\n",
    "        self.steps = steps\n",
    "        self.n = 0\n",
    "        \n",
    "    def step(self):\n",
    "        self.n += 1\n",
    "        cos = np.cos(np.pi * (self.n / self.steps)) + 1\n",
    "        return self.end + (self.start - self.end) / 2. * cos\n",
    "\n",
    "\n",
    "class OneCycleScheduler(Callback):\n",
    " \n",
    "\n",
    "    def __init__(self, lr_max, steps, mom_min=0.85, mom_max=0.95, phase_1_pct=0.3, div_factor=25.):\n",
    "        super(OneCycleScheduler, self).__init__()\n",
    "        lr_min = lr_max / div_factor\n",
    "        final_lr = lr_max / (div_factor * 1e4)\n",
    "        phase_1_steps = steps * phase_1_pct\n",
    "        phase_2_steps = steps - phase_1_steps\n",
    "        \n",
    "        self.phase_1_steps = phase_1_steps\n",
    "        self.phase_2_steps = phase_2_steps\n",
    "        self.phase = 0\n",
    "        self.step = 0\n",
    "        \n",
    "        self.phases = [[CosineAnnealer(lr_min, lr_max, phase_1_steps), CosineAnnealer(mom_max, mom_min, phase_1_steps)], \n",
    "                 [CosineAnnealer(lr_max, final_lr, phase_2_steps), CosineAnnealer(mom_min, mom_max, phase_2_steps)]]\n",
    "        \n",
    "        self.lrs = []\n",
    "        self.moms = []\n",
    "\n",
    "    def on_train_begin(self, logs=None):\n",
    "        self.phase = 0\n",
    "        self.step = 0\n",
    "\n",
    "        self.set_lr(self.lr_schedule().start)\n",
    "        self.set_momentum(self.mom_schedule().start)\n",
    "        \n",
    "    def on_train_batch_begin(self, batch, logs=None):\n",
    "        self.lrs.append(self.get_lr())\n",
    "        self.moms.append(self.get_momentum())\n",
    "\n",
    "    def on_train_batch_end(self, batch, logs=None):\n",
    "        self.step += 1\n",
    "        if self.step >= self.phase_1_steps:\n",
    "            self.phase = 1\n",
    "            \n",
    "        self.set_lr(self.lr_schedule().step())\n",
    "        self.set_momentum(self.mom_schedule().step())\n",
    "        \n",
    "    def get_lr(self):\n",
    "        try:\n",
    "            return tf.keras.backend.get_value(self.model.optimizer.lr)\n",
    "        except AttributeError:\n",
    "            print('get lr error')\n",
    "            return None\n",
    "        \n",
    "    def get_momentum(self):\n",
    "        try:\n",
    "            return tf.keras.backend.get_value(self.model.optimizer.momentum)\n",
    "        except AttributeError:\n",
    "            print('get momentum error')\n",
    "            return None\n",
    "        \n",
    "    def set_lr(self, lr):\n",
    "        try:\n",
    "            tf.keras.backend.set_value(self.model.optimizer.lr, lr)\n",
    "        except AttributeError:\n",
    "            print('set lr error')\n",
    "            pass # ignore\n",
    "        \n",
    "    def set_momentum(self, mom):\n",
    "        try:\n",
    "            tf.keras.backend.set_value(self.model.optimizer.momentum, mom)\n",
    "        except AttributeError:\n",
    "            print('set momentum error')\n",
    "            pass # ignore\n",
    "\n",
    "    def lr_schedule(self):\n",
    "        return self.phases[self.phase][0]\n",
    "    \n",
    "    def mom_schedule(self):\n",
    "        return self.phases[self.phase][1]\n",
    "    \n",
    "    def plot(self):\n",
    "        ax = plt.subplot(1, 2, 1)\n",
    "        ax.plot(self.lrs)\n",
    "        ax.set_title('Learning Rate')\n",
    "        ax = plt.subplot(1, 2, 2)\n",
    "        ax.plot(self.moms)\n",
    "        ax.set_title('Momentum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "(8, 7, 7, 2048)\n",
      "(8, 2048)\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "resnet50 (Model)             (None, 7, 7, 2048)        23587712  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2048)              4196352   \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2048)              4196352   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 2049      \n",
      "=================================================================\n",
      "Total params: 31,982,465\n",
      "Trainable params: 8,394,753\n",
      "Non-trainable params: 23,587,712\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "IMG_SHAPE = (IMG_HEIGHT, IMG_WIDTH, 3)\n",
    "lr = 3e-3\n",
    "steps = np.ceil(image_count / BATCH_SIZE) * epochs\n",
    "lr_schedule = OneCycleScheduler(lr, steps)\n",
    "\n",
    "\n",
    "mirrored_strategy = tf.distribute.MirroredStrategy(devices=[\"/gpu:0\", \"/gpu:1\"])\n",
    "with mirrored_strategy.scope():\n",
    "\n",
    "    base_model = tf.keras.applications.ResNet50(input_shape=IMG_SHAPE,\n",
    "                                               include_top=False,\n",
    "                                               weights='imagenet')\n",
    "\n",
    "    feature_batch = base_model(image_batch)\n",
    "    print(feature_batch.shape)\n",
    "    base_model.trainable = False\n",
    "    \n",
    "    global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
    "    feature_batch_average = global_average_layer(feature_batch)\n",
    "    print(feature_batch_average.shape)\n",
    "\n",
    "    \n",
    "    dense_layer_1 = tf.keras.layers.Dense(2048,activation='relu')\n",
    "    drop_out_1 = tf.keras.layers.Dropout(0.3)\n",
    "    dense_layer_2 = tf.keras.layers.Dense(2048,activation='relu')\n",
    "    drop_out_2 = tf.keras.layers.Dropout(0.3)\n",
    "    prediction_layer = tf.keras.layers.Dense(1)\n",
    "    #prediction_batch = prediction_layer(feature_batch_average)\n",
    "    #print(prediction_batch.shape)\n",
    "\n",
    "    model = tf.keras.Sequential([\n",
    "      base_model,\n",
    "      global_average_layer,\n",
    "      dense_layer_1,\n",
    "      drop_out_1,\n",
    "      dense_layer_2,\n",
    "      drop_out_2,\n",
    "      prediction_layer\n",
    "    ])\n",
    "\n",
    "    \n",
    "    model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "    model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 400.0 steps, validate for 100.0 steps\n",
      "Epoch 1/20\n",
      "INFO:tensorflow:batch_all_reduce: 6 all-reduces with algorithm = nccl, num_packs = 1, agg_small_grads_max_bytes = 0 and agg_small_grads_max_group = 10\n",
      "INFO:tensorflow:batch_all_reduce: 6 all-reduces with algorithm = nccl, num_packs = 1, agg_small_grads_max_bytes = 0 and agg_small_grads_max_group = 10\n",
      "400/400 [==============================] - 100s 250ms/step - loss: 0.7360 - accuracy: 0.5931 - val_loss: 0.7034 - val_accuracy: 0.5175\n",
      "Epoch 2/20\n",
      "400/400 [==============================] - 12s 30ms/step - loss: 0.6235 - accuracy: 0.6284 - val_loss: 0.6997 - val_accuracy: 0.5175\n",
      "Epoch 3/20\n",
      "400/400 [==============================] - 12s 30ms/step - loss: 0.6160 - accuracy: 0.6444 - val_loss: 0.7054 - val_accuracy: 0.5175\n",
      "Epoch 4/20\n",
      "400/400 [==============================] - 12s 30ms/step - loss: 0.6045 - accuracy: 0.6484 - val_loss: 0.7003 - val_accuracy: 0.5175\n",
      "Epoch 5/20\n",
      "400/400 [==============================] - 12s 30ms/step - loss: 0.5959 - accuracy: 0.6409 - val_loss: 0.6965 - val_accuracy: 0.5175\n",
      "Epoch 6/20\n",
      "400/400 [==============================] - 12s 30ms/step - loss: 0.5940 - accuracy: 0.6575 - val_loss: 0.7122 - val_accuracy: 0.5175\n",
      "Epoch 7/20\n",
      "400/400 [==============================] - 12s 30ms/step - loss: 0.5816 - accuracy: 0.6506 - val_loss: 0.7029 - val_accuracy: 0.5175\n",
      "Epoch 8/20\n",
      "400/400 [==============================] - 12s 30ms/step - loss: 0.5747 - accuracy: 0.6637 - val_loss: 0.6967 - val_accuracy: 0.5175\n",
      "Epoch 9/20\n",
      "400/400 [==============================] - 12s 30ms/step - loss: 0.5736 - accuracy: 0.6719 - val_loss: 0.7000 - val_accuracy: 0.5175\n",
      "Epoch 10/20\n",
      "400/400 [==============================] - 12s 30ms/step - loss: 0.5700 - accuracy: 0.6734 - val_loss: 0.6954 - val_accuracy: 0.5175\n",
      "Epoch 11/20\n",
      "400/400 [==============================] - 12s 30ms/step - loss: 0.5655 - accuracy: 0.6784 - val_loss: 0.6961 - val_accuracy: 0.5175\n",
      "Epoch 12/20\n",
      "400/400 [==============================] - 12s 30ms/step - loss: 0.5522 - accuracy: 0.6766 - val_loss: 0.6994 - val_accuracy: 0.5175\n",
      "Epoch 13/20\n",
      "400/400 [==============================] - 12s 30ms/step - loss: 0.5487 - accuracy: 0.6850 - val_loss: 0.6976 - val_accuracy: 0.5175\n",
      "Epoch 14/20\n",
      "400/400 [==============================] - 12s 30ms/step - loss: 0.5505 - accuracy: 0.6837 - val_loss: 0.7037 - val_accuracy: 0.5175\n",
      "Epoch 15/20\n",
      "400/400 [==============================] - 12s 30ms/step - loss: 0.5541 - accuracy: 0.6837 - val_loss: 0.7037 - val_accuracy: 0.5175\n",
      "Epoch 16/20\n",
      "400/400 [==============================] - 12s 30ms/step - loss: 0.5441 - accuracy: 0.6950 - val_loss: 0.6986 - val_accuracy: 0.5175\n",
      "Epoch 17/20\n",
      "400/400 [==============================] - 12s 30ms/step - loss: 0.5432 - accuracy: 0.6928 - val_loss: 0.6974 - val_accuracy: 0.5175\n",
      "Epoch 18/20\n",
      "400/400 [==============================] - 12s 30ms/step - loss: 0.5503 - accuracy: 0.6994 - val_loss: 0.7069 - val_accuracy: 0.5175\n",
      "Epoch 19/20\n",
      "400/400 [==============================] - 12s 30ms/step - loss: 0.5472 - accuracy: 0.6803 - val_loss: 0.7116 - val_accuracy: 0.5175\n",
      "Epoch 20/20\n",
      "400/400 [==============================] - 12s 30ms/step - loss: 0.5428 - accuracy: 0.6900 - val_loss: 0.6960 - val_accuracy: 0.5175\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_ds,\n",
    "                    epochs=20,\n",
    "                    validation_data=valid_ds, \n",
    "                    steps_per_epoch=STEPS_PER_EPOCH, \n",
    "                    validation_steps=VAL_STEPS_PER_EPOCH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf-gpu] *",
   "language": "python",
   "name": "conda-env-tf-gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
