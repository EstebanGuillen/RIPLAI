{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/HEALTH/ejguillen/anaconda3/envs/tf2.1-conda/lib/python3.7/site-packages/keras_applications/mobilenet.py:207: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "  warnings.warn('`input_shape` is undefined or non-square, '\n",
      "/home/HEALTH/ejguillen/anaconda3/envs/tf2.1-conda/lib/python3.7/site-packages/keras_applications/mobilenet_v2.py:294: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "  warnings.warn('`input_shape` is undefined or non-square, '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arch:  DenseNet121\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "densenet121 (Model)          (None, 16, 16, 1024)      7037504   \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_207 (Bat (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "batch_normalization_208 (Bat (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 1026      \n",
      "_________________________________________________________________\n",
      "batch_normalization_209 (Bat (None, 2)                 8         \n",
      "=================================================================\n",
      "Total params: 7,569,482\n",
      "Trainable params: 528,902\n",
      "Non-trainable params: 7,040,580\n",
      "_________________________________________________________________\n",
      "Train for 129.0 steps, validate for 33.0 steps\n",
      "INFO:tensorflow:batch_all_reduce: 10 all-reduces with algorithm = nccl, num_packs = 1, agg_small_grads_max_bytes = 0 and agg_small_grads_max_group = 10\n",
      "INFO:tensorflow:batch_all_reduce: 10 all-reduces with algorithm = nccl, num_packs = 1, agg_small_grads_max_bytes = 0 and agg_small_grads_max_group = 10\n",
      "129/129 [==============================] - 88s 682ms/step - loss: 0.5678 - acc: 0.6846 - val_loss: 0.6244 - val_acc: 0.6072\n",
      "Arch:  DenseNet169\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "densenet169 (Model)          (None, 16, 16, 1664)      12642880  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 1664)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_210 (Bat (None, 1664)              6656      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1664)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               852480    \n",
      "_________________________________________________________________\n",
      "batch_normalization_211 (Bat (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 1026      \n",
      "_________________________________________________________________\n",
      "batch_normalization_212 (Bat (None, 2)                 8         \n",
      "=================================================================\n",
      "Total params: 13,505,098\n",
      "Trainable params: 857,862\n",
      "Non-trainable params: 12,647,236\n",
      "_________________________________________________________________\n",
      "Train for 129.0 steps, validate for 33.0 steps\n",
      "INFO:tensorflow:batch_all_reduce: 10 all-reduces with algorithm = nccl, num_packs = 1, agg_small_grads_max_bytes = 0 and agg_small_grads_max_group = 10\n",
      "INFO:tensorflow:batch_all_reduce: 10 all-reduces with algorithm = nccl, num_packs = 1, agg_small_grads_max_bytes = 0 and agg_small_grads_max_group = 10\n",
      "129/129 [==============================] - 100s 774ms/step - loss: 0.5603 - acc: 0.6942 - val_loss: 0.6525 - val_acc: 0.6084\n",
      "Arch:  DenseNet201\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "densenet201 (Model)          (None, 16, 16, 1920)      18321984  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_2 ( (None, 1920)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_213 (Bat (None, 1920)              7680      \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 1920)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 512)               983552    \n",
      "_________________________________________________________________\n",
      "batch_normalization_214 (Bat (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 2)                 1026      \n",
      "_________________________________________________________________\n",
      "batch_normalization_215 (Bat (None, 2)                 8         \n",
      "=================================================================\n",
      "Total params: 19,316,298\n",
      "Trainable params: 989,446\n",
      "Non-trainable params: 18,326,852\n",
      "_________________________________________________________________\n",
      "Train for 129.0 steps, validate for 33.0 steps\n",
      "INFO:tensorflow:batch_all_reduce: 10 all-reduces with algorithm = nccl, num_packs = 1, agg_small_grads_max_bytes = 0 and agg_small_grads_max_group = 10\n",
      "INFO:tensorflow:batch_all_reduce: 10 all-reduces with algorithm = nccl, num_packs = 1, agg_small_grads_max_bytes = 0 and agg_small_grads_max_group = 10\n",
      "129/129 [==============================] - 120s 933ms/step - loss: 0.5674 - acc: 0.6867 - val_loss: 0.6159 - val_acc: 0.6212\n",
      "Arch:  InceptionResNetV2\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inception_resnet_v2 (Model)  (None, 14, 14, 1536)      54336736  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_3 ( (None, 1536)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_216 (Bat (None, 1536)              6144      \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 1536)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 512)               786944    \n",
      "_________________________________________________________________\n",
      "batch_normalization_217 (Bat (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 2)                 1026      \n",
      "_________________________________________________________________\n",
      "batch_normalization_218 (Bat (None, 2)                 8         \n",
      "=================================================================\n",
      "Total params: 55,132,906\n",
      "Trainable params: 792,070\n",
      "Non-trainable params: 54,340,836\n",
      "_________________________________________________________________\n",
      "Train for 129.0 steps, validate for 33.0 steps\n",
      "INFO:tensorflow:batch_all_reduce: 10 all-reduces with algorithm = nccl, num_packs = 1, agg_small_grads_max_bytes = 0 and agg_small_grads_max_group = 10\n",
      "INFO:tensorflow:batch_all_reduce: 10 all-reduces with algorithm = nccl, num_packs = 1, agg_small_grads_max_bytes = 0 and agg_small_grads_max_group = 10\n",
      "129/129 [==============================] - 138s 1s/step - loss: 0.5895 - acc: 0.6662 - val_loss: 0.6411 - val_acc: 0.5722\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arch:  MobileNet\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "mobilenet_1.00_224 (Model)   (None, 16, 16, 1024)      3228864   \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_4 ( (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_219 (Bat (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "batch_normalization_220 (Bat (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 2)                 1026      \n",
      "_________________________________________________________________\n",
      "batch_normalization_221 (Bat (None, 2)                 8         \n",
      "=================================================================\n",
      "Total params: 3,760,842\n",
      "Trainable params: 528,902\n",
      "Non-trainable params: 3,231,940\n",
      "_________________________________________________________________\n",
      "Train for 129.0 steps, validate for 33.0 steps\n",
      "INFO:tensorflow:batch_all_reduce: 10 all-reduces with algorithm = nccl, num_packs = 1, agg_small_grads_max_bytes = 0 and agg_small_grads_max_group = 10\n",
      "INFO:tensorflow:batch_all_reduce: 10 all-reduces with algorithm = nccl, num_packs = 1, agg_small_grads_max_bytes = 0 and agg_small_grads_max_group = 10\n",
      "129/129 [==============================] - 45s 346ms/step - loss: 0.5512 - acc: 0.7008 - val_loss: 0.9783 - val_acc: 0.4633\n",
      "Arch:  MobileNetV2\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "mobilenetv2_1.00_224 (Model) (None, 16, 16, 1280)      2257984   \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_5 ( (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_222 (Bat (None, 1280)              5120      \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 512)               655872    \n",
      "_________________________________________________________________\n",
      "batch_normalization_223 (Bat (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 2)                 1026      \n",
      "_________________________________________________________________\n",
      "batch_normalization_224 (Bat (None, 2)                 8         \n",
      "=================================================================\n",
      "Total params: 2,922,058\n",
      "Trainable params: 660,486\n",
      "Non-trainable params: 2,261,572\n",
      "_________________________________________________________________\n",
      "Train for 129.0 steps, validate for 33.0 steps\n",
      "129/129 [==============================] - 54s 418ms/step - loss: 0.5826 - acc: 0.6722 - val_loss: 0.6748 - val_acc: 0.5223\n",
      "Arch:  ResNet101\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "resnet101 (Model)            (None, 16, 16, 2048)      42658176  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_6 ( (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_225 (Bat (None, 2048)              8192      \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 512)               1049088   \n",
      "_________________________________________________________________\n",
      "batch_normalization_226 (Bat (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 2)                 1026      \n",
      "_________________________________________________________________\n",
      "batch_normalization_227 (Bat (None, 2)                 8         \n",
      "=================================================================\n",
      "Total params: 43,718,538\n",
      "Trainable params: 1,055,238\n",
      "Non-trainable params: 42,663,300\n",
      "_________________________________________________________________\n",
      "Train for 129.0 steps, validate for 33.0 steps\n",
      "129/129 [==============================] - 113s 872ms/step - loss: 0.5583 - acc: 0.6969 - val_loss: 0.9915 - val_acc: 0.4399\n",
      "Arch:  ResNet101V2\n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "resnet101v2 (Model)          (None, 16, 16, 2048)      42626560  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_7 ( (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_228 (Bat (None, 2048)              8192      \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 512)               1049088   \n",
      "_________________________________________________________________\n",
      "batch_normalization_229 (Bat (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 2)                 1026      \n",
      "_________________________________________________________________\n",
      "batch_normalization_230 (Bat (None, 2)                 8         \n",
      "=================================================================\n",
      "Total params: 43,686,922\n",
      "Trainable params: 1,055,238\n",
      "Non-trainable params: 42,631,684\n",
      "_________________________________________________________________\n",
      "Train for 129.0 steps, validate for 33.0 steps\n",
      "129/129 [==============================] - 104s 810ms/step - loss: 0.5490 - acc: 0.6989 - val_loss: 0.6378 - val_acc: 0.6257\n",
      "Arch:  ResNet152\n",
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "resnet152 (Model)            (None, 16, 16, 2048)      58370944  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_8 ( (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_231 (Bat (None, 2048)              8192      \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 512)               1049088   \n",
      "_________________________________________________________________\n",
      "batch_normalization_232 (Bat (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 2)                 1026      \n",
      "_________________________________________________________________\n",
      "batch_normalization_233 (Bat (None, 2)                 8         \n",
      "=================================================================\n",
      "Total params: 59,431,306\n",
      "Trainable params: 1,055,238\n",
      "Non-trainable params: 58,376,068\n",
      "_________________________________________________________________\n",
      "Train for 129.0 steps, validate for 33.0 steps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "129/129 [==============================] - 153s 1s/step - loss: 0.5589 - acc: 0.6925 - val_loss: 0.6925 - val_acc: 0.5000\n",
      "Arch:  ResNet152V2\n",
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "resnet152v2 (Model)          (None, 16, 16, 2048)      58331648  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_9 ( (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_234 (Bat (None, 2048)              8192      \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 512)               1049088   \n",
      "_________________________________________________________________\n",
      "batch_normalization_235 (Bat (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 2)                 1026      \n",
      "_________________________________________________________________\n",
      "batch_normalization_236 (Bat (None, 2)                 8         \n",
      "=================================================================\n",
      "Total params: 59,392,010\n",
      "Trainable params: 1,055,238\n",
      "Non-trainable params: 58,336,772\n",
      "_________________________________________________________________\n",
      "Train for 129.0 steps, validate for 33.0 steps\n",
      "129/129 [==============================] - 146s 1s/step - loss: 0.5620 - acc: 0.6912 - val_loss: 0.6045 - val_acc: 0.6446\n",
      "Arch:  ResNet50\n",
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "resnet50 (Model)             (None, 16, 16, 2048)      23587712  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_10  (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_237 (Bat (None, 2048)              8192      \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 512)               1049088   \n",
      "_________________________________________________________________\n",
      "batch_normalization_238 (Bat (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 2)                 1026      \n",
      "_________________________________________________________________\n",
      "batch_normalization_239 (Bat (None, 2)                 8         \n",
      "=================================================================\n",
      "Total params: 24,648,074\n",
      "Trainable params: 1,055,238\n",
      "Non-trainable params: 23,592,836\n",
      "_________________________________________________________________\n",
      "Train for 129.0 steps, validate for 33.0 steps\n",
      "129/129 [==============================] - 77s 594ms/step - loss: 0.5562 - acc: 0.6940 - val_loss: 1.3294 - val_acc: 0.4422\n",
      "Arch:  ResNet50V2\n",
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "resnet50v2 (Model)           (None, 16, 16, 2048)      23564800  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_11  (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_240 (Bat (None, 2048)              8192      \n",
      "_________________________________________________________________\n",
      "dropout_22 (Dropout)         (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 512)               1049088   \n",
      "_________________________________________________________________\n",
      "batch_normalization_241 (Bat (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dropout_23 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 2)                 1026      \n",
      "_________________________________________________________________\n",
      "batch_normalization_242 (Bat (None, 2)                 8         \n",
      "=================================================================\n",
      "Total params: 24,625,162\n",
      "Trainable params: 1,055,238\n",
      "Non-trainable params: 23,569,924\n",
      "_________________________________________________________________\n",
      "Train for 129.0 steps, validate for 33.0 steps\n",
      "129/129 [==============================] - 69s 533ms/step - loss: 0.5496 - acc: 0.7020 - val_loss: 0.6389 - val_acc: 0.6089\n",
      "Arch:  VGG16\n",
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg16 (Model)                (None, 16, 16, 512)       14714688  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_12  (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_243 (Bat (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dropout_24 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_244 (Bat (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dropout_25 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 2)                 1026      \n",
      "_________________________________________________________________\n",
      "batch_normalization_245 (Bat (None, 2)                 8         \n",
      "=================================================================\n",
      "Total params: 14,982,474\n",
      "Trainable params: 265,734\n",
      "Non-trainable params: 14,716,740\n",
      "_________________________________________________________________\n",
      "Train for 129.0 steps, validate for 33.0 steps\n",
      "129/129 [==============================] - 92s 710ms/step - loss: 0.5941 - acc: 0.6625 - val_loss: 0.6710 - val_acc: 0.5000\n",
      "Arch:  VGG19\n",
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg19 (Model)                (None, 16, 16, 512)       20024384  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_13  (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_246 (Bat (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dropout_26 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_247 (Bat (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dropout_27 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 2)                 1026      \n",
      "_________________________________________________________________\n",
      "batch_normalization_248 (Bat (None, 2)                 8         \n",
      "=================================================================\n",
      "Total params: 20,292,170\n",
      "Trainable params: 265,734\n",
      "Non-trainable params: 20,026,436\n",
      "_________________________________________________________________\n",
      "Train for 129.0 steps, validate for 33.0 steps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "129/129 [==============================] - 100s 773ms/step - loss: 0.6032 - acc: 0.6537 - val_loss: 0.6793 - val_acc: 0.5992\n",
      "Arch:  Xception\n",
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "xception (Model)             (None, 16, 16, 2048)      20861480  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_14  (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_249 (Bat (None, 2048)              8192      \n",
      "_________________________________________________________________\n",
      "dropout_28 (Dropout)         (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 512)               1049088   \n",
      "_________________________________________________________________\n",
      "batch_normalization_250 (Bat (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dropout_29 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 2)                 1026      \n",
      "_________________________________________________________________\n",
      "batch_normalization_251 (Bat (None, 2)                 8         \n",
      "=================================================================\n",
      "Total params: 21,921,842\n",
      "Trainable params: 1,055,238\n",
      "Non-trainable params: 20,866,604\n",
      "_________________________________________________________________\n",
      "Train for 129.0 steps, validate for 33.0 steps\n",
      "129/129 [==============================] - 94s 727ms/step - loss: 0.5747 - acc: 0.6788 - val_loss: 0.6345 - val_acc: 0.5608\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.mixed_precision import experimental as mixed_precision\n",
    "\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "\n",
    "import IPython.display as display\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pathlib\n",
    "\n",
    "import tensorflow.keras.applications\n",
    "\n",
    "from tensorflow.keras.applications import DenseNet121,DenseNet169,  \\\n",
    "                                          DenseNet201,InceptionResNetV2,  \\\n",
    "                                          InceptionV3,MobileNet,MobileNetV2,  \\\n",
    "                                          NASNetLarge,NASNetMobile,ResNet101,  \\\n",
    "                                          ResNet101V2,ResNet152,ResNet152V2,  \\\n",
    "                                          ResNet50,ResNet50V2,VGG16,VGG19,Xception  \n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "IMG_HEIGHT = 512\n",
    "IMG_WIDTH = 512\n",
    "EPOCHS = 25\n",
    "lr = 3e-3\n",
    "CHANNELS =3\n",
    "IMG_SHAPE = (IMG_HEIGHT, IMG_WIDTH, CHANNELS)\n",
    "\n",
    "FILTER_SIZE = 3\n",
    "\n",
    "lrs = [1e-4, 3e-3, 1e-2]\n",
    "batch_sizes = [16,32,64]\n",
    "\n",
    "val_data_dir = '/opt/AIStorage/PLAYGROUND/images/1024/validation'\n",
    "val_data_dir = pathlib.Path(val_data_dir)\n",
    "\n",
    "data_dir = '/opt/AIStorage/PLAYGROUND/images/1024/train'\n",
    "data_dir = pathlib.Path(data_dir)\n",
    "\n",
    "image_count = len(list(data_dir.glob('*/*.png')))\n",
    "\n",
    "val_image_count = len(list(val_data_dir.glob('*/*.png')))\n",
    "\n",
    "list_ds = tf.data.Dataset.list_files(str(data_dir/'*/*'))\n",
    "\n",
    "val_list_ds = tf.data.Dataset.list_files(str(val_data_dir/'*/*'))\n",
    "\n",
    "def get_label(file_path):\n",
    "    # convert the path to a list of path components\n",
    "    parts = tf.strings.split(file_path, os.path.sep)\n",
    "    # The second to last is the class-directory\n",
    "    label = -1\n",
    "    if parts[-2] == 'negative':\n",
    "        label = tf.constant([1.0, 0.0])\n",
    "    else:\n",
    "        label = tf.constant([0.0, 1.0])\n",
    "    return label\n",
    "\n",
    "def decode_img(img):\n",
    "    # convert the compressed string to a 3D uint8 tensor\n",
    "    img = tf.image.decode_png(img, channels=CHANNELS)\n",
    "    # Use `convert_image_dtype` to convert to floats in the [0,1] range.\n",
    "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "    # resize the image to the desired size.\n",
    "    return tf.image.resize(img, [IMG_WIDTH, IMG_HEIGHT])\n",
    "\n",
    "def process_path(file_path):\n",
    "    label = get_label(file_path)\n",
    "    # load the raw data from the file as a string\n",
    "    img = tf.io.read_file(file_path)\n",
    "    img = decode_img(img)\n",
    "    return img, label\n",
    "\n",
    "# Set `num_parallel_calls` so multiple images are loaded/processed in parallel.\n",
    "labeled_ds = list_ds.map(process_path, num_parallel_calls=AUTOTUNE)\n",
    "\n",
    "val_labeled_ds = val_list_ds.map(process_path, num_parallel_calls=AUTOTUNE)\n",
    "\n",
    "STEPS_PER_EPOCH = np.ceil(image_count/BATCH_SIZE)\n",
    "VAL_STEPS_PER_EPOCH = np.ceil(val_image_count/BATCH_SIZE)\n",
    "\n",
    "def prepare_for_training(ds, shuffle=True, cache=True, shuffle_buffer_size=11000):\n",
    "    # This is a small dataset, only load it once, and keep it in memory.\n",
    "    # use `.cache(filename)` to cache preprocessing work for datasets that don't\n",
    "    # fit in memory.\n",
    "    if cache:\n",
    "        if isinstance(cache, str):\n",
    "            ds = ds.cache(cache)\n",
    "        else:\n",
    "            ds = ds.cache()\n",
    "\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(buffer_size=shuffle_buffer_size, reshuffle_each_iteration=True)\n",
    "\n",
    "    # Repeat forever\n",
    "    ds = ds.repeat()\n",
    "\n",
    "    ds = ds.batch(BATCH_SIZE)\n",
    "\n",
    "    # `prefetch` lets the dataset fetch batches in the background while the model\n",
    "    # is training.\n",
    "    ds = ds.prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "    return ds\n",
    "\n",
    "train_ds = prepare_for_training(labeled_ds)\n",
    "\n",
    "valid_ds = prepare_for_training(val_labeled_ds, shuffle=False)\n",
    "\n",
    "mirrored_strategy = tf.distribute.MirroredStrategy(devices=[\"/gpu:0\", \"/gpu:1\"])\n",
    "with mirrored_strategy.scope():\n",
    "\n",
    "    architectures = [(\"DenseNet121\",DenseNet121(input_shape=IMG_SHAPE,include_top=False,weights='imagenet')),\n",
    "                 (\"DenseNet169\",DenseNet169(input_shape=IMG_SHAPE,include_top=False,weights='imagenet')),\n",
    "                 (\"DenseNet201\",DenseNet201(input_shape=IMG_SHAPE,include_top=False,weights='imagenet')),\n",
    "                 (\"InceptionResNetV2\",InceptionResNetV2(input_shape=IMG_SHAPE,include_top=False,weights='imagenet')),\n",
    "                 (\"MobileNet\",MobileNet(input_shape=IMG_SHAPE,include_top=False,weights='imagenet')),\n",
    "                 (\"MobileNetV2\",MobileNetV2(input_shape=IMG_SHAPE,include_top=False,weights='imagenet')),\n",
    "                 (\"ResNet101\",ResNet101(input_shape=IMG_SHAPE,include_top=False,weights='imagenet')),\n",
    "                 (\"ResNet101V2\",ResNet101V2(input_shape=IMG_SHAPE,include_top=False,weights='imagenet')),\n",
    "                 (\"ResNet152\",ResNet152(input_shape=IMG_SHAPE,include_top=False,weights='imagenet')),\n",
    "                 (\"ResNet152V2\",ResNet152V2(input_shape=IMG_SHAPE,include_top=False,weights='imagenet')),\n",
    "                 (\"ResNet50\",ResNet50(input_shape=IMG_SHAPE,include_top=False,weights='imagenet')),\n",
    "                 (\"ResNet50V2\",ResNet50V2(input_shape=IMG_SHAPE,include_top=False,weights='imagenet')),\n",
    "                 (\"VGG16\",VGG16(input_shape=IMG_SHAPE,include_top=False,weights='imagenet')),\n",
    "                 (\"VGG19\",VGG19(input_shape=IMG_SHAPE,include_top=False,weights='imagenet')),\n",
    "                 (\"Xception\",Xception(input_shape=IMG_SHAPE,include_top=False,weights='imagenet'))]\n",
    "    \n",
    "    for arch in architectures:\n",
    "    \n",
    "        policy = mixed_precision.Policy('mixed_float16')\n",
    "        mixed_precision.set_policy(policy)\n",
    "        print(\"\")\n",
    "        print(\"Arch: \",arch[0])\n",
    "    \n",
    "        initializer = tf.keras.initializers.he_normal()\n",
    "        steps = np.ceil(image_count / BATCH_SIZE) * EPOCHS\n",
    "\n",
    "        #optimizer = tf.keras.optimizers.SGD(lr=lr)\n",
    "    \n",
    "        #optimizer = tf.keras.optimizers.RMSprop(lr=lr)\n",
    "        optimizer = tf.keras.optimizers.Adam(lr=lr)\n",
    "    \n",
    "        base_model = arch[1]\n",
    "    \n",
    "        base_model.trainable = False\n",
    "        global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
    "\n",
    "        batch_norm_1 = tf.keras.layers.BatchNormalization()\n",
    "        drop_out_1 = tf.keras.layers.Dropout(0.30)\n",
    "        dense_layer_1 = tf.keras.layers.Dense(512,activation='relu', kernel_initializer=initializer)\n",
    "\n",
    "        batch_norm_2 = tf.keras.layers.BatchNormalization()\n",
    "        drop_out_2 = tf.keras.layers.Dropout(0.5)\n",
    "        prediction_layer = tf.keras.layers.Dense(2)\n",
    "    \n",
    "        batch_norm_3 = tf.keras.layers.BatchNormalization()\n",
    "\n",
    "        model = tf.keras.Sequential([\n",
    "          base_model,\n",
    "          global_average_layer,\n",
    "      \n",
    "          batch_norm_1,\n",
    "          drop_out_1,\n",
    "          dense_layer_1,\n",
    "      \n",
    "          batch_norm_2,\n",
    "          drop_out_2,\n",
    "          prediction_layer,\n",
    "          batch_norm_3\n",
    "        ])\n",
    "\n",
    "    \n",
    "        model.compile(optimizer=optimizer,\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=['acc'])\n",
    "    \n",
    "        #model.summary()\n",
    "    \n",
    "        history = model.fit(train_ds,\n",
    "                    epochs=EPOCHS,\n",
    "                    validation_data=valid_ds, \n",
    "                    steps_per_epoch=STEPS_PER_EPOCH, \n",
    "                    validation_steps=VAL_STEPS_PER_EPOCH,\n",
    "                    callbacks=[])\n",
    "        print(\"\")\n",
    "        print(\"\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2.1-conda",
   "language": "python",
   "name": "tf2.1-conda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
